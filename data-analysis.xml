<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>StudyLog</title>
<link>https://shinjihan.github.io/studylog/data-analysis.html</link>
<atom:link href="https://shinjihan.github.io/studylog/data-analysis.xml" rel="self" type="application/rss+xml"/>
<description>통계와 AI를 기록하는 개인 블로그</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Invalid Date</lastBuildDate>
<item>
  <title>두 모집단에 대한 비교</title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_06_0.html</link>
  <description><![CDATA[ 





<p>두 모집단의 모평균, 모비율, 모분산의 차이에 대한 가설검증 문제를 다루고자 한다. (12장: 두 모집단의 비교와 이어지는 내용이다.)</p>
<p>표본 평균을 추정하려면, 표본의 크기와 모분산을 고려해야 한다.</p>
<p>[1] 두 모분산 σ12, σ 22 이 모두 알려져 있는 경우,</p>
<p>두 모평균 차에 대한 “추정량” ⇨ “두 표본평균의 차” 통계적 추론을 위한 “준비물” ⇨ “추정량의 분포”</p>
<p>이 분포는 다음과 같은 평균과 분산을 가진 정규분포를 따른다:</p>
<p>표준화된 확률변수 Z는 표준정규분포 N(0, 1)를 따른다.</p>
<p>[2] 두 모분산 σ12, σ 22 을 모두 모르는 경우, 표본의 크기를 고려하게 된다. 표본의 크기가 충분히 큰 경우 ( 25 이상 )</p>
<p>중심극한정리에 의해 모집단의 분포에 관계없이 x̄ 와 ȳ 가 근사적으로 정규분포를 따른다. 두 모분산의 추정치인 표본분산 s₁², s₂² 를 고려한 통계량을 사용하여 검정을 수행한다.</p>
<p>[3] 두 모집단이 알려져 있지는 않지만, 모분산이 동일한 것으로 가정할 수 있는 경우, 다음과 같은 평균과 분산을 가지는 정규분포를 따르며, [1]과 동일하다.</p>
<p>공통분산 σ ² 의 합동추정량 (Pooled Variance) 자유도 n ₁ + n ₂ – 2인 t-분포를 따른다.</p>
<p>[4] 두 모분산이 서로 다른 경우, [3]번 식은 t-분포를 따르지 않는다. 단, 아래와 같이 자유도를 수정할 경우, 근사적으로 t-분포를 따르게 된다. 근사적으로 t-분포를 따르게 된다. 수정된 자유도(df).</p>
<section id="독립표본-t검정" class="level2">
<h2 class="anchored" data-anchor-id="독립표본-t검정">독립표본 t–검정</h2>
<p>독립표본에 의한 두 모평균의 비교 두 개의 서로 독립적인 집단의 평균을 비교하여 그 차이가 통계적으로 유의한지 판단하는 방법이다.</p>
<p>사례: 새로운 강의방식이 초등학생 독해력 향상에 도움이 되는가?</p>
<div id="3055b74e" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"></span>
<span id="cb1-3">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://raw.githubusercontent.com/SHINJIHAN/advanced-bigdata/main/data/Reading.csv"</span></span>
<span id="cb1-4">Reading <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(url)</span>
<span id="cb1-5">Reading.head()</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">Group</th>
<th data-quarto-table-cell-role="th">Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1</td>
<td>New</td>
<td>75</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2</td>
<td>New</td>
<td>80</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3</td>
<td>New</td>
<td>72</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>4</td>
<td>New</td>
<td>77</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>5</td>
<td>New</td>
<td>69</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>가설검증을 결정하기 전에 데이터를 시각화한다.</p>
<div id="33bfce92" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 박스 플롯</span></span>
<span id="cb2-2">sns.boxplot(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Group'</span>, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Score'</span>, data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Reading)</span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shinjihan.github.io/studylog/da/ada/ada_06_0_files/figure-html/cell-3-output-1.png" width="597" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>중위수와 같은 요인을 비교한 결과, 차이가 나타나므로 이를 근거로 검증을 진행할 수 있다.</p>
<div id="0ea8c6c0" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 바이올린 플롯</span></span>
<span id="cb3-2">sns.violinplot(x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Group'</span>, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Score'</span>, data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Reading)</span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shinjihan.github.io/studylog/da/ada/ada_06_0_files/figure-html/cell-4-output-1.png" width="585" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e4d952db" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 기술통계량</span></span>
<span id="cb4-2">Reading.groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Group'</span>).Score.describe()</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">min</th>
<th data-quarto-table-cell-role="th">25%</th>
<th data-quarto-table-cell-role="th">50%</th>
<th data-quarto-table-cell-role="th">75%</th>
<th data-quarto-table-cell-role="th">max</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Group</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">New</th>
<td>8.0</td>
<td>75.375</td>
<td>4.373214</td>
<td>69.0</td>
<td>71.75</td>
<td>76.0</td>
<td>78.50</td>
<td>81.0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Old</th>
<td>8.0</td>
<td>69.125</td>
<td>4.086126</td>
<td>63.0</td>
<td>67.25</td>
<td>69.0</td>
<td>71.25</td>
<td>76.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>양측검정 적용.</p>
<div id="6ebe1e8e" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 그룹 나누기</span></span>
<span id="cb5-2">New <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Reading[Reading.Group <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'New'</span>]</span>
<span id="cb5-3">Old <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Reading[Reading.Group <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Old'</span>]</span>
<span id="cb5-4"></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 양측검증:</span></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 두 강의 방식에 차이가 있다. vs 차이가 없다.</span></span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ttest_ind  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 독립 t-검정</span></span>
<span id="cb5-9">ttest_ind(New.Score, Old.Score, equal_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb5-10"></span>
<span id="cb5-11"></span>
<span id="cb5-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># T통계량: 그룹 간 평균 차이가 실제로 존재하는지를 나타내는 통계량.</span></span>
<span id="cb5-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 통계량이 클수록 차이가 있을 가능성이 높다.</span></span>
<span id="cb5-14"></span>
<span id="cb5-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [3]번 통계량: statistic=2.9536127902039953</span></span>
<span id="cb5-16"></span>
<span id="cb5-17"></span>
<span id="cb5-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 두 꼬리 검정에서의 p-값: pvalue=0.010470744188033123</span></span>
<span id="cb5-19"></span>
<span id="cb5-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 통상적으로 p-값이 0.05보다 작으면 귀무가설을 기각할 수 있다. </span></span>
<span id="cb5-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 즉, 두 강의 방식에 차이가 있다고 결론 내릴 수 있다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>TtestResult(statistic=np.float64(2.9536127902039953), pvalue=np.float64(0.010470744188033123), df=np.float64(14.0))</code></pre>
</div>
</div>
<p>양측검증을 수행한 뒤, p-value를 2로 나누어 단측 검정을 수행한 것과 동일한 결과를 얻고 있다.</p>
<div id="a829cc89" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 단측검정:</span></span>
<span id="cb7-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 새로운 학습법이 더 효과적이다. vs 효과적이지 않다.</span></span>
<span id="cb7-3"></span>
<span id="cb7-4">stat, pval <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ttest_ind(New.Score, Old.Score, equal_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"P"</span>, pval<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb7-6"></span>
<span id="cb7-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># p-값이 0.0052로 유의수준 0.05보다 작으므로, 대립가설을 채택할 수 있다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>P 0.005235372094016561</code></pre>
</div>
</div>
<p>단측검정과 등분산 가정 적용.</p>
<div id="59f90881" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 단측검정</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.stats.weightstats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ttest_ind</span>
<span id="cb9-3">ttest_ind(New.Score, Old.Score, alternative <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'larger'</span>, </span>
<span id="cb9-4">          usevar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pooled'</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 등분산 가정 적용:</span></span>
<span id="cb9-5">          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 두 그룹 간의 분산이 동일하다고 가정</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(np.float64(2.9536127902039953),
 np.float64(0.005235372094016561),
 np.float64(14.0))</code></pre>
</div>
</div>
<p>단측검정과 이분산 가정 적용.</p>
<div id="3af16d03" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 단측검정</span></span>
<span id="cb11-2">ttest_ind(New.Score, Old.Score, alternative <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'larger'</span>, </span>
<span id="cb11-3">          usevar <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'unequal'</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 이분산 가정 적용:</span></span>
<span id="cb11-4">          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 두 그룹의 분산이 서로 다르다는 가정</span></span>
<span id="cb11-5"></span>
<span id="cb11-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [4]번 통계량: usevar= 'pooled' ⇨ 'unequal'</span></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 14 ⇨ 13.935945095796395 (자유도가 실수로 바뀜)</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(np.float64(2.9536127902039953),
 np.float64(0.005256688626975243),
 np.float64(13.935945095796395))</code></pre>
</div>
</div>
<p>결론적으로, 새로운 강의방식이 초등학생 독해력 향상에 도움이 된다고 할 수 있다.</p>
<hr>
</section>
<section id="대응표본-t검정" class="level2">
<h2 class="anchored" data-anchor-id="대응표본-t검정">대응표본 t–검정</h2>
<p>대응표본에 의한 두 모평균의 비교 어떤 신발의 마모율을 비교할 때, 독립 표본 검정에 경우, 한 그룹의 사람이 왼쪽 신발을 신고, 다른 그룹의 사람이 오른쪽 신발을 신더라도 상관이 없다. 하지만 <strong>대응 표본 검정</strong>은 동일한 사람이 왼쪽 신발과 오른쪽 신발을 모두 신어야 만 한다. 각 쌍이 서로 연관되어 있으므로 두 신발을 신는 사람이 동일해야 하며, 표본의 수도 일치해야 한다.</p>
<p>이는 마모율에 영향을 줄 수 있는 교락 요인(confounding factor), 즉 신발을 신는 사람의 특성 등을 배제하기 때문이다.</p>
<p>그러므로, 대응 표본 검정은 같은 대상에 대한 실험 전후의 결과를 비교할 때 주로 사용된다.</p>
<ul>
<li>사례: 컴퓨터 교육을 실시하기 전과 후의 성적에 차이가 있는가?</li>
</ul>
<div id="784b6820" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb13-2"></span>
<span id="cb13-3">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://raw.githubusercontent.com/SHINJIHAN/advanced-bigdata/main/data/Paired.csv"</span></span>
<span id="cb13-4">Paired <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(url)</span>
<span id="cb13-5">Paired.head()</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">Pretest</th>
<th data-quarto-table-cell-role="th">Posttest</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1</td>
<td>80</td>
<td>82</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2</td>
<td>73</td>
<td>71</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3</td>
<td>70</td>
<td>95</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>4</td>
<td>60</td>
<td>69</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>5</td>
<td>88</td>
<td>100</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>박스플롯 시각화 및 기술 통계량 출력.</p>
<div id="f783e8ac" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb14-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pretest와 Posttest에 대한 박스플롯 시각화</span></span>
<span id="cb14-5">sns.boxplot(data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Paired.iloc[:, [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]], </span>
<span id="cb14-6">            orient <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'h'</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 수평 방향</span></span>
<span id="cb14-7"></span>
<span id="cb14-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pretest와 Posttest의 차이 계산 및 새로운 열(Diff) 추가</span></span>
<span id="cb14-9">Paired[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Diff"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Paired.Pretest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Paired.Posttest </span>
<span id="cb14-10">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># = 교육 전 성적 - 교육 후 성적</span></span>
<span id="cb14-11">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 교육이 효과가 있다면 교육 후 성적이 더 높을 것이므로</span></span>
<span id="cb14-12">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 결과적으로는 변수 Diff의 값이 음수로 나와야 한다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shinjihan.github.io/studylog/da/ada/ada_06_0_files/figure-html/cell-11-output-1.png" width="603" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>두 변수에 대한 상자 그림</p>
<div id="5b9fd091" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">Paired.iloc[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>].describe()</span>
<span id="cb15-2"></span>
<span id="cb15-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 변수 Diff 평균(mean)이 -7.93이며</span></span>
<span id="cb15-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 실제로 그래프 상에서도 대부분의 개체에서 </span></span>
<span id="cb15-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 변수 Diff의 값이 0보다 작음을 볼 수 있다.</span></span>
<span id="cb15-6"></span>
<span id="cb15-7"></span>
<span id="cb15-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 표준편차(std)는 데이터의 산포도(변동성)를 측정하는 지표로, </span></span>
<span id="cb15-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 데이터가 평균으로부터 얼마나 떨어져 있는지를 나타낸다. </span></span>
<span id="cb15-10"></span>
<span id="cb15-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 표준편차는 항상 0 이상의 값을 가지며, 음수가 될 수 없다. </span></span>
<span id="cb15-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 이는 표준편차가 데이터 값의 차이를 제곱하여 계산하기 때문이다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Pretest</th>
<th data-quarto-table-cell-role="th">Posttest</th>
<th data-quarto-table-cell-role="th">Diff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">count</th>
<td>15.000000</td>
<td>15.000000</td>
<td>15.000000</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">mean</th>
<td>70.266667</td>
<td>78.200000</td>
<td>-7.933333</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">std</th>
<td>18.041487</td>
<td>14.313829</td>
<td>9.931671</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">min</th>
<td>37.000000</td>
<td>60.000000</td>
<td>-25.000000</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">25%</th>
<td>59.500000</td>
<td>67.000000</td>
<td>-12.500000</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">50%</th>
<td>73.000000</td>
<td>75.000000</td>
<td>-7.000000</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">75%</th>
<td>82.000000</td>
<td>90.500000</td>
<td>-2.500000</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">max</th>
<td>98.000000</td>
<td>100.000000</td>
<td>13.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>히스토그램 및 커널 밀도 추정(KDE) 시각화</p>
<div id="f4dc040f" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">sns.distplot(Paired.Diff)</span>
<span id="cb16-2"></span>
<span id="cb16-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Seaborn의 최신 버전에서는 더 이상 지원되지 않으므로,</span></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># sns.histplot 또는 sns.kdeplot을 사용하는 것이 권장된다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\user\AppData\Local\Temp\ipykernel_18240\4004193321.py:1: UserWarning:



`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shinjihan.github.io/studylog/da/ada/ada_06_0_files/figure-html/cell-13-output-2.png" width="597" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e2c12a3d" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb18-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 히스토그램 그리기</span></span>
<span id="cb18-5">sns.histplot(Paired.Diff, </span>
<span id="cb18-6">             stat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'density'</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># y축을 밀도로 변경</span></span>
<span id="cb18-7"></span>
<span id="cb18-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># KDE만 수정하기 위해 따로 그리기</span></span>
<span id="cb18-9">sns.kdeplot(Paired.Diff, </span>
<span id="cb18-10">            fill <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 음영 처리</span></span>
<span id="cb18-11"></span>
<span id="cb18-12">plt.xlim(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># x축 범위 설정</span></span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://shinjihan.github.io/studylog/da/ada/ada_06_0_files/figure-html/cell-14-output-1.png" width="606" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>양측검정 적용</p>
<div id="601c00f7" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ttest_rel에서 rel은 paired 또는 related를 의미한다.</span></span>
<span id="cb19-2"></span>
<span id="cb19-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 이 함수는 대응표본 t-검정을 수행하는 것으로, </span></span>
<span id="cb19-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 두 관련된 표본에 대한 평균의 차이를 비교하는 데 사용된다.</span></span>
<span id="cb19-5"></span>
<span id="cb19-6"></span>
<span id="cb19-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ttest_rel</span>
<span id="cb19-8">ttest_rel(Paired.Pretest, Paired.Posttest)</span>
<span id="cb19-9"></span>
<span id="cb19-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># p-값이 0.0079(0.79%)로 0.05(5%)보다 작기 때문에 </span></span>
<span id="cb19-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 귀무가설을 기각하고 대립가설을 채택할 수 있다. </span></span>
<span id="cb19-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 이는 두 표본 간에 유의미한 차이가 있음을 의미한다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>TtestResult(statistic=np.float64(-3.093705670004429), pvalue=np.float64(0.007930923229026533), df=np.int64(14))</code></pre>
</div>
</div>
<p>양측검증을 수행한 뒤, p-value를 2로 나누어 단측 검정을 수행한 것과 동일한 결과를 얻고 있다.</p>
<div id="2a8bb37e" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">stat, pval <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ttest_rel(Paired.Pretest, Paired.Posttest)</span>
<span id="cb21-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"one-sided p-value ="</span>, pval<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb21-3"></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 이 경우에도, p-값이 0.05보다 작으므로 </span></span>
<span id="cb21-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 귀무가설을 기각하고 대립가설을 채택할 수 있다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>one-sided p-value = 0.003965461614513267</code></pre>
</div>
</div>
<p>결론적으로 컴퓨터 교육을 실시하기 전과 후의 성적에 차이가 있으며, 사후 테스트의 결과가 더 좋다고 할 수 있다.</p>
<hr>
</section>
<section id="피셔의-정확검정" class="level2">
<h2 class="anchored" data-anchor-id="피셔의-정확검정">피셔의 정확검정</h2>
<p><code>Fisher's Exact Test</code></p>
<p>독립표본에 의한 두 모비율의 비교 두 모비율에 대한 검정을 수행하기 위해 사용할 수 있는 대표적인 검정법은 두 독립된 이항분포의 비율에 대한 z-검정이다.</p>
<p>사례: 현 정부에 대한 지지율이 성인 남녀별로 차이가 있는가?</p>
<div id="296a930e" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb23-2"></span>
<span id="cb23-3">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://raw.githubusercontent.com/SHINJIHAN/advanced-bigdata/main/data/Support.csv"</span></span>
<span id="cb23-4">Support <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(url)</span>
<span id="cb23-5">Support.head()</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th">YesNo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1</td>
<td>Male</td>
<td>No</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2</td>
<td>Female</td>
<td>Yes</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3</td>
<td>Female</td>
<td>No</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>4</td>
<td>Female</td>
<td>No</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>5</td>
<td>Female</td>
<td>No</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>이 데이터에 대한 2차원 분할표(빈도표) 작성하기.</p>
<div id="fae26668" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb24-2">SupportTable <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.crosstab(index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Support[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gender"</span>],</span>
<span id="cb24-3">                           columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Support[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"YesNo"</span>])</span>
<span id="cb24-4"></span>
<span id="cb24-5">SupportTable</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">YesNo</th>
<th data-quarto-table-cell-role="th">No</th>
<th data-quarto-table-cell-role="th">Yes</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">Female</th>
<td>96</td>
<td>104</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Male</th>
<td>140</td>
<td>110</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>행 백분율 계산하기.</p>
<div id="5013daef" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">pd.crosstab(index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Support[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gender"</span>], columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Support[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"YesNo"</span>],</span>
<span id="cb25-2">           normalize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"index"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 행의 합을 기준으로 비율을 계산</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">YesNo</th>
<th data-quarto-table-cell-role="th">No</th>
<th data-quarto-table-cell-role="th">Yes</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Gender</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">Female</th>
<td>0.48</td>
<td>0.52</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Male</th>
<td>0.56</td>
<td>0.44</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>다음과 같은 교차 테이블(Cross Table)을 만들 수 있다.</p>
<p>양측검증 적용.</p>
<div id="1e8dda61" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> fisher_exact</span>
<span id="cb26-2">fisher_exact(SupportTable, </span>
<span id="cb26-3">             alternative <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'two-sided'</span>)</span>
<span id="cb26-4">             </span>
<span id="cb26-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 이 결과는 검정 통계량이 0.725이고 </span></span>
<span id="cb26-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># p-값이 0.106(10.6%)이다.</span></span>
<span id="cb26-7"></span>
<span id="cb26-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 이는 일반적으로 사용되는 유의 수준 0.05(5%)에서 </span></span>
<span id="cb26-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 통계적으로 유의하지 않다는 것을 의미한다. </span></span>
<span id="cb26-10"></span>
<span id="cb26-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 결론적으로, 두 그룹(또는 변수) 간에 유의한 차이 또는 </span></span>
<span id="cb26-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연관성을 찾지 못했다는 것을 나타낸다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>SignificanceResult(statistic=np.float64(0.7252747252747253), pvalue=np.float64(0.10634531219761142))</code></pre>
</div>
</div>
<p>정규 근사 검정</p>
<p>이항분포의 표본 크기 n이 충분히 크면, 이항분포는 정규분포로 근사할 수 있으며, 이를 정규 근사라고 한다. 일반적으로 n×p와 n×(1 − p)가 모두 5 이상이면, 정규분포로 근사할 수 있다고 간주한다.</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?p">: 성공 확률</li>
</ul>
<p>이러한 정규화된 변수를 제곱하면, 자유도가 1인 카이제곱 분포를 따른다. 카이제곱검정(Chi-Square Test) 적용.</p>
<div id="deb688be" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> chi2_contingency</span>
<span id="cb28-2">chi2_contingency(SupportTable)</span>
<span id="cb28-3"></span>
<span id="cb28-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 카이제곱 통계량: 2.54</span></span>
<span id="cb28-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 유의 수준이 일반적으로 0.05(5%)인 경우, </span></span>
<span id="cb28-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># p-값이 0.111(11.1%)이므로 귀무가설을 기각할 수 없다.</span></span>
<span id="cb28-7"></span>
<span id="cb28-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 따라서 이 결과는 두 변수 간에 통계적으로 </span></span>
<span id="cb28-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 유의한 연관성이 없다고 결론지을 수 있다. </span></span>
<span id="cb28-10"></span>
<span id="cb28-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 즉, 이 교차표에 따르면 두 변수는 독립적이다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>Chi2ContingencyResult(statistic=np.float64(2.5395141968952935), pvalue=np.float64(0.1110289428837834), dof=1, expected_freq=array([[104.88888889,  95.11111111],
       [131.11111111, 118.88888889]]))</code></pre>
</div>
</div>
<p>결론적으로, 현 정부에 대한 지지율이 성인 남녀별로 차이가 없다고 할 수 있다.</p>
<hr>
</section>
<section id="맥니머-검정" class="level2">
<h2 class="anchored" data-anchor-id="맥니머-검정">맥니머 검정</h2>
<p>대응표본에 의한 두 모비율의 비교</p>
<p>맥니머 검정은 피셔의 정확검정이나 카이제곱 검정과 달리 대응 표본에 적용할 수 있는 검정이다. 이 검정은 대응 표본 t-검정과 유사하게 교락 효과를 제거하는 것이 중요하다.</p>
<p>독립 표본의 경우, 한 사람이 A, B 제품 모두를 사용하지 않아도 무방하다. 그러나 대응 표본에서는 한 사람이 반드시 두 제품 모두를 사용해야 한다.</p>
<p>사례: 정부에서 정책 발표 후 지지율에 변화가 있는가?</p>
<div id="802d9e53" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb30-2"></span>
<span id="cb30-3">url <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://raw.githubusercontent.com/SHINJIHAN/advanced-bigdata/main/data/Prepost.csv"</span></span>
<span id="cb30-4">Prepost <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(url)</span>
<span id="cb30-5">Prepost.head()</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">Pre</th>
<th data-quarto-table-cell-role="th">Post</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>4</td>
<td>No</td>
<td>No</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>5</td>
<td>No</td>
<td>No</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="b4d9e842" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb31-2"></span>
<span id="cb31-3">PrepostTable <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.crosstab(index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Prepost[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Pre"</span>], </span>
<span id="cb31-4">                           columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Prepost[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Post"</span>], </span>
<span id="cb31-5">                           margins <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 행과 열의 합계 추가</span></span>
<span id="cb31-6">                           margins_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"합계"</span>)</span>
<span id="cb31-7">PrepostTable</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Post</th>
<th data-quarto-table-cell-role="th">No</th>
<th data-quarto-table-cell-role="th">Yes</th>
<th data-quarto-table-cell-role="th">합계</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Pre</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">No</th>
<td>18</td>
<td>27</td>
<td>45</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Yes</th>
<td>8</td>
<td>67</td>
<td>75</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">합계</th>
<td>26</td>
<td>94</td>
<td>120</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="57575b9c" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">pd.crosstab(index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Prepost[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Pre"</span>], columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Prepost[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Post"</span>], </span>
<span id="cb32-2">            margins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, margins_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"합계"</span>, </span>
<span id="cb32-3">            normalize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"all"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 전체 데이터에 대한 비율 변환</span></span>
<span id="cb32-4">            </span>
<span id="cb32-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 정책 발표 이전 지지율(pre): 62.5%</span></span>
<span id="cb32-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 정책 발표 이후 지지율(post): 78.3%</span></span>
<span id="cb32-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 결과적으로 15.8%p가 상승하였음을 볼 수 있다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Post</th>
<th data-quarto-table-cell-role="th">No</th>
<th data-quarto-table-cell-role="th">Yes</th>
<th data-quarto-table-cell-role="th">합계</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Pre</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">No</th>
<td>0.150000</td>
<td>0.225000</td>
<td>0.375</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">Yes</th>
<td>0.066667</td>
<td>0.558333</td>
<td>0.625</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">합계</th>
<td>0.216667</td>
<td>0.783333</td>
<td>1.000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="914488bf" class="cell" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pip install statsmodels</span></span>
<span id="cb33-2"></span>
<span id="cb33-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.stats.contingency_tables <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mcnemar</span>
<span id="cb33-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mcnemar(PrepostTable, </span>
<span id="cb33-5">              exact <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 이항분포 기반의 정확 검정 방법</span></span>
<span id="cb33-6">              </span>
<span id="cb33-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 0.001(0.1%) &lt; 0.05(5%)</span></span>
<span id="cb33-8"></span>
<span id="cb33-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mcnemar(PrepostTable, </span>
<span id="cb33-10">              exact<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 카이제곱분포를 사용한 근사 검정 방법</span></span>
<span id="cb33-11">              </span>
<span id="cb33-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 0.002(0.2%) &lt; 0.05(5%)</span></span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>pvalue      0.0018782254774123432
statistic   8.0
pvalue      0.0023457869795667934
statistic   9.257142857142858</code></pre>
</div>
</div>
<p>결론적으로, 정부에서 정책 발표 전후 지지율에 변화가 있으며, 정책 발표 후에 지지율이 상승한 것으로 볼 수 있다.</p>
</section>
<section id="f검정" class="level2">
<h2 class="anchored" data-anchor-id="f검정">F–검정</h2>
<p><code>F–test</code></p>
<p>모분산의 동일성에 대한 검정 가장 일반적인 검정 방법으로, 두 집단의 모분산이 동일한지 평가한다. 두 집단의 분산 비율을 계산하고, 이를 기반으로 F–분포를 사용하여 p–값을 구한다.</p>
<p>Reading 데이터의 모분산이 다른가?</p>
<p>이전에 다루었던 Reading 데이터에 대해 분산의 동일성 검정을 위한 사용자 정의 함수를 작성하고, 가설검정을 수행하였다.</p>
<div id="e0b97d8e" class="cell" data-execution_count="25">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb35-2"></span>
<span id="cb35-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># file_path = os.path.join('data', 'Reading.csv')</span></span>
<span id="cb35-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Reading = pd.read_csv(file_path)</span></span>
<span id="cb35-5"></span>
<span id="cb35-6">New <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Reading[Reading.Group <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'New'</span>]</span>
<span id="cb35-7">Old <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Reading[Reading.Group <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Old'</span>]</span>
<span id="cb35-8"></span>
<span id="cb35-9"></span>
<span id="cb35-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb35-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> stats</span>
<span id="cb35-12"></span>
<span id="cb35-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> F_test(x, y):</span>
<span id="cb35-14">    f <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.var(x, ddof <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>np.var(y, ddof <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb35-15">    df1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x.size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> </span>
<span id="cb35-16">    df2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y.size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> </span>
<span id="cb35-17">    p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>stats.f.cdf(f, df1, df2))</span>
<span id="cb35-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> f, p</span>
<span id="cb35-19"></span>
<span id="cb35-20">F_test(New.Score, Old.Score)</span>
<span id="cb35-21"></span>
<span id="cb35-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 0.8(80%) &gt; 0.05(5%) </span></span>
<span id="cb35-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 귀무가설을 기각할 수 없다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>(1.1454545454545453, np.float64(0.8624138071371459))</code></pre>
</div>
</div>
<section id="bartletts-test" class="level3">
<h3 class="anchored" data-anchor-id="bartletts-test">Bartlett’s Test</h3>
<div id="e1edbd14" class="cell" data-execution_count="26">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> stats</span>
<span id="cb37-2">stats.bartlett(New.Score, Old.Score)</span>
<span id="cb37-3"></span>
<span id="cb37-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 0.8(80%) &gt; 0.05(5%) </span></span>
<span id="cb37-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 귀무가설을 기각할 수 없다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>BartlettResult(statistic=np.float64(1.2110354068328009), pvalue=np.float64(0.27112715913152846))</code></pre>
</div>
</div>
</section>
<section id="levenes-test" class="level3">
<h3 class="anchored" data-anchor-id="levenes-test">Levene’s Test</h3>
<div id="478ea05a" class="cell" data-execution_count="27">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">stats.levene(New.Score, Old.Score)</span>
<span id="cb39-2"></span>
<span id="cb39-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 0.6(60%) &gt; 0.05(5%) </span></span>
<span id="cb39-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 귀무가설을 기각할 수 없다.</span></span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>LeveneResult(statistic=np.float64(0.1978798586572438), pvalue=np.float64(0.6632376240724351))</code></pre>
</div>
</div>
<p>결론적으로, 두 집단의 모분산이 다르다고 말할 수 없다.</p>
<hr>
<p>교제: 파이썬을 활용한 데이터 분석과 응용</p>


</section>
</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_06_0.html</guid>
  <pubDate>Invalid Date</pubDate>
</item>
<item>
  <title>주성분 분석(PCA)</title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/dap/dap_03.html</link>
  <description><![CDATA[ 





<p><code>Principal Component Analysis, PCA</code><br> 상관관계가 존재할 수 있는 (p)개의 관찰 변수를 <strong>선형 변환</strong>하여<br> 서로 상관관계가 없는 새로운 인공 변수(주성분)를 생성하는 통계적 기법이다.<br></p>
<p>고차원 데이터에서는 변수 간 상관 관계가 분석과 해석을 복잡하게 만들 수 있으므로,<br> PCA를 통해 데이터 구조를 단순화하고, <strong>차원 축소</strong>를 수행함으로써 데이터 시각화, 노이즈 제거, 변수 간 다중공선성 문제 해결이 가능하다.<br></p>
<hr>
<section id="목표-및-원리" class="level1">
<h1>01 목표 및 원리</h1>
<section id="주성분-생성" class="level2">
<h2 class="anchored" data-anchor-id="주성분-생성">1. 주성분 생성</h2>
<p>주성분 분석의 목적은 다음과 같이 정의할 수 있다:</p>
<ol type="1">
<li><p>상관관계가 존재할 수 있는 <img src="https://latex.codecogs.com/png.latex?p"> 개의 원본 관찰 변수 <img src="https://latex.codecogs.com/png.latex?X%20=%20%5Bx_1,%20x_2,%20%5Cdots,%20x_p%5D"> 를 <strong>선형 변환(linear transformation)</strong>하여, 서로 상관관계가 없는 새로운 변수 집합 <img src="https://latex.codecogs.com/png.latex?Z%20=%20%5Bz_1,%20z_2,%20%5Cdots,%20z_p%5D"> 를 생성한다.</p></li>
<li><p>변환된 변수 <img src="https://latex.codecogs.com/png.latex?Z"> 는 서로 <strong>직교(orthogonal)</strong>하므로 상관성이 제거되며, 이를 통해 차원 축소와 데이터 구조 파악을 보다 효과적으로 수행할 수 있다.</p></li>
<li><p>각 주성분 <img src="https://latex.codecogs.com/png.latex?z_k"> 는 <strong>원자료의 분산을 최대한 보존</strong>하도록 선택되며, 주성분의 순서는 설명하는 분산의 크기에 따라 결정된다.</p></li>
</ol>
</section>
<section id="표준화" class="level2">
<h2 class="anchored" data-anchor-id="표준화">2 표준화</h2>
<p><code>Standardization</code><br> PCA 수행 시 변수의 단위와 스케일이 다를 경우, 표준화를 먼저 수행해야 한다.<br> 표준화 방법:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax'_i%20=%20%5Cfrac%7Bx_i%20-%20%5Cbar%7Bx%7D%7D%7Bs_x%7D,%20%5Cquad%20i%20=%201,2,%5Cdots,n%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?x_i"> : 원 변수 값</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbar%7Bx%7D"> : 변수의 평균</li>
<li><img src="https://latex.codecogs.com/png.latex?s_x"> : 변수의 표준편차</li>
</ul>
<p>표준화 후 변수는 평균 0, 분산 1을 갖게 되어 PCA에서 각 변수의 영향력이 균등하게 반영된다.</p>
<p>데이터 행렬은 다음과 같이 표현한다.</p>
<ul>
<li><p><strong>원본 데이터 행렬:</strong> <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bp%20%5Ctimes%20n%7D"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?p">: 관찰 변수의 수</li>
<li><img src="https://latex.codecogs.com/png.latex?n">: 관측치(샘플)의 수</li>
</ul></li>
</ul>
</section>
<section id="선형-변환" class="level2">
<h2 class="anchored" data-anchor-id="선형-변환">3. 선형 변환</h2>
<p>주성분 <img src="https://latex.codecogs.com/png.latex?z_k"> 는 원본 변수의 <strong>선형 결합</strong>으로 정의되며 다음과 같이 표현된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az_k%20=%20a_%7B1k%7D%20x_1%20+%20a_%7B2k%7D%20x_2%20+%20%5Cdots%20+%20a_%7Bpk%7D%20x_p%0A=%20%5Cmathbf%7Ba%7D_k%5ET%20%5Cmathbf%7Bx%7D,%20%5Cquad%20k%20=%201,%202,%20%5Cdots,%20p%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20%5Cin%20%5Cmathbb%7BR%7D%5Ep">: 원본 데이터 벡터</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D_k%20%5Cin%20%5Cmathbb%7BR%7D%5Ep">: k번째 주성분의 로딩(loading) 벡터</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D_k%5ET%20%5Cmathbf%7Ba%7D_j%20=%200%20(%20k%20%5Cneq%20j%20)">: 주성분 간 직교성</li>
</ul>
<blockquote class="blockquote">
<p>예시: 첫 번째 관측치 (n_1)의 첫 번째 주성분 좌표 (z_{1,1} = x_1^T v_1 = -0.2152) → (n_1)이 첫 번째 주성분 축 (v_1) 상에서 어디에 위치하는지를 나타내는 스칼라 값이다.</p>
</blockquote>
</section>
<section id="분산-최대화" class="level2">
<h2 class="anchored" data-anchor-id="분산-최대화">4. 분산 최대화</h2>
<p>첫 번째 주성분 <img src="https://latex.codecogs.com/png.latex?z_1">: <strong>전체 분산을 최대한 설명하는 방향</strong>이 되도록 선택.<br> 두 번째 주성분 <img src="https://latex.codecogs.com/png.latex?z_2">: <img src="https://latex.codecogs.com/png.latex?z_1"> 과 직교한다는 제약 아래 <strong>남아 있는 분산을 최대한 설명하는 방향</strong>으로 정의됨.<br> 이러한 방식으로 각 주성분은 계층적으로 결정된다.</p>
<p>따라서 k번째 주성분의 로딩 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D_k"> 는 다음 최적화 문제를 통해 구해진다.</p>
<p><strong>일반식 (k번째 주성분)</strong></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Ba%7D*k%0A=%20%5Carg%5Cmax*%7B%5Cmathbf%7Ba%7D%7D%0A%5Cmathrm%7BVar%7D(%5Cmathbf%7Ba%7D%5ET%20%5Cmathbf%7Bx%7D),%0A%5Cquad%0A%5Ctext%7Bsubject%20to%20%7D%0A%5Cmathbf%7Ba%7D%5ET%20%5Cmathbf%7Ba%7D%20=%201,;%0A%5Cmathbf%7Ba%7D%5ET%20%5Cmathbf%7Ba%7D_j%20=%200,;%20j%20%3C%20k%0A"></p>
<p><strong>특수식 (첫 번째 주성분)</strong><br> 첫 번째 주성분은 이전 주성분이 없으므로 직교 조건이 필요 없습니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Ba%7D_1%0A=%20%5Carg%5Cmax_%7B%5Cmathbf%7Ba%7D%7D%0A%5Cmathrm%7BVar%7D(%5Cmathbf%7Ba%7D%5ET%20%5Cmathbf%7Bx%7D),%0A%5Cquad%0A%5Ctext%7Bsubject%20to%20%7D%0A%5Cmathbf%7Ba%7D%5ET%20%5Cmathbf%7Ba%7D%20=%201%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7Ba%7D%7C%5E2%20=%20%5Cmathbf%7Ba%7D%5ET%20%5Cmathbf%7Ba%7D%20=%201">: Lagrange 승수법 적용을 위한 제약 조건</li>
</ul>
</section>
<section id="공분산-행렬과-고유값-분해" class="level2">
<h2 class="anchored" data-anchor-id="공분산-행렬과-고유값-분해">5. 공분산 행렬과 고유값 분해</h2>
<ol type="1">
<li><strong>Lagrange 승수법 적용 → 고유값 문제 도출</strong></li>
</ol>
<p>첫 번째 주성분에 대해 Lagrange 함수를 구성한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AL(%5Cmathbf%7Ba%7D,%5Clambda)%0A=%20%5Cmathbf%7Ba%7D%5ET%20%5CSigma%20%5Cmathbf%7Ba%7D%20-%20%5Clambda%20(%5Cmathbf%7Ba%7D%5ET%5Cmathbf%7Ba%7D-1)%0A"></p>
<p>편미분하여 최적 조건을 구하면, 다음 고유값 문제가 얻어진다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20%5Cmathbf%7Ba%7D%7D%20=%202%5CSigma%5Cmathbf%7Ba%7D%20-%202%5Clambda%20%5Cmathbf%7Ba%7D%20=%200%0A%5Cquad%20%5CRightarrow%20%5Cquad%20%5CSigma%20%5Cmathbf%7Ba%7D%20=%20%5Clambda%20%5Cmathbf%7Ba%7D%0A"></p>
<p>즉, <strong>주성분 로딩 벡터는 공분산 행렬의 고유벡터</strong>이다. * <strong>추가</strong>: 여기서 <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7Ba%7D%7C%5E2%20=%201"> 조건은 <strong>단위벡터(normalized vector)</strong>로 만들어 주성분 크기 비교가 가능하게 하는 역할을 한다.</p>
<ol start="2" type="1">
<li><strong>공분산 행렬 계산</strong></li>
</ol>
<p>데이터 행렬 <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bp%20%5Ctimes%20n%7D"> 에 대해 공분산 행렬은 다음으로 정의된다.<br> <img src="https://latex.codecogs.com/png.latex?%5CSigma">는 실대칭 행렬이므로 고유값 분해가 가능하다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5CSigma%20=%20%5Cfrac%7B1%7D%7Bn-1%7D%20XX%5ET%0A"></p>
<ul>
<li><strong>추가</strong>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bp%20%5Ctimes%20n%7D"> 가 아닌 <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p"> 형태라면<br> <img src="https://latex.codecogs.com/png.latex?%5CSigma%20=%20%5Cfrac%7B1%7D%7Bn-1%7D%20X%5ET%20X"> 로 계산해야 함.<br> → 구현 시 데이터 행렬 차원 주의</li>
<li><img src="https://latex.codecogs.com/png.latex?%5CSigma"> 는 대칭 행렬(Symmetric matrix)<br> → 고유벡터는 서로 직교(orthogonal)하며 정규화 가능</li>
</ul></li>
</ul>
<ol start="3" type="1">
<li><strong>고유값·고유벡터 해석 → 주성분의 분산</strong></li>
</ol>
<p>고유값 분해에서 얻어진 값:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5CSigma%20%5Cmathbf%7Ba%7D_k%20=%20%5Clambda_k%20%5Cmathbf%7Ba%7D_k%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D_k">: k번째 주성분 방향(loading vector)</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Clambda_k">: 해당 주성분이 설명하는 분산</li>
</ul>
<p>주성분 순서: 고유값 크기 순서대로 정렬<br> → <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20%5Cge%20%5Clambda_2%20%5Cge%20%5Cdots%20%5Cge%20%5Clambda_p"></p>
<p>다음과 같이 분산과 연결된다: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7BVar%7D(z_k)%20=%20%5Clambda_k%0A"></p>
</section>
<section id="차원-축소" class="level2">
<h2 class="anchored" data-anchor-id="차원-축소">6. 차원 축소</h2>
<p><code>Dimensionality Reduction</code><br> PCA는 고차원 데이터에서 <strong>분산을 많이 설명하는 주성분만 선택</strong>하여 차원을 축소하는 기법이다.<br> 원래의 <img src="https://latex.codecogs.com/png.latex?p"> 차원 데이터 중 정보를 가장 많이 보존하는 상위 <img src="https://latex.codecogs.com/png.latex?m"> 개의 주성분( <img src="https://latex.codecogs.com/png.latex?m%20%3C%20p"> )을 선택한다.</p>
<ol type="1">
<li><strong>설명되는 분산 비율</strong> <code>EVR, Explained Variance Ratio</code><br> 공분산 행렬의 고유값 <img src="https://latex.codecogs.com/png.latex?%5Clambda_k"> 는 k번째 주성분이 설명하는 분산을 의미한다.<br> 따라서 EVR은 다음과 같이 정의된다.</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BEVR%7D_k%0A=%20%5Cfrac%7B%5Clambda_k%7D%7B%5Csum_%7Bi=1%7D%5Ep%20%5Clambda_i%7D,%0A%5Cquad%20k%20=%201,2,%5Cdots,p%0A"></p>
<ol start="2" type="1">
<li><strong>누적 설명 분산 비율</strong> <code>Cumulative EVR</code><br> 차원 축소의 선택 기준은 누적 EVR이다.</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BCumulative%20EVR%7D_m%0A=%20%5Csum*%7Bk=1%7D%5Em%20%5Ctext%7BEVR%7D_k%0A"></p>
<p>일반적으로 <strong>전체 분산의 80~90%를 설명하는 m개의 주성분</strong>을 선택하면<br> 정보 손실 없이 효과적인 차원 축소가 가능하다.</p>
<ol start="3" type="1">
<li><strong>새로운 좌표계로의 사영</strong> <code>projection</code><br> 선택된 상위 <img src="https://latex.codecogs.com/png.latex?m"> 개의 주성분 벡터</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0AA_m%20=%20%5B%5Cmathbf%7Ba%7D_1,%20%5Cdots,%20%5Cmathbf%7Ba%7D_m%5D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bp%20%5Ctimes%20m%7D%0A"></p>
<p>사용하여 원본 데이터 <img src="https://latex.codecogs.com/png.latex?X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bp%20%5Ctimes%20n%7D"> 를 <strong>새로운 좌표계(주성분 축)</strong>로 투사(projection)한다. 각 관측치 <img src="https://latex.codecogs.com/png.latex?x_i%20%5Cin%20%5Cmathbb%7BR%7D%5Ep"> (i번째 열) 는 다음과 같이 <img src="https://latex.codecogs.com/png.latex?m"> 차원 좌표 <img src="https://latex.codecogs.com/png.latex?z_i%20%5Cin%20%5Cmathbb%7BR%7D%5Em"> 로 변환된다:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az_i%20=%20A_m%5ET%20x_i%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?m"> : 선택된 주성분 수 (차원 축소 후)</li>
<li><img src="https://latex.codecogs.com/png.latex?z_i"> : 관측치 (i)의 주성분 좌표</li>
<li>예: 5개의 주성분을 선택하면 각 관측치는 5차원 좌표를 가지게 됨</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0AZ_m%20=%20A_m%5ET%20X%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_m%20=%20%5B%5Cmathbf%7Ba%7D_1,%20%5Cdots,%20%5Cmathbf%7Ba%7D_m%5D">: 상위 m개의 주성분 로딩 벡터</li>
<li><img src="https://latex.codecogs.com/png.latex?Z_m">: 축소된 차원에서의 데이터 표현</li>
</ul>
<p>각 주성분은 원본 데이터의 분산을 최대한 유지하며 서로 직교하기 때문에,<br> <img src="https://latex.codecogs.com/png.latex?Z_m"> 은 <strong>상호 독립적인 새로운 좌표계에서의 데이터</strong>가 된다.</p>
<ol start="4" type="1">
<li><strong>해석</strong></li>
</ol>
<ul>
<li><p>각 주성분은 원본 변수들의 <strong>선형 결합</strong>으로 구성되므로,<br> 가중치(로딩) 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D_k"> 를 확인하면 해당 주성분이 어떤 변수에 의해 형성되었는지 해석 가능하다.</p></li>
<li><p>예: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D_1%20=%20%5B0.5,%200.5,%20-0.3,%20%5Cdots%5D"> → 첫 번째 주성분은 첫 두 변수의 기여도가 높음을 의미</p></li>
<li><p>필요 시, 시각화를 통해 각 주성분과 원자료 변수의 관계를 분석 가능.</p></li>
<li><p>(z_{i,k})는 관측치 (i)를 주성분 (k) 축에 사영한 값</p></li>
<li><p>시각화 시, 좌표 값의 크기는 축 방향으로 관측치가 얼마나 멀리 위치하는지를 나타냄</p></li>
<li><p>고유벡터 성분의 부호와 크기는 원 변수들이 주성분에 미치는 영향도를 나타냄</p></li>
<li><p>부호는 방향성을 의미하며, 절대 크기를 통해 상대적 기여도를 판단 가능</p></li>
<li><p>각 관측치의 (z_{i,k}) 값은 주성분 축 상의 위치를 나타냄</p></li>
<li><p>2차원 또는 3차원 시각화 시, 좌표 값은 관측치가 새로운 축 상에서 가지는 위치와 변동성을 직관적으로 보여줌</p></li>
<li><p>예: (z_{1,1})을 x축으로, (z_{1,2})를 y축으로 하여 관측치를 점으로 표현하면, 주성분 상에서의 데이터 분포를 시각화 가능</p></li>
</ul>
<ol start="5" type="1">
<li><strong>실무 활용</strong></li>
</ol>
<ul>
<li><p>PCA는 <strong>고차원 데이터의 시각화, 노이즈 제거, 변수 간 다중공선성 해결, 머신러닝 전처리</strong>에 활용됨</p></li>
<li><p>실무 적용 시 유의사항:</p>
<ol type="1">
<li>원자료 변수 단위가 서로 다른 경우 <strong>표준화(Standardization)</strong> 필요</li>
<li>PCA는 <strong>비지도 학습</strong>이므로 목적 변수(y)를 고려하지 않음</li>
<li>차원 축소 후 선택된 주성분이 실제 업무 의미와 일치하는지 확인 필요</li>
<li>주성분 해석 시, 원본 변수와의 관계를 반드시 확인하여 의미 있는 인사이트를 확보</li>
</ol></li>
</ul>
<ol start="6" type="1">
<li>전처리 차원 축소 vs PCA 차원 축소</li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 4%">
<col style="width: 37%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="header">
<th>구분</th>
<th>전처리 차원 축소</th>
<th>PCA 차원 축소</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>목적</td>
<td>불필요 변수 제거, 단위 조정 등</td>
<td>분산 최대 보존, 상관관계 제거, 통계적 차원 축소</td>
</tr>
<tr class="even">
<td>방식</td>
<td>경험적/규칙적</td>
<td>선형 변환 기반, 수학적 최적화</td>
</tr>
<tr class="odd">
<td>결과</td>
<td>원 변수 일부 제거</td>
<td>주성분으로 변환된 새로운 좌표</td>
</tr>
<tr class="even">
<td>활용</td>
<td>데이터 정제, 단순화</td>
<td>시각화, 피처 선택, 노이즈 제거, 모델 전처리</td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="biplot" class="level1">
<h1>03 Biplot</h1>
<p>다변량 데이터에서 차원 축소를 수행한 후 반드시 고려해야 하는 중요한 시각화 도구이다. 이 플롯에서는 주성분 축을 기준으로 데이터 포인트를 시각화하며, 동시에 주성분 벡터를 원래 변수의 방향과 크기를 나타내는 화살표로 표시한다. 각 원변수 벡터에는 레이블을 붙여 변수의 의미를 명확히 부여할 수 있다. 파이썬에서는 전용 함수가 제공되지 않기 때문에, 화살표는 보통 임의로 지정하여 추가한다. 이를 통해 주성분 축과 데이터 분포를 중심으로 각 변수가 어느 방향으로, 얼마나 퍼져나가는지를 확인할 수 있다.</p>
<p>전통적인 PCA 해석에서는 제1축과 제2축의 방향성을 수학적 계산으로 구분하지만, biplot에서는 화살표가 가리키거나 겹치거나 맞닿은 군집 간에서 변수가 유사하게 증가하거나 감소하며, 반대 방향에 위치한 경우에는 전혀 다른 변동성을 보인다. 이러한 시각적 해석 방식은 컨설팅 분야에서 자주 활용되며, 제1축과 제2축에 대한 라벨링과 4분면 구분을 통해 해석을 보다 직관적으로 수행할 수 있다.</p>
<hr>
<p>데이터가 적으므로 데이터 증강을 통해 정규분포를 따르는 노이즈 생성한다. 비율 서로 알맞게 설정. 강건성을 보기 위해서. 여러개 중에 비교하여 월드의 효용성 입증. 2로도 한 번 해보기 어떤 패턴이 나타나는지?? 가우시안 메소드, 베이지안 메소드.(약간 효능감이 떨어진다) 가중치(중심점)가 0.5이상인 것만 표시함 k-mean, 가우시안, 베이지안의 혼동행렬을 출력. 해석 방식이 조금 달라짐. 결과적으로 k-mean, 가우시안이 보다 효능감 있게 분리한다. 여기서 차이가 발생하는 데 이 이유는 각각 중심기준으로 원형태, 타원 형태로 그 기준이 달라서 차이가 나는 것임. 그러나 베이지안이 너무 디테일하게 한다고 특성을 무시하면서 억지로 그룹을 맞추려고 하는 것은 그러면 안된다.</p>
<hr>
<p>시나리오, 할수 있다 없다를 떠나서. CEO관점에서 뭐가 궁금한가? 가설을 여러개 세우고 묶는다. 그리고 단계별로 가지치기하면서 한다. 뭐가 빠져있지? 뭘 붙이지? 어떤 식을 세워야 하는가?</p>
<hr>
<p>종이나 변수에 대해 자세히 설명하기 갭통계량에서는 2를 할 이유는 없다, 적당히 큰 것이 좋기 때문. 기울기가 기준이 아님.</p>
<p>미국 대학의 최신의 데이터를 가져와서 쓰기. 증강한 데이터 패턴. 보여주기, 원데이터의 기초통계량과의 차이 등. 미적분학, 행렬, 벡터. 몇 백만, 십만개로 해야 됨.</p>
<p>아이디어. 데이터 주입. 그럼 분석결과와 시각화 나옴. 클릭하면 파이썬 코드 나옴.</p>
<p>SVM에서도 라그랑주 승수법으로 풀어주는 기법이 있다. RBF커널도 사용. 가장 성능이 좋다고 나옴.</p>


</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/dap/dap_03.html</guid>
  <pubDate>Mon, 01 Dec 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Clustering</title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/dap/dap_02.html</link>
  <description><![CDATA[ 





<section id="군집-분석" class="level1">
<h1>01 군집 분석</h1>
<p><strong>비지도 학습(Unsupervised Learning)</strong> 기법의 한 유형이다.<br></p>
<p>사전에 정의된 타겟 변수(종속 변수)가 존재하지 않는 데이터로부터<br> <strong>데이터 간 유사성 또는 거리(distance)</strong>를 기반으로 군집(cluster)을 형성하는 방법론이다.<br></p>
<p>이는 데이터가 어떠한 구조를 내재하고 있을 것으로 가정하되,<br> 그 구조의 형태—군집의 개수, 모양, 분포—가 <strong>사전에 알려져 있지 않은 상태</strong>에서 적용된다.<br></p>
<p>군집 분석의 핵심 목적은 다음 두 가지로 요약된다.<br> 1. <strong>군집 형성(Clustering)</strong>: 개체들 간 거리 계산을 통해 자연스러운 그룹을 형성<br> 2. <strong>군집 해석(Cluster Interpretation)</strong>: 형성된 군집의 특성과 군집 간 관계 구조를 분석하여 의미를 도출</p>
<section id="거리유사성-측정-방법론" class="level2">
<h2 class="anchored" data-anchor-id="거리유사성-측정-방법론">1. 거리(유사성) 측정 방법론</h2>
<p>군집 분석에서 가장 기초적이며 중요한 요소는<br> <strong>데이터 간 거리(distance) 또는 유사성(similarity) 계산 방식</strong>이다.<br> 거리 측정 방식에 따라 군집 결과는 크게 달라지므로, 데이터의 특성(연속형/희소벡터/텍스트 등)에 따라 적절한 측도를 선택해야 한다.<br></p>
<p>측도의 형태가 다르더라도, 군집 분석에서는<br> <strong>“거리 기반으로 개체 간 유사성을 정의한다는 점”</strong>이 공통적이다.</p>
<section id="유클리드-거리" class="level3">
<h3 class="anchored" data-anchor-id="유클리드-거리">1.1 유클리드 거리</h3>
<p><code>Euclidean Distance</code><br> 연속형 변수에서 가장 일반적으로 사용되는 거리 척도로, <strong>L2 노름(Norm)</strong>에 해당한다.<br> 두 관측치 <img src="https://latex.codecogs.com/png.latex?x_i,%20x_j%20%5Cin%20%5Cmathbb%7BR%7D%5Ep"> 사이의 유클리드 거리는 다음과 같이 정의된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad_%7B%5Cmathrm%7Beuclid%7D%7D(x_i,%20x_j)%20=%20%5Csqrt%7B%5Csum_%7Bk=1%7D%5E%7Bp%7D%20(x_%7Bik%7D%20-%20x_%7Bjk%7D)%5E2%7D%0A"></p>
<p>예: 2차원 데이터 <img src="https://latex.codecogs.com/png.latex?p_1=(x_1,%20~y_1),%20~~~p_2=(x_2,%20~y_2)"> 의 경우, 다음과 같이 계산할 수 있다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad(p_1,%20~~~p_2)%20=%20%5Csqrt%7B(x_2%20-%20x_1)%5E2%20+%20(y_2%20-%20y_1)%5E2%7D%0A"> <br></p>
<section id="데이터-표준화" class="level4">
<h4 class="anchored" data-anchor-id="데이터-표준화"><strong>(1) 데이터 표준화</strong></h4>
<p>각 변수의 단위가 상이할 경우, 거리 계산이 왜곡될 수 있으므로 표준화가 필요하다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax'%20=%20%5Cfrac%7Bx%20-%20%5Cmu%7D%7B%5Csigma%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu">: 평균</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Csigma">: 표준편차</li>
</ul>
</section>
<section id="병합적-계층-군집-분석-절차" class="level4">
<h4 class="anchored" data-anchor-id="병합적-계층-군집-분석-절차"><strong>(2) 병합적 계층 군집 분석 절차</strong></h4>
<ol type="1">
<li><p>모든 개체를 단일 군집(singleton cluster)으로 초기화한다. <img src="https://latex.codecogs.com/png.latex?%0AC_1%20=%20%7Bx_1%7D,%20C_2%20=%20%7Bx_2%7D,%20%5Cdots,%20C_n%20=%20%7Bx_n%7D%0A"></p></li>
<li><p>현재 존재하는 군집들 간 거리 행렬 <img src="https://latex.codecogs.com/png.latex?D_0"> 를 계산한다.</p>
<ul>
<li>행렬은 대칭이며, 각 원소 <img src="https://latex.codecogs.com/png.latex?d(C_i,C_j)"> 는 군집 <img src="https://latex.codecogs.com/png.latex?C_i,%20C_j"> 간 거리이다.</li>
</ul></li>
<li><p>거리 행렬에서 가장 가까운 군집 쌍 <img src="https://latex.codecogs.com/png.latex?(C_p,C_q)"> 을 선택하여 병합한다.</p>
<ul>
<li>행렬 크기는 1줄씩 감소하며, 새로운 군집 <img src="https://latex.codecogs.com/png.latex?C_%7Bnew%7D=C_p%20%5Ccup%20C_q"> 가 생성된다.</li>
</ul></li>
<li><p>새로운 군집과 나머지 군집 간 거리를 연결법(Linkage Method)에 따라 재계산한다.</p></li>
<li><p>이 과정을 반복하여 최종적으로 모든 개체가 하나의 군집으로 통합될 때까지 진행한다.</p></li>
</ol>
</section>
</section>
<section id="맨해튼-거리" class="level3">
<h3 class="anchored" data-anchor-id="맨해튼-거리">1.2 맨해튼 거리</h3>
<p><code>Manhattan Distance</code><br> <strong>L1 노름</strong> 기반 거리로, 고차원 데이터에서 유리할 수 있다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad_%7B%5Ctext%7Bmanhattan%7D%7D(x_i,%20x_j)%20=%20%5Csum_%7Bk=1%7D%5E%7Bp%7D%5Cleft%7Cx_%7Bik%7D%20-%20x_%7Bjk%7D%5Cright%7C%0A"></p>
</section>
<section id="코사인-유사도" class="level3">
<h3 class="anchored" data-anchor-id="코사인-유사도">1.3 코사인 유사도</h3>
<p><code>Cosine Similarity</code><br> 텍스트 마이닝 분야에서 주로 사용되며, 벡터 방향의 유사성을 측정한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bcos%7D(x_i,%20x_j)%20=%20%5Cfrac%7Bx_i%20%5Ccdot%20x_j%7D%7B%7Cx_i%7C%7Cx_j%7C%7D%0A"></p>
<p>코사인 <strong>거리(Cosine Distance)</strong>는 다음과 같이 정의된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad_%7B%5Ctext%7Bcosine%7D%7D%20=%201%20-%20%5Ctext%7Bcos%7D(x_i,%20x_j)%0A"></p>
<hr>
</section>
</section>
<section id="군집-형성의-구조적-특징" class="level2">
<h2 class="anchored" data-anchor-id="군집-형성의-구조적-특징">2. 군집 형성의 구조적 특징</h2>
<section id="안정적-군집-형태" class="level3">
<h3 class="anchored" data-anchor-id="안정적-군집-형태">2.1 안정적 군집 형태</h3>
<p>k-means 기반 군집화 모델은 군집을 수학적으로 <strong>구형(spherical)</strong> 구조로 가정한다.<br> k-means의 목적함수는 다음을 최소화한다.<br></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7BC_1,%20...,%20C_K%7D%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20%5Csum_%7Bx_i%20%5Cin%20C_k%7D%20%7Cx_i%20-%20%5Cmu_k%7C%5E2%0A"></p>
<p>이는 각 군집 중심(centroid)으로부터의 제곱거리 최소화를 가정하므로,<br> 군집이 <strong>타원형이 아닌 구형에 가까울 때</strong> 성능이 가장 안정적이다.</p>
</section>
<section id="비정형-군집의-문제-사례" class="level3">
<h3 class="anchored" data-anchor-id="비정형-군집의-문제-사례">2.2 비정형 군집의 문제 사례</h3>
<p>아래의 경우는 k-means 모델에서 성능이 저하되는 대표 사례이다.<br></p>
<ol type="1">
<li><strong>군집의 형태가 길고 가는 모양(elongated cluster)인 경우</strong><br>
<ul>
<li>구형 중심 거리 기준으로는 정확히 분리되지 않는다.</li>
</ul></li>
<li><strong>개체 A, B가 서로 다른 군집 사이에서 ‘다리’ 역할을 하는 중간 위치에 존재하는 경우</strong><br>
<ul>
<li>두 군집이 실제로 분리되어 있어도 k=2 가정에서 중심이 왜곡된다.</li>
</ul></li>
</ol>
<p>이와 같은 경우에는 DBSCAN, 계층적 군집 등<br> <strong>모양 제약이 없는 알고리즘</strong>이 더 유리하다.</p>
</section>
</section>
<section id="군집의-품질-평가-지표" class="level2">
<h2 class="anchored" data-anchor-id="군집의-품질-평가-지표">3. 군집의 품질 평가 지표</h2>
<p>군집 해석과 군집 수 결정에서 다양한 지표가 사용된다.</p>
<section id="실루엣-계수" class="level3">
<h3 class="anchored" data-anchor-id="실루엣-계수">3.1 실루엣 계수</h3>
<p><code>Silhouette Coefficient</code><br></p>
<p>개체 <img src="https://latex.codecogs.com/png.latex?i"> 에 대해<br> * <img src="https://latex.codecogs.com/png.latex?a(i)">: 같은 군집 내 평균 거리<br> * <img src="https://latex.codecogs.com/png.latex?b(i)">: 가장 가까운 다른 군집과의 평균 거리</p>
<p>실루엣 값은 다음과 같다:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0As(i)%20=%20%5Cfrac%7Bb(i)%20-%20a(i)%7D%7B%5Cmax%20%7Ba(i),%20b(i)%7D%7D%0A"></p>
<p>실루엣 계수는 군집의 <strong>응집도(cohesion)</strong>와 <strong>분리도(separation)</strong>를 동시에 평가하는 지표이다.</p>
</section>
<section id="엘보우-기법" class="level3">
<h3 class="anchored" data-anchor-id="엘보우-기법">3.2 엘보우 기법</h3>
<p><code>Elbow Method</code><br> SSE(Sum of Squared Errors)의 감소율을 관찰하여 <strong>변곡점(elbow)</strong>을 최적 군집 개수로 간주한다.<br> 수식은 k-means 목적함수와 동일하다.</p>
<hr>
</section>
</section>
<section id="알고리즘-선택과-실무적-전처리-요건" class="level2">
<h2 class="anchored" data-anchor-id="알고리즘-선택과-실무적-전처리-요건">4. 알고리즘 선택과 실무적 전처리 요건</h2>
<p>실무에서는 단순히 거리를 계산하여 k-means를 적용하는 것이 아니라,<br> 다음과 같은 요소가 필수적으로 고려된다.</p>
<ol type="1">
<li><strong>정규화/표준화(Scaling)</strong>:<br>
<ul>
<li>변수 간 단위 차이로 인한 거리 왜곡 방지<br></li>
</ul></li>
<li><strong>차원 축소(PCA, t-SNE 등)</strong>:<br>
<ul>
<li>고차원에서의 거리 희석 현상 해결<br></li>
</ul></li>
<li><strong>거리 측정 방식 선택</strong>:<br>
<ul>
<li>텍스트 → 코사인<br></li>
<li>연속형 수치 → 유클리드<br></li>
<li>이상치 존재 → 맨해튼<br></li>
</ul></li>
<li><strong>알고리즘 선택</strong><br>
<ul>
<li>구형 군집 → k-means<br></li>
<li>임의 형태의 군집 → DBSCAN<br></li>
<li>계층적 구조 중요 → Hierarchical Clustering<br></li>
</ul></li>
</ol>
<hr>
</section>
<section id="실무-적용-분야" class="level2">
<h2 class="anchored" data-anchor-id="실무-적용-분야">5. 실무 적용 분야</h2>
<p>군집 분석은 다양한 산업 분야에서 핵심 기법으로 활용된다.</p>
<ol type="1">
<li><strong>금융</strong> <code>Finance</code><br>
<ul>
<li>신용카드 소비 패턴 분석</li>
<li>리스크 기반 고객 세그멘테이션</li>
<li>사기 탐지(비정상 패턴 발견)</li>
</ul></li>
<li><strong>마케팅</strong> <code>Marketing</code><br>
<ul>
<li>고객 세분화(Customer Segmentation)</li>
<li>구매 행동 기반 타겟 마케팅</li>
<li>추천 시스템의 사용자 군집화</li>
</ul></li>
<li><strong>헬스케어</strong> <code>Healthcare</code><br>
<ul>
<li>환자 유형 분류</li>
<li>질병 패턴 분석</li>
<li>개인 맞춤형 치료 전략 개발</li>
</ul></li>
<li><strong>제조업</strong> <code>Manufacturing</code><br>
<ul>
<li>불량 패턴 탐지</li>
<li>공정 조건 기반 군집화</li>
<li>유지보수(Preventive Maintenance) 최적화</li>
</ul></li>
</ol>
<p>군집 분석은 특히 <strong>세그멘테이션(Segmentation)</strong> 분야에서 실무적 가치가 매우 높다.</p>
<hr>
</section>
</section>
<section id="계층적-군집-분석" class="level1">
<h1>02. 계층적 군집 분석</h1>
<p><code>Hierarchical Clustering</code><br> 비지도 학습(Unsupervised Learning)의 대표적 기법으로,<br> 개체 간 <strong>유사도</strong> 또는 <strong>거리(distance)</strong> 정보를 기반으로 군집을 단계적으로 형성하거나 분해하여 데이터의 구조적 관계를 탐색하는 데 사용된다.<br></p>
<p>계층적 군집 분석은 다음 두 방식으로 구분된다. * <strong>병합적(Agglomerative)</strong> 방식 * <strong>분할적(Divisive)</strong> 방식 <br></p>
<p>이 중 실무와 연구 대부분에서는 <strong>계산이 단순하고 직관적</strong>이라는 이유로 <strong>병합적 방법</strong>이 가장 널리 사용된다. 병합적 방법을 <strong>계보적 군집 분석(Agglomerative Hierarchical Clustering)</strong>이라고 부르기도 한다.<br></p>
<p>병합적 계층 군집은 모든 개체를 각각 하나의 단일 군집(singleton cluster)으로 시작한다. 이후 개체 간 거리 또는 유사도를 기준으로 가장 가까운 두 군집을 반복적으로 병합하며, 최종적으로 전체 개체가 하나의 군집이 될 때까지 과정을 이어간다. 이 과정은 <strong>덴드로그램(dendrogram)</strong>으로 시각화할 수 있어 데이터의 구조적 관계를 직관적으로 파악하는 데 도움이 된다.<br></p>
<p>또한 계층적 군집은 <strong>군집 수(K)를 사전에 지정할 필요가 없다는 점</strong>에서 탐색적 데이터 분석(Exploratory Data Analysis, EDA)에 특히 유용하다. 덴드로그램을 통해 적절한 군집 수를 시각적으로 판단할 수 있어 패턴 탐색, 구조 이해, 잠재적 그룹 확인 등에 효과적으로 활용된다.</p>
<section id="병합적-계층-군집-분석의-절차" class="level2">
<h2 class="anchored" data-anchor-id="병합적-계층-군집-분석의-절차">1. 병합적 계층 군집 분석의 절차</h2>
<section id="초기-단계" class="level3">
<h3 class="anchored" data-anchor-id="초기-단계">1.1 초기 단계</h3>
<p>분석 대상 개체가 <img src="https://latex.codecogs.com/png.latex?n"> 개라고 할 때, 초기에는 모든 개체가 단독 군집으로 간주된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AC_1%20=%20%7Bx_1%7D,%20C_2%20=%20%7Bx_2%7D,%20%5Cldots,%20C_n%20=%20%7Bx_n%7D%0A"></p>
<p>이후 각 군집 간 거리(유사성)가 거리 행렬(distance matrix)로 표현되며,<br> 이 행렬은 군집 병합 과정에서 매 단계 재계산된다.</p>
</section>
<section id="단계별-병합algo-과정" class="level3">
<h3 class="anchored" data-anchor-id="단계별-병합algo-과정">1.2 단계별 병합(algo) 과정</h3>
<p>각 단계에서는 다음 두 규칙이 반복적으로 적용된다.<br></p>
<ol type="1">
<li><p><strong>현재 존재하는 모든 군집 쌍 중 가장 가까운 군집을 찾는다.</strong> <img src="https://latex.codecogs.com/png.latex?%0A(C_p,%20C_q)=%5Carg%5Cmin_%7BC_i,%20C_j%7D%20d(C_i,C_j)%0A"></p></li>
<li><p><strong>해당 두 군집을 하나의 군집으로 병합한다.</strong> <img src="https://latex.codecogs.com/png.latex?%0AC_%7Bnew%7D=C_p%20%5Ccup%20C_q%0A"></p></li>
<li><p><strong>병합 후, 새로운 군집과 다른 군집 간의 거리를 ’연결법(Linkage Method)’에 따라 재계산한다.</strong><br> 이 과정이 반복되어 최종적으로 하나의 군집으로 통합된다. <img src="https://latex.codecogs.com/png.latex?%0An%20%5Crightarrow%20n-1%20%5Crightarrow%20n-2%20%5Crightarrow%20%5Ccdots%20%5Crightarrow%201%0A"></p></li>
</ol>
<p>이러한 병합 과정을 시각적으로 나타낸 것이 <strong>덴드로그램(Dendrogram)</strong>이며,<br> 수평선의 높이(height)는 해당 병합 단계에서의 군집 간 거리 혹은 이질성(Heterogeneity)을 나타낸다.</p>
</section>
</section>
<section id="연결법" class="level2">
<h2 class="anchored" data-anchor-id="연결법">2. 연결법</h2>
<p><code>Linkage Methods</code><br> 군집 간 거리 계산 방식은 계층적 군집 분석의 결과에 직접적으로 영향을 미치는 핵심 요소이다.<br> 아래는 대표적 연결법들의 <strong>정의, 수학적 공식, 특징, 구조적 영향</strong>을 상세히 정리한 것이다.</p>
<section id="최단-연결법" class="level3">
<h3 class="anchored" data-anchor-id="최단-연결법">2.1 최단 연결법</h3>
<p><code>Single Linkage</code><br> 두 군집 간 최소 거리(minimum pairwise distance)를 사용한다. <img src="https://latex.codecogs.com/png.latex?%0Ad_%7B%5Ctext%7Bsingle%7D%7D(C_i,C_j)=%5Cmin_%7Bx%20%5Cin%20C_i,,%20y%20%5Cin%20C_j%7D%20d(x,y)%0A"></p>
<p><strong>특징:</strong> * <strong>Chain Effect(사슬 현상)</strong> 발생 가능성이 높음 (길게 늘어지는 패턴이 나타나며, 여러 개체가 얇은 줄처럼 연결되어 있는 구조) * 개별 데이터들이 사슬처럼 연결되어 길게 늘어난 형태의 군집이 형성될 수 있음 * 군집 모양 취약: 좁고 길게 늘어진(Elongated) 군집에서는 적합하지 않음 * 잡음과 이상치 민감: 외곽 점(outlier)에 의해 군집 구조가 쉽게 왜곡됨</p>
<p><strong>실무적 주의:</strong> * 단순 거리만 고려하므로, 실제 데이터의 밀도나 분포를 충분히 반영하지 못할 수 있음 * 군집 결과가 직관적이지 않거나 왜곡될 수 있으므로, 데이터 특성을 고려하여 다른 연결법과 병행 평가 필요</p>
</section>
<section id="최장-연결법" class="level3">
<h3 class="anchored" data-anchor-id="최장-연결법">2.2 최장 연결법</h3>
<p><code>Complete Linkage</code><br> 두 군집 간 최대 거리(maximum pairwise distance)를 사용한다. <img src="https://latex.codecogs.com/png.latex?%0Ad_%7B%5Ctext%7Bcomplete%7D%7D(C_i,C_j)=%5Cmax_%7Bx%20%5Cin%20C_i,,%20y%20%5Cin%20C_j%7D%20d(x,y)%0A"></p>
<p><strong>특징:</strong> * 군집 내부가 조밀(compact)하게 유지됨 (각 군집 내 데이터 간 최대 거리를 고려하기 때문) * 이상치와 잡음의 영향을 Single linkage 대비 상대적으로 덜 받음 (<strong>균형 잡힌 군집 구조(Balanced Cluster Structure)</strong> 생성) * 덴드로그램 상에서 병합 높이가 일정하게 유지되어 구조가 시각적으로 균형 있게 나타남</p>
<p><strong>실무적 고려:</strong> * 분류 경계가 명확해야 하는 경우 유용 * 군집 간 거리 기준이 엄격하여, 너무 작은 군집이 과도하게 분리되는 경우 주의 필요</p>
</section>
<section id="평균-연결법" class="level3">
<h3 class="anchored" data-anchor-id="평균-연결법">2.3 평균 연결법</h3>
<p><code>Average Linkage / UPGMA</code><br> 군집 간 모든 개체 쌍의 거리 평균을 사용한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad_%7B%5Ctext%7Baverage%7D%7D(C_i,C_j)%0A=%20%5Cfrac%7B1%7D%7B%7CC_i%7C%5Ccdot%20%7CC_j%7C%7D%0A%5Csum_%7Bx%5Cin%20C_i%7D%5Csum_%7By%5Cin%20C_j%7D%20d(x,y)%0A"></p>
<p><strong>특징:</strong> * 군집 간 전체적 거리 구조를 반영 (단일 연결법의 사슬 현상 + 최장 연결법의 지나친 조밀화를 완화) * 극단적 이상치에 대한 민감도가 단일/최장 연결법보다 낮음 * 평균 기반 병합으로 군집 내 구조를 보다 세밀하게 반영 * 모든 데이터 쌍의 평균 거리 기반으로 병합이 이루어짐 * 병합 높이가 극단적으로 치우치지 않고, 일정한 간격을 유지하며 균형 있는 시각적 구조를 보여줌</p>
</section>
<section id="중심-연결법" class="level3">
<h3 class="anchored" data-anchor-id="중심-연결법">2.4 중심 연결법</h3>
<p><code>Centroid Linkage</code><br> 각 군집의 중심(centroid)을 계산한 뒤 중심 간 거리로 측정.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7B%EA%B5%B0%EC%A7%91%7D%20C_i%20%5Ctext%7B%EC%9D%98%20%EC%A4%91%EC%8B%AC%7D:%20%5Cmu_i=%5Cfrac%7B1%7D%7B%7CC_i%7C%7D%5Csum_%7Bx%5Cin%20C_i%7D%20x%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7B%EA%B5%B0%EC%A7%91%20%EA%B0%84%20%EA%B1%B0%EB%A6%AC%7D:%20d_%7B%5Ctext%7Bcentroid%7D%7D(C_i,C_j)=%7C%5Cmu_i-%5Cmu_j%7C%0A"></p>
<p><strong>특징:</strong> * 중심 계산과 거리 계산이 행렬 연산으로 처리 가능하여 구현 용이 * 군집이 선형적으로 분리되거나 중심 기반 구조가 뚜렷한 경우 성능이 우수 * 중심만 계산하면 되므로, 반복 연산이 많은 대규모 데이터에서 계산이 비교적 효율적 * 중심 이동으로 인해 Single/Complete/Average보다 덴드로그램의 구조가 덜 안정적일 수 있음 * 역병합(Reversal) 발생 가능성 높음 (군집 병합 후 새로운 중심이 기존 거리 구조를 뒤흔들어 덴드로그램 높이가 역전되는 비단조성(non-monotonicity) 문제가 발생하기 쉬움) * 컷(cut) 기준의 주관성 (덴드로그램의 높이가 단조 증가하지 않아, 군집 수 결정 시 절단 시점 판단이 더 주관적일 수 있음)</p>
</section>
<section id="중위수-연결법" class="level3">
<h3 class="anchored" data-anchor-id="중위수-연결법">2.5 중위수 연결법</h3>
<p><code>Median Linkage</code><br> 두 군집 중심의 중위값(median)을 기반으로 정의하며, Centroid linkage와 유사하나 중심 계산 방법이 다르다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7B%EB%B3%91%ED%95%A9%20%ED%9B%84%20%EC%83%88%EB%A1%9C%EC%9A%B4%20%EC%A4%91%EC%8B%AC%7D:%20%5Cmu_%7Bnew%7D=%5Cfrac%7B1%7D%7B2%7D(%5Cmu_i+%5Cmu_j)%0A"></p>
<p><strong>특징:</strong> * 중위수 사용으로 극단값의 영향을 평균보다 적게 받음 (단, 전체 군집 구조 안정성 문제를 해결할 수준의 강인성(robustness)은 아님) * 중위수 기반이므로 계산 과정은 상대적으로 단순하고 구현 난이도도 낮음</p>
<ul>
<li><p>역병합(Reversal) 발생 가능성 높음 (Centroid와 마찬가지로 병합 후 새 중위수 위치가 기존 거리 구조를 비단조적으로 변화시켜 <strong>덴드로그램 높이 역전(Non-monotonicity)</strong>이 발생할 수 있음)</p></li>
<li><p>여러 연구에서 Centroid와 유사하게 군집 구조가 불안정하다는 보고가 존재 (특히 군집 분리 기준이 덴드로그램에서 명확하지 않은 경우가 잦음)</p></li>
<li><p>데이터가 비정상적 분포(heavy-tailed)거나 극단값이 많은 경우 평균 기반보다 중위수 기반이 유리할 수 있음 (그러나 덴드로그램 해석의 비단조성 문제와 불안정성 때문에 Single, Complete, Average, Ward 방식보다 권장 빈도가 현저히 낮음)</p></li>
<li><p>따라서 실무·통계 패키지에서 기본 옵션으로 잘 사용되지 않으며, 실증 연구에서도 활용 빈도가 다른 연결법 대비 매우 낮음</p></li>
</ul>
</section>
<section id="ward의-방법" class="level3">
<h3 class="anchored" data-anchor-id="ward의-방법">2.6 Ward의 방법</h3>
<p><code>Ward’s Minimum Variance Method</code><br> 군집 병합 시 전체 군집 내 오류제곱합(SSE, Within-Cluster Sum of Squares)의 증가를 최소화하는 방법.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7B%EA%B5%B0%EC%A7%91%7D%20C%20%5Ctext%7B%EC%9D%98%7D%20SSE:%20%5Cquad%20SSE(C)=%5Csum_%7Bx%5Cin%20C%7D%7Cx-%5Cmu_C%7C%5E2%0A"></p>
<p>Ward 방식은 다음을 최소화한다:<br> <img src="https://latex.codecogs.com/png.latex?%0A%5CDelta%20=%20SSE(C_i%20%5Ccup%20C_j)%20-%20(SSE(C_i)+SSE(C_j))%0A"></p>
<p><strong>특징:</strong> * <strong>가장 널리 사용되는 연결법</strong> * 군집이 구형(spherical) 형태로 형성됨 (분산 최소화 원리로 인해 밀집되고 균형 잡힌 구형 구조를 만들기 쉬움) * 단일·최장 연결법보다 이상치 영향이 적고 안정적인 군집 구조를 형성 (병합 높이(height)가 비교적 균일하게 증가 → 매우 안정적이고 해석이 쉬운 덴드로그램 구조를 제공 군집 간 병합 폭이 일정해 분기(branch)가 균형적으로 나타남) * 군집 내 제곱합 기반이라 군집 간 차이가 직관적으로 해석 가능 * k-means와 유사한 알고리즘적 성향 (분산 최소화) (둘 다 군집 내 변동을 최소화하는 방향으로 동작 → 결과 군집 형태가 유사해지는 경향.)</p>
<p><strong>실무적 고려:</strong> * 데이터가 연속형이며, 군집이 구형에 가까운 구조일 때 가장 적합 * 고차원 데이터에서도 안정적이지만, 분산 계산 특성상 변수 스케일링(표준화)이 필수 * 비구형 구조(long, chain-like cluster)를 가진 데이터에서는 과도하게 조밀한 군집이 생성될 수 있음</p>
</section>
</section>
<section id="실무적-고려-사항" class="level2">
<h2 class="anchored" data-anchor-id="실무적-고려-사항">3. 실무적 고려 사항</h2>
<p>계층적 군집 분석은 다음과 같은 실무적 특성이 존재한다.</p>
<ol type="1">
<li><strong>연산 복잡도</strong></li>
</ol>
<ul>
<li>거리 행렬 계산: <img src="https://latex.codecogs.com/png.latex?O(n%5E2)"></li>
<li>전체 병합 과정: <img src="https://latex.codecogs.com/png.latex?O(n%5E3)"> (일반적 구현 기준)<br></li>
</ul>
<p>→ 데이터가 많아지면 실무에서 <strong>수천 개 이상은 사실상 불가능</strong><br> → 샘플링, 차원 축소 병행 필요</p>
<ol start="2" type="1">
<li><strong>데이터 전처리 필요성</strong></li>
</ol>
<ul>
<li><p>거리 기반이므로 <strong>표준화(Standardization)</strong> 필수 <img src="https://latex.codecogs.com/png.latex?%0Ax'=%5Cfrac%7Bx-%5Cmu%7D%7B%5Csigma%7D%0A"></p></li>
<li><p>이상치(outlier)에 매우 민감 → 사전 처리 필요</p></li>
<li><p>고차원 데이터에서는 차원의 저주로 성능 저하 → PCA 필요</p></li>
</ul>
<ol start="3" type="1">
<li><strong>군집 수 결정</strong></li>
</ol>
<ul>
<li>덴드로그램의 컷 높이(cut height)</li>
<li>비일관성 계수(inconsistency coefficient)</li>
<li>코페네틱 상관계수(cophenetic correlation coefficient) 등 고려</li>
</ul>
<ol start="4" type="1">
<li><strong>주관성 존재</strong></li>
</ol>
<ul>
<li>덴드로그램 컷(cut height) 결정, 연결법 선택,</li>
<li>최종 군집 수 결정은 분석자의 경험과 목적에 크게 의존</li>
</ul>
<ol start="5" type="1">
<li><strong>실무 활용</strong></li>
</ol>
<ul>
<li>단위가 다른 변수는 반드시 표준화 필요</li>
<li>통계적 솔루션만 적용하면 데이터의 감성적 패턴 반영 부족</li>
<li>마케팅/금융에서 고객 세그멘테이션, 1년 단위 갱신 등 경험적 기준 적용</li>
</ul>
<ol start="6" type="1">
<li><strong>알고리즘 관점</strong></li>
</ol>
<ul>
<li>최단, 최장, 평균, 중심 연결법 결과는<br> 병합 순서나 군집 모양에서 차이가 발생하지만, 최종 그룹화 자체는 모두 유사</li>
<li>관점 차이일 뿐, 전체적인 군집 구조 탐색에는 유용함</li>
</ul>
<hr>
</section>
</section>
<section id="protein.csv" class="level1">
<h1>03 protein.csv</h1>
<hr>
</section>
<section id="k-평균-군집-분석" class="level1">
<h1>04 K-평균 군집 분석</h1>
<p><code>K-means clustering</code><br> 비지도 학습(Unsupervised Learning)의 대표적 알고리즘으로,<br> 관측값들을 K개의 군집으로 분류하는 프로토타입 기반(Prototype-based) 군집화 방법이다.<br></p>
<p>데이터의 유클리드 거리(Euclidean distance)를 활용하여 군집 중심(centroid)에<br> 가장 가까운 개체를 반복적으로 할당함으로써 군집 내 동질성을 최대화하고 군집 간 이질성을 극대화하는 것이 목적이다.<br></p>
<p>K-평균은 계산 효율이 높고 구현이 간단하며 다양한 산업 분야에서 널리 적용되어 실무적 가치가 높다.<br> 그러나 초기 중심 선택, 이상치(outlier) 민감성, 군집형태 제약(구형 구조), 변수 단위 문제 등 여러 제약을 반드시 고려해야 한다.<br></p>
<hr>
<section id="k-평균-군집의-목적-함수" class="level2">
<h2 class="anchored" data-anchor-id="k-평균-군집의-목적-함수">1. K-평균 군집의 목적 함수</h2>
<p>K-평균 알고리즘은 다음의 목적 함수(Objective Function)를 최소화하는 문제로 정의된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7BC_1,%5Cdots,C_K%7D%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20%5Csum_%7Bx_i%20%5Cin%20C_k%7D%20%7C%20x_i%20-%20%5Cmu_k%20%7C%5E2%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?C_k">: k번째 군집</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_k">: k번째 군집의 중심(centroid)</li>
<li><img src="https://latex.codecogs.com/png.latex?x_i">: 군집에 속한 데이터 포인트</li>
<li><img src="https://latex.codecogs.com/png.latex?%7Cx_i%20-%20%5Cmu_k%7C%5E2">: 유클리드 거리의 제곱</li>
<li>목적: 군집 내 제곱합(WSS, Within-Cluster Sum of Squares)의 최소화</li>
</ul>
<p>이 함수가 최소화될 때, 각 군집은 내부적으로 가장 조밀하며, 군집 간 분리는 상대적으로 크다.</p>
</section>
<section id="k-평균-알고리즘-절차" class="level2">
<h2 class="anchored" data-anchor-id="k-평균-알고리즘-절차">2. K-평균 알고리즘 절차</h2>
<p>K-평균 알고리즘의 표준 절차는 다음과 같다.</p>
<ol type="1">
<li><strong>군집 수(K)의 결정</strong> K는 사전에 사용자가 결정해야 하는 <strong>하이퍼파라미터</strong>이다.<br> 일반적으로 엘보우 기법(Elbow method), 실루엣 계수(Silhouette coefficient), Gap Statistic 등으로 후보값을 선정한다.<br></li>
</ol>
<p>특히 엘보우 기법은 실무에서 가장 흔하게 사용된다.</p>
<ol start="2" type="1">
<li><p><strong>초기 중심 선택</strong> <code>Initial Centroid</code><br> 초기 중심은 임의로 선택하거나, K-means++ 등 보다 안정적인 방법으로 선정할 수 있다.<br> 초기값에 따라 최종 군집 결과가 달라질 수 있어 초기 중심 선택은 중요한 단계이다.</p></li>
<li><p><strong>개체의 군집 할당</strong> <code>Assignment Step</code><br> 각 데이터 포인트 <img src="https://latex.codecogs.com/png.latex?x_i"> 는 가장 가까운 중심 <img src="https://latex.codecogs.com/png.latex?%5Cmu_k"> 에 할당된다.<br> 거리 계산은 일반적으로 유클리드 거리로 수행한다: <img src="https://latex.codecogs.com/png.latex?%0Ad(x_i,%20%5Cmu_k)%20=%20%5Csqrt%7B%5Csum_%7Bj=1%7D%5E%7Bp%7D%20(x_%7Bij%7D%20-%20%5Cmu_%7Bkj%7D)%5E2%7D%0A"></p></li>
</ol>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?p">: 변수의 개수</li>
</ul>
<ol start="4" type="1">
<li><strong>군집 중심 재계산</strong> <code>Update Step</code><br> 각 군집에 속한 데이터의 평균 벡터를 이용해 새로운 중심을 계산한다:</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmu_k%20=%20%5Cfrac%7B1%7D%7B%7CC_k%7C%7D%20%5Csum_%7Bx_i%20%5Cin%20C_k%7D%20x_i%0A"></p>
<p>각 개체가 추가될 때마다(혹은 반복적 재계산 과정에서) 중심값이 변동한다.</p>
<ol start="5" type="1">
<li><strong>수렴 조건 충족 시까지 반복</strong> 다음 중 하나의 조건이 충족하면 알고리즘은 종료된다.</li>
</ol>
<ul>
<li><p>중심 벡터 변화량이 특정 임계값 이하일 때 <img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmu_k%5E%7B(t+1)%7D%20-%20%5Cmu_k%5E%7B(t)%7D%7C%20%3C%20%5Cepsilon%0A"></p></li>
<li><p>일정 횟수(T) 이상 반복 수행</p></li>
<li><p>WSS 변화가 미미할 때</p></li>
</ul>
<p>이러한 반복 과정으로 K-means는 <strong>군집 내 동질성이 가장 높은 상태</strong>로 수렴한다.</p>
</section>
<section id="엘보우-기법-1" class="level2">
<h2 class="anchored" data-anchor-id="엘보우-기법-1">3. 엘보우 기법</h2>
<p><code>Elbow</code><br> 엘보우 기법은 군집 수 K를 선택하기 위한 정형화된 방법이다.</p>
<ol type="1">
<li><strong>WSS 정의</strong></li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0AWSS(K)%20=%20%5Csum_%7Bk=1%7D%5E%7BK%7D%5Csum_%7Bx_i%5Cin%20C_k%7D%7Cx_i%20-%20%5Cmu_k%7C%5E2%0A"></p>
<p>군집 수 K가 증가할수록 WSS는 감소한다.<br> 이는 군집이 나뉠수록 각 군집이 더 조밀해지기 때문이다.</p>
<ol start="2" type="1">
<li><strong>엘보우의 해석</strong></li>
</ol>
<ul>
<li>WSS는 K가 증가할수록 급격히 감소하다가,</li>
<li>어느 지점에서 감소 폭이 완만해지는 시점이 나타난다.</li>
<li>이 지점이 “엘보우(elbow)”이며 적절한 K의 후보로 간주된다.</li>
</ul>
<p>단, 엘보우는 절대적인 정답이 아니며, 실루엣 계수 등 다른 지표와 병행해야 한다.</p>
</section>
<section id="데이터-전처리와-표준화" class="level2">
<h2 class="anchored" data-anchor-id="데이터-전처리와-표준화">4. 데이터 전처리와 표준화</h2>
<p>K-평균은 거리 기반 모델이므로 변수의 단위 차이가 큰 경우 오차가 발생한다.<br> 예: 나이(20 ~ 80)와 수입(1,000 ~ 1억)이 함께 있을 경우 수입 변수가 거리 계산을 압도한다.<br></p>
<p>따라서 다음과 같은 표준화가 필요하다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax'%20=%20%5Cfrac%7Bx%20-%20%5Cmu%7D%7B%5Csigma%7D%0A"></p>
<p>표준화는 거리 측정의 공정성을 확보하지만, “정보 손실”이 있는 것은 아니며 <strong>변수의 스케일 해석이 달라지는 것</strong>이 정확한 표현이다.</p>
</section>
<section id="차원-축소" class="level2">
<h2 class="anchored" data-anchor-id="차원-축소">5. 차원 축소</h2>
<p>대부분의 실무 데이터는 3차원 이상의 다변량 구조를 가진다.<br> K-평균으로 군집을 생성한 뒤, 결과를 2차원 또는 3차원 그래프로 시각화하기 위해 차원 축소 기법(PCA, t-SNE 등)을 사용한다.</p>
<ul>
<li>PCA를 통해 고차원 공간의 분산을 보존하면서 차원을 축약</li>
<li>축약된 공간에서 각 군집을 색상(라벨)으로 표시</li>
<li>이는 군집 구조를 탐색하고 설명하는 데 유용</li>
</ul>
<p>군집 라벨은 비지도 학습의 결과이며 “예측값”이라기보다 <em>“모델이 발견한 데이터 구조에 대한 할당 결과”</em>에 가깝다.</p>
</section>
<section id="실무적-장점과-제약" class="level2">
<h2 class="anchored" data-anchor-id="실무적-장점과-제약">6. 실무적 장점과 제약</h2>
<ol type="1">
<li><strong>장점</strong></li>
</ol>
<ul>
<li>계산 효율이 매우 높음</li>
<li>대규모 데이터에 적합</li>
<li>구현이 단순하고 결과가 직관적</li>
<li>마케팅·고객 세그멘테이션·금융 데이터 분석에서 표준처럼 사용됨</li>
</ul>
<ol start="2" type="1">
<li><strong>제약</strong></li>
</ol>
<ul>
<li>구형(spherical) 군집 가정</li>
<li>비정형, 길쭉한 군집 구조에서는 부정확</li>
<li>사전에 K를 결정해야 하는 제약이 존재한다.</li>
<li>K-means++ 등의 기법을 활용해야 초기값이 안정적</li>
<li>이상치는 중심값을 크게 왜곡시켜 전체 군집 구조를 변형시킨다.</li>
</ul>
<hr>
</section>
</section>
<section id="군집수-결정-지표" class="level1">
<h1>05 군집수 결정 지표</h1>
<p>군집 분석에서는 “정답(ground truth)”이 존재하지 않기 때문에,<br> 군집 수(k)의 결정은 통계적 지표, 산술적 근거, 데이터의 특성, 실무 목적 등이 복합적으로 작용한다.<br></p>
<p>본 장에서는 군집 수 결정에 사용되는 대표적 성능 지표로 <strong>실루엣 계수(Silhouette Coefficient)</strong>, <strong>엘보우 기법(Elbow Method)</strong>, <strong>갭 통계량(Gap Statistic)</strong>을 중심으로 그 이론적 배경, 계산 방식, 해석 기준, 실무적 의사결정 요소의 중요성을 체계적으로 기술한다.</p>
<section id="실루엣-계수-1" class="level2">
<h2 class="anchored" data-anchor-id="실루엣-계수-1">1. 실루엣 계수</h2>
<p><code>Silhouette Coefficient</code><br></p>
<section id="수학적-정의" class="level3">
<h3 class="anchored" data-anchor-id="수학적-정의">1.1 수학적 정의</h3>
<p>실루엣 계수는 개별 데이터 포인트가 <strong>자신이 속한 군집과 얼마나 응집(Cohesion)</strong> 되어 있으며,<br> 동시에 <strong>다른 군집과는 얼마나 분리(Separation)</strong> 되어 있는지를 정량적으로 측정하는 지표이다.</p>
<p>특정 데이터 포인트 <img src="https://latex.codecogs.com/png.latex?i"> 에 대해 다음과 같이 정의한다.</p>
<ol type="1">
<li><p>동일 군집 내 거리 평균 <img src="https://latex.codecogs.com/png.latex?%0Aa(i)%20=%20%5Cfrac%7B1%7D%7B%7CC_i%7C-1%7D%5Csum_%7Bj%5Cin%20C_i,%20j%5Cneq%20i%7D%20d(i,j)%0A"></p></li>
<li><p>가장 가까운 외군집과의 평균거리 <img src="https://latex.codecogs.com/png.latex?%0Ab(i)%20=%20%5Cmin_%7BC_k%20%5Cne%20C_i%7D%20%5Cleft(%20%5Cfrac%7B1%7D%7B%7CC_k%7C%7D%20%5Csum_%7Bj%5Cin%20C_k%7D%20d(i,j)%20%5Cright)%0A"></p></li>
<li><p>실루엣 계수 공식 <img src="https://latex.codecogs.com/png.latex?%0As(i)=%5Cfrac%7Bb(i)-a(i)%7D%7B%5Cmax(a(i),b(i))%7D,%20%5Cquad%20%5Ctext%7B%EB%B2%94%EC%9C%84%7D:%20-1%20%5Cle%20s(i)%20%5Cle%201%0A"></p></li>
</ol>
</section>
<section id="해석-기준" class="level3">
<h3 class="anchored" data-anchor-id="해석-기준">1.2 해석 기준</h3>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?s(i)%20%5Capprox%201">: 군집이 매우 잘 형성됨 (높은 응집 + 높은 분리)</li>
<li><img src="https://latex.codecogs.com/png.latex?s(i)%20%5Capprox%200">: 군집 간 경계에 위치</li>
<li><img src="https://latex.codecogs.com/png.latex?s(i)%20%3C%200">: 잘못된 군집 배정 가능성이 높음</li>
</ul>
<p>군집 전체의 실루엣 계수는 다음과 같이 평균으로 계산한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS(k)%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5E%7Bn%7Ds(i)%0A"></p>
<p>이 값이 최대가 되는 k를 선택하는 것이 대표적 접근이다.</p>
</section>
</section>
<section id="실무-적용성과-한계" class="level2">
<h2 class="anchored" data-anchor-id="실무-적용성과-한계">1.3 실무 적용성과 한계</h2>
<p><strong>장점</strong> * 개별 포인트 단위의 군집 품질 평가 가능 * 모델 비교 가능 (예: K=2~10)</p>
<p><strong>한계</strong> * <strong>비선형 구조(예: 두 개의 링 모양)에서는 K-means와 함께 비적합</strong> * 고차원 데이터에서 거리 기반 접근의 신뢰도 저하 * 실루엣 계수가 높아도 실무 요구와 맞지 않을 수 있음(예: 비즈니스 세분화 목적이 다른 경우)</p>
</section>
<section id="엘보우-기법-2" class="level2">
<h2 class="anchored" data-anchor-id="엘보우-기법-2">2. 엘보우 기법</h2>
<p><code>Elbow Method</code>, 군집 내 응집도를 나타내는 <strong>군집 내 제곱합(WSS, Within-Cluster Sum of Squares)</strong>에 기반한다.<br></p>
<p>WSS는 다음과 같이 정의한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AWSS(k)=%5Csum_%7Bi=1%7D%5E%7Bk%7D%5Csum_%7Bx%20%5Cin%20C_i%7D%20%7C%20x%20-%20%5Cmu_i%20%7C%5E2%0A"> * <img src="https://latex.codecogs.com/png.latex?C_i">: i번째 군집 * <img src="https://latex.codecogs.com/png.latex?%5Cmu_i">: 해당 군집의 중심(centroid)</p>
<p><strong>해석 기준</strong> * WSS(k)는 k가 증가할수록 항상 감소한다. * 감소 곡선에서 <strong>기울기 변화가 급격 → 완만</strong>으로 바뀌는 지점을 “팔꿈치(Elbow)”라고 한다. * 이 지점이 <strong>적절한 군집 수 후보</strong>가 된다.</p>
<p><strong>한계</strong> * 엘보우 지점이 명확히 보이지 않는 경우가 매우 많다. * 시각적 판단 의존도가 높아 <strong>객관성이 떨어진다</strong>. * 실무에서는 “엘보우처럼 보이는 두세 지점”이 나오는 경우가 흔하며, 이를 전문가가 해석해야 한다.</p>
</section>
<section id="갭-통계량" class="level2">
<h2 class="anchored" data-anchor-id="갭-통계량">3. 갭 통계량</h2>
<p><code>Gap Statistic</code><br> 갭 통계량은 Tibshirani(2001)에 의해 제안되었으며,<br> “관측 데이터의 군집 응집도”와 “참조분포(보통 균일분포) 기반 기대치”를 비교하여 군집의 구조가 통계적으로 의미 있는지를 측정한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AGap(k)=E%5E*%5B%5Clog(W_k)%5D%20-%20%5Clog(W_k)%0A"> * <img src="https://latex.codecogs.com/png.latex?W_k">: k개의 군집으로 분할했을 때의 군집 내 분산 * <img src="https://latex.codecogs.com/png.latex?E%5E*%5B%5Ccdot%5D">: 참조 분포에서의 몬테카를로(Monte Carlo) 기준 기대값</p>
<p>값이 클수록 군집이 “랜덤한 분포보다 더 잘 분리되어 있다”는 의미이다.</p>
<p><strong>최적 k 선택 규칙</strong> Tibshirani는 다음 조건을 만족하는 최초의 k를 선택하도록 제안하였다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AGap(k)%20%5Cge%20Gap(k+1)%20-%20s_%7Bk+1%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?s_%7Bk+1%7D">: 표준오차(SE)에 기반한 보정 항</li>
</ul>
<p><strong>장점</strong> * 엘보우 기법보다 객관적 * 내재적 군집 구조를 통계적으로 검증 가능</p>
<p><strong>단점</strong> * <strong>부트스트랩 반복수가 많을수록 시간 비용이 큼</strong> * 대규모 데이터에서는 사용되지 않는 경우가 많음</p>
</section>
<section id="실무-관점의-종합적-의사결정" class="level2">
<h2 class="anchored" data-anchor-id="실무-관점의-종합적-의사결정">4. 실무 관점의 종합적 의사결정</h2>
<section id="지표-간-결과-차이의-존재" class="level3">
<h3 class="anchored" data-anchor-id="지표-간-결과-차이의-존재">4.1 지표 간 결과 차이의 존재</h3>
<p>엘보우 기법과 실루엣 계수는 서로 다른 관점에서 k를 선택하기 때문에 서로 다른 결과가 나오기 쉽다. 갭 통계량까지 고려하면 결과는 더욱 다양해진다.</p>
<p>따라서 <strong>한 가지 지표만으로 군집 수를 결정하는 것은 통계적으로 부적절</strong>하다.</p>
</section>
<section id="산업-현장에서의-실제-의사결정-방식" class="level3">
<h3 class="anchored" data-anchor-id="산업-현장에서의-실제-의사결정-방식">4.2 산업 현장에서의 실제 의사결정 방식</h3>
<p>기업의 고객군 세분화(마스터 세그멘테이션), 금융 리스크 분류, 구좌별 소비자 유형 분류 등에서는 다음의 요소가 함께 고려된다.</p>
<ol type="1">
<li>지표 값의 통계적 안정성</li>
<li>군집의 해석 가능성(Interpretability)</li>
<li>비즈니스 목적에 맞는 분류 구조</li>
<li>실무 담당자 및 도메인 전문가의 판단</li>
<li>추후 유지·갱신 가능성</li>
<li>스케일링(표준화) 여부의 영향</li>
</ol>
<p>특히,<br> * 변수 단위가 모두 다를 경우 표준화(Z-score normalization)는 필수적이다.<br> * 표준화는 “정보 손실”이 아니라 “스케일 기반 의미가 소거된다는 문제”로 해석하는 것이 정확하다.</p>
</section>
</section>
<section id="학문성과-해석의-주관성" class="level2">
<h2 class="anchored" data-anchor-id="학문성과-해석의-주관성">5. 학문성과 해석의 주관성</h2>
<p>군집 분석은 지도학습이 아니며, 통계적으로 “가장 좋은 군집”이라는 절대적 기준이 존재하지 않는다. 따라서 해석자, 전문가, 비즈니스 목적에 의해 결과가 달라진다.</p>
<p>이것이 군집 분석을 최근 연구에서 <strong>Exploratory Data Analysis(EDA)</strong> 기반 기법으로 분류하는 이유이기도 하다.</p>
<p>즉, 이론적 수학 모델은 제공된다.<br> 그러나 최종 모델 선택은 <strong>이론+실무 목적+해석의 융통성</strong>이 결합된 의사결정이다.</p>
<hr>
</section>
</section>
<section id="section" class="level1">
<h1>06</h1>
<p>분석사례 - NbClust (군집수를 결정하는 추가적인 통계량 제공) 왜 이 많은 걸 볼까? 그건 각 통계량마다 헛점들이 많기 때문이다. 만약에 2, 3가지로 봐서 명확하게 나오면 괜춘. 근데 애매하면 꼭 여러가지 기법을 총동원해서 최적의 군집을 찾고 그 성능과 신뢰도까지 보여줄 수 있어야 한다.</p>
<hr>
</section>
<section id="베이지안-gaussian-혼합-모델" class="level1">
<h1>07 베이지안 Gaussian 혼합 모델</h1>
<p><code>Bayesian Gaussian Mixture Model, Bayesian GMM</code><br></p>
<p>기존 거리 기반 방법(K-means 등)은 데이터 포인트 간의 거리 계산에 의존하지만,<br> Gaussian 혼합 모델(GMM)은 각 군집을 확률 분포로 가정하여 <strong>데이터가 각 군집에 속할 확률</strong>을 계산한다.<br></p>
<p>Bayesian GMM은 이러한 GMM을 <strong>베이지안 관점에서 확장</strong>한 모델로,<br> 군집 수에 대한 불확실성을 고려하며 데이터 기반 사전(prior)을 적용할 수 있다.<br></p>
<section id="gmm" class="level2">
<h2 class="anchored" data-anchor-id="gmm">1. GMM</h2>
<p>다변량 정규분포(Multivariate Gaussian Distribution)의 혼합으로 데이터 분포를 나타낸다.<br> 각 데이터 포인트 <img src="https://latex.codecogs.com/png.latex?x_i%20%5Cin%20%5Cmathbb%7BR%7D%5Ed"> 는 다음과 같이 확률적으로 군집에 속한다.<br></p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(x_i)%20=%20%5Csum_%7Bk=1%7D%5E%7BK%7D%20%5Cpi_k%20%5Cmathcal%7BN%7D(x_i%20%5Cmid%20%5Cmu_k,%20%5CSigma_k)%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?K"> : 군집 수</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cpi_k"> : k번째 군집의 혼합 비율 ((_{k=1}^{K} _k = 1))</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmu_k"> : k번째 군집의 평균 벡터</li>
<li><img src="https://latex.codecogs.com/png.latex?%5CSigma_k"> : k번째 군집의 공분산 행렬</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BN%7D(x_i%20%5Cmid%20%5Cmu_k,%20%5CSigma_k)"> : 다변량 정규분포 확률밀도함수</li>
</ul>
</section>
<section id="bayesian-gmm" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-gmm">2 Bayesian GMM</h2>
<p><strong>군집 수 K에 대한 불확실성을 모델링</strong>하며,<br> 사전 분포(prior)와 데이터로부터 얻은 우도(likelihood)를 결합하여 <strong>후행 분포(posterior)</strong>를 계산한다.<br></p>
<ul>
<li>혼합 비율 <img src="https://latex.codecogs.com/png.latex?%5Cpi_k"> : Dirichlet 사전 분포</li>
<li>평균 <img src="https://latex.codecogs.com/png.latex?%5Cmu_k"> : Gaussian 사전 분포</li>
<li>공분산 <img src="https://latex.codecogs.com/png.latex?%5CSigma_k"> : Inverse-Wishart 사전 분포</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(%5Cpi,%20%5Cmu,%20%5CSigma%20%5Cmid%20X)%20%5Cpropto%20p(X%20%5Cmid%20%5Cpi,%20%5Cmu,%20%5CSigma)%20,%20p(%5Cpi)%20,%20p(%5Cmu)%20,%20p(%5CSigma)%0A"></p>
<p>Bayesian 추정에서는 EM(Expectation-Maximization)과 유사한 반복적 최적화 또는 변분 추정(Variational Inference)을 사용한다.</p>
<p><strong>특징</strong> 1. 데이터 포인트마다 <strong>군집 소속 확률</strong> 제공 2. 군집 수가 명확하지 않을 때 사전 분포를 통한 <strong>자동 결정 가능성</strong> 3. <strong>특이값(outlier)에 민감</strong></p>
<ul>
<li>이유: 공분산 행렬 추정 시 이상치가 분산을 왜곡하기 때문</li>
<li>단순 거리 기반이 아니며, 확률적 분포 추정 과정에서 민감</li>
</ul>
</section>
<section id="군집-안정성-검증" class="level2">
<h2 class="anchored" data-anchor-id="군집-안정성-검증">3. 군집 안정성 검증</h2>
<p>군집 결과가 신뢰할 수 있는지 평가하기 위해 여러 방법이 사용된다.</p>
<ol type="1">
<li><strong>동일 자료에 다양한 군집 기법 적용</strong></li>
</ol>
<ul>
<li>같은 데이터셋에 K-means, GMM, 계층적 군집 분석 등 <strong>다양한 가정 기반 군집 방법</strong>을 적용</li>
<li>결과 군집이 <strong>유사하게 나타나는지 비교</strong>하여 안정성을 검증</li>
</ul>
<ol start="2" type="1">
<li><strong>데이터 분할</strong> <code>Cross-validation</code><br></li>
</ol>
<ul>
<li>데이터셋을 임의로 두 부분으로 분할</li>
<li>각 부분을 독립적으로 군집 분석 수행</li>
<li><strong>군집 구조가 일관되게 나타나는지</strong> 확인</li>
</ul>
<ol start="3" type="1">
<li><strong>변수 제거/추가</strong> <code>Sensitivity Analysis</code><br></li>
</ol>
<ul>
<li>일부 변수를 제거하거나 추가하여 군집 분석 수행</li>
<li><strong>군집 구조가 어떻게 변화하는지</strong> 관찰</li>
<li>특정 변수에 과도하게 의존하는 군집인지 평가 가능</li>
</ul>
<ol start="4" type="1">
<li><strong>실무 적용</strong></li>
</ol>
<ul>
<li><p>Bayesian GMM은 <strong>다중 패턴이 혼합된 데이터</strong><br> 예: 고객 세분화, 금융 리스크 평가, 헬스케어 환자 그룹 분류에 적합</p></li>
<li><p>안정성 검증 방법은 <strong>실무 데이터 분석에서 필수적</strong></p>
<ul>
<li>데이터 분할, 변수 제거/추가, 다른 알고리즘 비교를 통해 신뢰성 확보</li>
</ul></li>
<li><p>모델 복잡도가 높으므로, <strong>분석 목적, 데이터 특성, 해석 가능성</strong>을 함께 고려해야 함</p></li>
</ul>
<hr>
<p>파셜 주성분 분석.(교수님 박사 논문)</p>


</section>
</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/dap/dap_02.html</guid>
  <pubDate>Mon, 17 Nov 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>6장: 감성 분석</title>
  <dc:creator>파이썬기반 SNS텍스트 데이터마이닝 개정판</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/tm/tm_06_1.html</link>
  <description><![CDATA[ 





<p>감성분석에 대해 다루고자 한다.</p>
<p>01 감성 사전 다운</p>
<p>1 . KNU</p>
<p>GitHub - park1200656/KnuSentiLex: KNU(케이앤유) 한국어 감성사전</p>
<p>KNU(케이앤유) 한국어 감성사전. Contribute to park1200656/KnuSentiLex development by creating an account on GitHub.</p>
<p>github.com import json</p>
<p>file_path = r’C:-master-master_info.json’</p>
<p>with open(file_path, ‘r’, encoding=‘utf-8’) as f: json_data = json.load(f)</p>
<section id="단어-리스트-생성" class="level1">
<h1>단어 리스트 생성</h1>
<p>word_list = [] for item in json_data: # 리스트 반복 word_txt = item[‘word’] word_list.append(word_txt)</p>
</section>
<section id="결과-출력-앞-10개만-보기" class="level1">
<h1>결과 출력 (앞 10개만 보기)</h1>
<p>print(word_list[:10])</p>
<p>2 . KoreanSentimentAnalyzer</p>
<p>GitHub - mrlee23/KoreanSentimentAnalyzer: 한국어 감성 분석기</p>
<p>한국어 감성 분석기. Contribute to mrlee23/KoreanSentimentAnalyzer development by creating an account on GitHub.</p>
<p>github.com import pandas as pd</p>
</section>
<section id="파일-경로" class="level1">
<h1>파일 경로</h1>
<p>file_path = r’C:-master-master.csv’</p>
</section>
<section id="csv-파일-읽기" class="level1">
<h1>CSV 파일 읽기</h1>
<p>senti_df = pd.read_csv(file_path, encoding=‘utf-8’) # 또는 encoding=‘cp949’ senti_df.head()</p>
<p>import pickle</p>
</section>
<section id="파일-저장-위치" class="level1">
<h1>파일 저장 위치</h1>
<p>file_path = r’C:\’</p>
</section>
<section id="doc_topic과-comment_topic이-포함된-파일" class="level1">
<h1>doc_topic과 comment_topic이 포함된 파일</h1>
<p>f = open(file_path + ‘topic_doc.pkl’, “rb”) # 데이터 불러오기 data = pickle.load(f) f.close()</p>
<p>data # 문서 전체의 명사 리스트 확보</p>
<p>KNU 감성사전을 이용해서 텍스트 데이터에 감정 점수를 부여하는 Python 스크립트입니다. 각 텍스트가 긍정적인지, 부정적인지, 중립적인지를 파악하기 위해 사용됩니다.</p>
<p>import json import pandas as pd from tqdm import tqdm</p>
</section>
<section id="감정분석-json-데이터-knu-감성사전-불러오기" class="level1">
<h1>감정분석 JSON 데이터 (KNU 감성사전) 불러오기</h1>
<p>file_path = r’C:-master-master’</p>
<p>with open(file_path + r’_info.json’, encoding=‘UTF-8’) as json_file: sentiword = json.load(json_file)</p>
</section>
<section id="감성-단어-리스트-및-점수-초기화" class="level1">
<h1>감성 단어 리스트 및 점수 초기화</h1>
<p>s_word = [] values = [] score = []</p>
</section>
<section id="평균-계산-함수" class="level1">
<h1>평균 계산 함수</h1>
<p>def average(lst): return sum(lst) / len(lst)</p>
<p>텍스트에서 감성 단어 찾고 점수 계산</p>
</section>
<section id="감성-점수-계산" class="level1">
<h1>감성 점수 계산</h1>
<p>for word in tqdm(data[‘doc’]): temp_s_word = [] # 본문에서 가져옴 temp_value = []</p>
<pre><code>for s in sentiword:
    if s['word'] in word:
        temp_s_word.append(s['word'])
        temp_value.append(int(s['polarity']))

s_word.append(temp_s_word)
values.append(temp_value)

if len(temp_value) &gt; 0:
    score.append(average(temp_value))
else:
    score.append(0)</code></pre>
</section>
<section id="결과-삽입" class="level1">
<h1>결과 삽입</h1>
<p>data = data.assign(sentiword=s_word, values=values, score=score) data</p>
<p>가상 공간 안에서만 있는 것, 이를 저장 함.</p>
<p>import pickle import pandas as pd</p>
</section>
<section id="저장" class="level1">
<h1>저장</h1>
<p>file_path = r’C:\’ with open(file_path + “total_docs_KNU.pkl”, “wb”) as f: pickle.dump(data, f)</p>
</section>
<section id="불러오기" class="level1">
<h1>불러오기</h1>
<p>with open(file_path + “total_docs_KNU.pkl”, “rb”) as f: ff = pickle.load(f)</p>
</section>
<section id="데이터프레임-복원" class="level1">
<h1>데이터프레임 복원</h1>
<p>total_docs = pd.DataFrame() total_docs[‘doc’] = ff[‘doc’] total_docs[‘doc_token_noun’] = ff[‘doc_token_noun’] total_docs[‘doc_topic’] = ff[‘doc_topic’] total_docs[‘comment_topic’] = ff[‘comment_topic’] total_docs[‘sentiword’] = ff[‘sentiword’] total_docs[‘values’] = ff[‘values’] total_docs[‘score’] = ff[‘score’]</p>
<p>total_docs</p>
<p>doc_token_noun의 모든 단어가 감성 단어가 아니다. 그들 중 감성 단어를 sentiword로 불러온 것.</p>
<p>from wordcloud import WordCloud import matplotlib.pyplot as plt</p>
</section>
<section id="폰트-경로-windows용-예시---나눔고딕" class="level1">
<h1>폰트 경로 (Windows용 예시 - 나눔고딕)</h1>
<p>font_path = r”C:.otf”</p>
</section>
<section id="토픽-개수만큼-반복" class="level1">
<h1>토픽 개수만큼 반복</h1>
<p>num_topics = total_docs[‘doc_topic’].nunique()</p>
<p>for topic_num in range(num_topics): # 해당 토픽의 문서 필터링 topic_docs = total_docs[total_docs[‘doc_topic’] == topic_num]</p>
<pre><code># 토큰 리스트를 하나로 합치기 (flatten)
all_tokens = sum(topic_docs['doc_token_noun'], [])

# 문자열로 변환 (공백으로 연결)
text = ' '.join(all_tokens)

# 워드클라우드 생성
wordcloud = WordCloud(font_path=font_path, background_color='white', width=800, height=400).generate(text)

# 시각화
plt.figure(figsize=(10, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title(f"Topic {topic_num} Word Cloud", fontsize=16)</code></pre>
<p>이 코드는 감성 점수(score)를 기준으로 각 토픽(doc_topic)에 대해 감정 분포를 분류하고 있습니다.</p>
<p>if score &gt; 0.3: # 긍정 elif -0.3 &lt;= score &lt;= 0.3: # 중립 else: # 부정 여기서 “0.3”과 “-0.3”이라는 기준은 <strong>사용자가 임의로 정한 값 (threshold)</strong>입니다. → 즉, 이 기준이 정해진 절대값이 아니라, → 분석 목적에 따라 조정해야 하는 값이에요.</p>
<p>🧠 사용자가 결정해야 할 것들 score의 값 범위가 어떻게 구성되어 있는가? 감성 점수가 -2 ~ 2인지, -1 ~ 1인지, -5 ~ 5인지 먼저 확인해야 합니다. 0.3이 의미 있는 경계값인가? 감성 점수의 분포가 대부분 -0.1 ~ 0.1이라면, 0.3은 너무 높은 기준일 수 있습니다. 반대로 감성 점수 범위가 크다면, 0.3은 너무 낮은 기준일 수 있죠. 목표에 따라 기준이 달라질 수 있음 예를 들어: 마케팅 분석이라면 조금만 긍정적이어도 긍정으로 간주 감정 민감도 분석이라면 더 엄격한 기준 적용 필요</p>
<p>코드에서 senti_0 = [0, 0, 0, 0, 0, 0] 의미 이 리스트는 <strong>특정 토픽(topic 0, topic 1 등)</strong>에 대한 감성 점수 분포를 저장하려고 만든 것입니다. 즉, 각 인덱스가 감정의 강도나 구간을 나타냅니다.</p>
<p>0 매우 긍정 1 긍정 2 중립 3 부정 4 매우 부정 5 기타 / 미정 (혹은 사용자 정의) 그런데 본문 코드에서는 실제로는 0, 2, 4만 사용되고 있죠? 이건 중간 단계일 가능성도 있고, 나중에 더 구체적인 등급으로 확장하기 위해 미리 6칸 확보해둔 것일 수도 있어요.</p>
<p>🧠 핵심 포인트 senti_0, senti_1은 토픽별 감정 분포를 담기 위한 그릇입니다. 토픽이 더 늘어나면? → senti_2, senti_3, … 식으로 계속 만들어야겠죠. 또는 다음처럼 딕셔너리 구조로 더 깔끔하게 관리할 수도 있어요: senti_dict = {i: [0, 0, 0, 0, 0, 0] for i in total_docs[‘doc_topic’].unique()} ✅ 요약 항목 설명</p>
<p>senti_0, senti_1 토픽별 감정 분포 저장용 리스트 길이 6 감정 강도 6단계로 분류하려는 구조 (0~5) 사용자 정의 가능 목적에 따라 개수, 의미를 직접 설정 필요하시면 이 구조를 자동화해서 n개의 토픽에 대해 감정 분포를 계산하는 코드도 만들어드릴 수 있어요. 원하시나요?</p>
<p>긍정 / 중립 / 부정의 빈도와 비율을 토픽별로 확인하려는 거군요.</p>
<p>각 토픽(topic)마다 긍정: score &gt; 0.3 중립: -0.3 ≤ score ≤ 0.3 부정: score &lt; -0.3 해당 범주의 빈도수와 <strong>비율(%)</strong>을 구하기</p>
<p>감정 빈도 doc_topic negative neutral positive</p>
<p>0 12 56 32 1 8 30 62</p>
<p>감정 비율 (%) doc_topic negative neutral positive</p>
<p>0 12.0 56.0 32.0 1 8.0 30.0 62.0</p>
</section>
<section id="토픽별-감성-점수-분류-리스트-초기화-긍정-중립-부정" class="level1">
<h1>토픽별 감성 점수 분류 리스트 초기화 (긍정, 중립, 부정)</h1>
<p>senti_0 = [0, 0, 0, 0, 0, 0] senti_1 = [0, 0, 0, 0, 0, 0] senti_2 = [0, 0, 0, 0, 0, 0] senti_3 = [0, 0, 0, 0, 0, 0]</p>
<p>for i in range(len(total_docs)): topic = total_docs[‘doc_topic’].iloc[i] score = total_docs[‘score’].iloc[i]</p>
<pre><code>if topic == 0:
    if score &gt; 0.3:
        senti_0[0] += 1
    elif -0.3 &lt;= score &lt;= 0.3:
        senti_0[2] += 1
    else:
        senti_0[4] += 1

elif topic == 1:
    if score &gt; 0.3:
        senti_1[0] += 1
    elif -0.3 &lt;= score &lt;= 0.3:
        senti_1[2] += 1
    else:
        senti_1[4] += 1</code></pre>
<p>for i in range(len(total_docs)): topic = total_docs[‘comment_topic’].iloc[i] score = total_docs[‘score’].iloc[i]</p>
<pre><code>if topic == 0:
    if score &gt; 0.3:
        senti_2[0] += 1
    elif -0.3 &lt;= score &lt;= 0.3:
        senti_2[2] += 1
    else:
        senti_2[4] += 1

elif topic == 1:
    if score &gt; 0.3:
        senti_3[0] += 1
    elif -0.3 &lt;= score &lt;= 0.3:
        senti_3[2] += 1
    else:
        senti_3[4] += 1</code></pre>
<p>지금 작성하신 코드는 토픽별 감정 분포 리스트에서 비율(%)을 1칸씩 띄워서 저장하는 방식입니다.</p>
<p>📦 구조 요약 senti_0 = [긍정_빈도, 긍정_비율, 중립_빈도, 중립_비율, 부정_빈도, 부정_비율]</p>
<p>인덱스 0, 2, 4: 빈도수 (count) 인덱스 1, 3, 5: 비율 (ratio, 혹은 percentage) 🔁 반복문 설명 for i in range(1, 7, 2): # i는 1, 3, 5 i-1 → 현재 비율을 계산할 빈도 인덱스 i → 비율을 저장할 인덱스 분모는 전체 감정의 합: 긍정 + 중립 + 부정 즉, 예를 들어:</p>
<p>senti_0[1] = senti_0[0] / (senti_0[0] + senti_0[2] + senti_0[4]) 이건 긍정 비율, 그다음 senti_0[3]은 중립 비율, senti_0[5]는 부정 비율이 되는 식입니다.</p>
</section>
<section id="감성-클래스별-비율-계산-분모가-0일-경우-예외-처리-추가" class="level1">
<h1>감성 클래스별 비율 계산 (분모가 0일 경우 예외 처리 추가)</h1>
<p>for i in range(1, 7, 2): if (senti_0[0] + senti_0[2] + senti_0[4]) != 0: senti_0[i] = senti_0[i-1] / (senti_0[0] + senti_0[2] + senti_0[4]) else: senti_0[i] = 0 # 분모가 0이면 비율을 0으로 설정</p>
<pre><code>if (senti_1[0] + senti_1[2] + senti_1[4]) != 0:
    senti_1[i] = senti_1[i-1] / (senti_1[0] + senti_1[2] + senti_1[4])
else:
    senti_1[i] = 0  # 분모가 0이면 비율을 0으로 설정

if (senti_2[0] + senti_2[2] + senti_2[4]) != 0:
    senti_2[i] = senti_2[i-1] / (senti_2[0] + senti_2[2] + senti_2[4])
else:
    senti_2[i] = 0  # 분모가 0이면 비율을 0으로 설정

if (senti_3[0] + senti_3[2] + senti_3[4]) != 0:
    senti_3[i] = senti_3[i-1] / (senti_3[0] + senti_3[2] + senti_3[4])
else:
    senti_3[i] = 0  # 분모가 0이면 비율을 0으로 설정</code></pre>
</section>
<section id="토픽별-감성-비율-데이터프레임-생성" class="level1">
<h1>토픽별 감성 비율 데이터프레임 생성</h1>
<p>graph = pd.DataFrame( [senti_0, senti_1, senti_2, senti_3], index=[‘topic1’, ‘topic2’, ‘topic3’, ‘topic4’], columns=[[‘긍정’, ‘긍정’, ‘중립’, ‘중립’, ‘부정’, ‘부정’], [‘빈도’, ‘비율’, ‘빈도’, ‘비율’, ‘빈도’, ‘비율’]] )</p>
<p>graph</p>
<p>🔍 왜 워드클라우드와 감정 점수(혹은 분류) 결과가 다를 수 있는가? 1. 워드클라우드는 감성 단어 필터 없이 모든 단어 사용 일반적으로 워드클라우드는 특정 토픽에서 자주 등장한 단어의 빈도만을 시각화합니다. 이 과정에서 감성 사전에 없는 <strong>중립 단어, 불용어(의미 없는 단어)</strong>들도 포함될 수 있습니다. 따라서 시각적으로 중요한 단어처럼 보여도 감성 점수 계산에서는 무시될 수 있습니다. 2. KNU 감성사전 기반 감정 점수는 ’등록된 감성 단어’만 사용 예: 좋다, 싫다, 기쁘다, 화나다 등만 감성 점수로 환산됨. 감성 사전에 없는 단어는 아무리 많이 나와도 score에 기여하지 않음. 3. 토픽의 특성과 감성 단어 간 연관성 결여 예를 들어, 주제는 부정적인 사건이라도 직접적으로 부정 단어(예: “나쁘다”, “불편하다”)가 없을 수 있음. 이 경우 토픽 자체는 부정적으로 보이지만, 감성 점수는 중립 혹은 긍정이 나올 수 있습니다. 4. 토픽 내 감성 단어 비율이 낮은 경우 감성 점수를 계산할 때 사용하는 감성 단어 수가 전체 단어에 비해 매우 적다면, score의 분포도 좁거나 왜곡될 수 있습니다. 이로 인해 score는 0 근처로 몰리거나, 예외적으로 높은 감성 단어 하나에 과도하게 영향받을 수 있습니다. ✅ 요약 요소특징감성 점수에 반영됨? 워드클라우드 주요 단어 빈도가 높은 모든 단어 ❌ 감성 단어만 반영됨 감정 점수(score) 감성사전에 있는 단어 기반 ✅ 해당 단어만 반영됨 감정 판단 정확도 단어 수, 감성 단어 존재 여부에 민감 상황에 따라 다름</p>
<p>💡 개선 팁 워드클라우드 만들 때 감성 단어만 필터링해서 시각화할 수도 있습니다. python 복사편집 sentiment_words = [s[‘word’] for s in sentiword] topic_words = [word for word in topic_docs if word in sentiment_words] 감성 점수 외에도 TF-IDF 기반 상위 감성 단어 추출도 좋은 방법입니다. 감성 점수 분포와 함께 워드클라우드 결과를 비교 분석하면 더 풍부한 인사이트를 얻을 수 있습니다.</p>
<p>01 감성 사전 다운</p>
<p>1 . NRC</p>
<p>NRC Emotion Lexicon</p>
<p>Impact Some notable ways in which the NRC Emotion Lexicon has made impact include: First of its kind: It was the first word-emotion association lexicon, with entries for eight basic emotions as well as positive and negative sentiment. It still remains the</p>
<p>saifmohammad.com</p>
<p>이 코드는 <strong>NRC 감성사전 (Korean NRC Emotion Lexicon)</strong>을 기반으로 각 문서의 감정값을 계산하는 과정입니다. 간단히 말하면, 문서에 등장하는 감성 단어를 찾아서 해당 감정 점수를 누적하는 구조입니다.</p>
<p>아래에 코드의 의미를 단계별로 설명드리겠습니다:</p>
<p>🔢 코드 설명 for i in range(1, len(nrc)): # NRC 감성사전의 각 단어에 대해 반복 nrc: NRC 감성사전을 담은 DataFrame입니다. nrc[‘Korean Word’]: 감성사전에 있는 한국어 단어. range(1, len(nrc)): 아마 첫 번째 행(헤더 또는 불필요한 데이터)을 생략하고자 1부터 시작한 것 같습니다. if nrc[‘Korean Word’][i] in word: 현재 문서(word)에 감성사전의 단어가 포함되어 있는지 확인. if len(nrc[‘Korean Word’][i]) &gt; 1: 글자 수가 1자인 경우(ex. “다”, “게”)는 보통 의미가 불분명하거나 너무 일반적이라 제외. 따라서 두 글자 이상인 감성 단어만 사용. temp_s_word.append(nrc[‘Korean Word’][i]) 해당 감성 단어를 temp_s_word 리스트에 저장 (이 문서에서 발견된 감성 단어 목록). b = list(map(int, nrc.iloc[i, 1:11].tolist())) nrc.iloc[i, 1:11]: 해당 단어에 대한 감정 점수들 (예: 긍정, 부정, 분노, 기쁨 등 10가지 감정). map(int, …): 감정 점수들이 문자열로 되어 있다면 정수로 변환. 결과적으로 b는 해당 단어의 10개 감정 점수 리스트. temp_value = [x + y for x, y in zip(temp_value, b)] temp_value: 현재 문서에서 감정 점수를 누적하는 리스트. b를 더해가며 문서 전체의 감정 점수를 계산. 🔍 이 코드의 목적 NRC 감성사전 기반 다중 감정 분석입니다. 단순히 긍·부정 점수만 계산하는 것이 아니라, 여러 감정 카테고리(기쁨, 슬픔, 분노 등)의 누적 점수를 구해서 문서의 감정 프로파일을 생성합니다.</p>


</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/tm/tm_06_1.html</guid>
  <pubDate>Mon, 19 May 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>6장: 감성 분석</title>
  <dc:creator>파이썬기반 SNS텍스트 데이터마이닝 개정판</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/tm/tm_06_0.html</link>
  <description><![CDATA[ 





<p>감성분석에 대해 다루고자 한다.</p>
<p>01 제목1 [ID 사용하기] 감성 사전, 말에는 감성이 있다. 단어에 관한 감성 분석, 태도, 성향, 의견 한 개인의 감정이라도 이것도 많아지면 사람들이 생각하는 한 방향이 됨</p>
<p>극성, 과학에서 말하는 극성</p>
<p>어휘 기반은 수동으로 구축, 도메인(산업군, 어떤 카테고리 또는 영역인가?) 같은 언어, 단어가 도메인에 따라 다른 감성을 가질 수 있다.</p>
<p>사전 기반은 이미 누군가가 만들어 놓은 감성 사전을 사용하는 것</p>
<p>한국어 사전, 한국어, 국문학을 전공한 사람들이 참여했을 것이다. 리커트 척도? 보통이라는 의미를 담는 3점을 고른 생각이 같지 않을 것이라는 것이다. 정량적인 분석이 가능해야 리커트 척도라고 볼 수 있다. 즉, 각 등간 간격이 모두 동일해야 한다는 것이다.</p>
<p>디테일하게 보고 싶으면 에뮬렉스를 사용.</p>
<p>1 . 제목2 감성 분석을 위해 군산대학교 감성사전 웹사이트를 참고한다.</p>
<p>KNU 한국어 감성사전</p>
<p>dilab.kunsan.ac.kr</p>
<p>또는 깃허브로 바로 이동해도 된다.</p>
<p>GitHub - park1200656/KnuSentiLex: KNU(케이앤유) 한국어 감성사전</p>
<p>KNU(케이앤유) 한국어 감성사전. Contribute to park1200656/KnuSentiLex development by creating an account on GitHub.</p>
<p>github.com</p>
<p>이 사이트는 다음과 같은 이유로 감성 분석에 유용하다.</p>
<p>KNUSL 감성 사전의 특징 국내에서 구축한 한글 감성 어휘 사전으로, 한국어 감성 분석에 특화되어 있다. 각 단어에 감성 점수(긍정/부정/중립 등급)를 부여할 수 있다. 다양한 도메인(예: 리뷰, 뉴스 등)에 맞춘 감성 어휘 제공한다. 데이터는 연구 및 학습 목적으로 자유롭게 다운로드 가능 (단, 출처 명시 필요)</p>
<p>Download ZIP 클릭.</p>
<p>다운로드 된 파일 압축 풀기.</p>
<p>data 폴더로 들어간 다음 SentiWord_info 파일 경로 복사하기</p>
<p>감성 사전 JSON 파일을 읽어서 단어만 추출해보기.</p>
<p>import json</p>
<p>file_path = r’C:-master-master_info.json’</p>
<p>with open(file_path, ‘r’, encoding=‘utf-8’) as f: json_data = json.load(f)</p>
<section id="단어-리스트-생성" class="level1">
<h1>단어 리스트 생성</h1>
<p>word_list = [] for item in json_data: # 리스트 반복 word_txt = item[‘word’] word_list.append(word_txt)</p>
</section>
<section id="결과-출력-앞-10개만-보기" class="level1">
<h1>결과 출력 (앞 10개만 보기)</h1>
<p>print(word_list[:10])</p>
<p>KOSAC 감성사전 다운로드</p>
<p>GitHub - mrlee23/KoreanSentimentAnalyzer: 한국어 감성 분석기</p>
<p>한국어 감성 분석기. Contribute to mrlee23/KoreanSentimentAnalyzer development by creating an account on GitHub.</p>
<p>github.com</p>
</section>
<section id="values-긍정부정중립" class="level1">
<h1>values 긍정부정중립</h1>
<p>01 제목1 [ID 사용하기]</p>
<p>1 . 제목2</p>
<p>NRC Emotion Lexicon</p>
<p>Impact Some notable ways in which the NRC Emotion Lexicon has made impact include: First of its kind: It was the first word-emotion association lexicon, with entries for eight basic emotions as well as positive and negative sentiment. It still remains the</p>
<p>saifmohammad.com</p>


</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/tm/tm_06_0.html</guid>
  <pubDate>Mon, 12 May 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>5장: 텍스트 데이터 마이닝</title>
  <dc:creator>파이썬기반 SNS텍스트 데이터마이닝 개정판</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/tm/tm_05_0.html</link>
  <description><![CDATA[ 





<p>텍스트 데이터 마이닝에 대해 다루고자 한다.</p>
<section id="텍스트-데이터-마이닝" class="level1">
<h1>01 텍스트 데이터 마이닝</h1>
<p>광도들이 보석을 캐는 과정.</p>
<p>노인 부양에 관한 가설 세우기.</p>
<p>텍스트 데이터 전처리</p>
<p>텍스트 마이닝의 핵심적인 시작 단계로, 데이터의 품질을 높이기 위한 여러 과정으로 구성된다.</p>
<p>먼저, 데이터 수집 후에는 한글화, 결측치 처리, 단어 및 형태소 분석 등의 전처리를 진행합니다.</p>
<p>한글화는 텍스트에서 한글 이외의 문자를 제거하거나 블랭크 처리하여 분석에 적합한 형태로 만드는 과정입니다.</p>
<p>이때 특수기호는 유지하며 한글만 남기는 방식으로 필터링한다.</p>
<p>이렇게 정제된 데이터는 피클(pickle) 파일 형태로 저장하며, 작업 시에는 파일 경로와 파일명을 명확히 지정해야 한다.</p>
<p>예를 들어, 보험연수원에서 제공한 연금 관련 텍스트 데이터를 수년간 6개 채널에서 크롤링해 5개의 피클 파일로 저장한 사례가 있다.</p>
<p>이 파일들은 병합한 후 인덱스를 지정해 다시 저장하며, 저장 경로는 작업 환경에 맞춰 지정해야 한다.</p>
<p>import pickle import pandas as pd import itertools import os import re</p>
</section>
<section id="파일-저장-위치" class="level1">
<h1>파일 저장 위치</h1>
<p>file_path = r’C:\’</p>
<p>이후 분석을 위해 저장된 피클 파일을 다시 로드하여 활용한다.</p>
<p>f = open(file_path + ‘total_doc.pkl’, “rb”) # 데이터 불러오기 data = pickle.load(f) f.close()</p>
<p>data # 문서 전체의 명사 리스트 확보</p>
<ol type="1">
<li>단어들의 빈도 데이터 정제 과정에서는 불필요한 기호나 단어를 제거하고, 결측값은 일괄 삭제하며 인덱스를 재정비합니다. 예컨대 ‘샵’, ’펀드’와 같은 특정 요소는 정제 대상이 되며, 본문 일부 삭제 시 데이터의 일관성을 유지하기 위해 인덱스를 재조정합니다. 정제는 원본을 복사한 후 진행하는 것이 안전합니다.</li>
</ol>
<p>형태소 분석은 한글 데이터 분석에 필수적인 과정이며, 이는 텍스트를 의미 단위로 나누어주는 작업입니다. 형태소 분석을 위해서는 Java 설치와 버전 확인, 인터넷 환경 설정이 필요하며, 대표적으로 사용하는 라이브러리는 코모란(Komoran)입니다. 코모란은 GitHub에서 설치 가능하며, 설치 후 환경 변수 설정 및 보안 설정 등을 완료한 후 사용합니다.</p>
<p>형태소 분석을 통해 본문에서 추출된 단어들은 토큰화 과정을 거쳐 리스트 형태로 정리됩니다. 이때 불용어(의미 없는 단어)를 제거하기 위해 스탑워드 리스트를 활용하며, 불용어와 일치하는 형태소는 제외합니다. 최종적으로 정제된 단어 리스트와 형태소 리스트는 데이터프레임 형태로 저장하고, 이를 다시 파일로 변환하여 보관합니다.</p>
<p>import itertools</p>
</section>
<section id="제목-리스트-언패킹" class="level1">
<h1>제목 리스트 언패킹</h1>
<p>title_noun = list(itertools.chain(*data[‘title_token_noun’])) print(title_noun[:15]) # 앞에서 5개 요소 출력</p>
</section>
<section id="본문-리스트-언패킹" class="level1">
<h1>본문 리스트 언패킹</h1>
<p>doc_noun = list(itertools.chain(*data[‘doc_token_noun’])) print(doc_noun[:15])</p>
</section>
<section id="댓글-리스트-언패킹" class="level1">
<h1>댓글 리스트 언패킹</h1>
<p>comment_noun = list(itertools.chain(*data[‘comment_token_noun’])) print(comment_noun[:15])</p>
<ol start="2" type="1">
<li>제목, 본문, 댓글 데이터 빈도</li>
</ol>
</section>
<section id="빈도를-카운트하는-라이브러리" class="level1">
<h1>빈도를 카운트하는 라이브러리</h1>
<p>from collections import Counter</p>
<p>title_count = Counter(title_noun) # 리스트 원소의 개수가 계산됨 title_top = dict(title_count.most_common(100)) # 상위 100개 출력하기 title_top</p>
<p>#—</p>
<p>doc_count = Counter(doc_noun) # 리스트 원소의 개수가 계산됨 doc_top = dict(doc_count.most_common(100)) # 상위 100개 출력하기 doc_top</p>
</section>
<section id="section" class="level1">
<h1>—</h1>
<p>comment_count = Counter(comment_noun) # 리스트 원소의 개수가 계산됨 comment_top = dict(comment_count.most_common(100)) # 상위 100개 출력하기 comment_top</p>
<ol start="3" type="1">
<li>import csv</li>
</ol>
</section>
<section id="제목별-빈도수-저장" class="level1">
<h1>제목별 빈도수 저장</h1>
<p>with open(file_path + ‘\title_top.csv’, ‘w’) as f: w = csv.writer(f) for k, v in title_top.items(): w.writerow([k, v]) # k, v -&gt; 딕셔너리의 key, value # 즉, 단어와 빈도</p>
</section>
<section id="본문별-빈도수-저장" class="level1">
<h1>본문별 빈도수 저장</h1>
<p>with open(file_path + ‘\doc_top.csv’, ‘w’) as f: w = csv.writer(f) for k, v in doc_top.items(): w.writerow([k, v])</p>
</section>
<section id="댓글별-빈도수-저장" class="level1">
<h1>댓글별 빈도수 저장</h1>
<p>with open(file_path + ‘\comment_top.csv’, ‘w’) as f: w = csv.writer(f) for k, v in comment_top.items(): w.writerow([k, v])</p>
<p>4 . 워드 클라우드 정제된 단어들을 기반으로 워드 클라우드를 그릴 수 있다.</p>
<p>워드 클라우드는 단어의 빈도를 시각적으로 표현하는 기법으로, 가장 자주 등장한 단어를 강조하는 방식으로 표현된다.</p>
<p>이때 Counter의 most_common 함수를 이용해 빈도를 계산하고, 원하는 형태의 마스크 이미지(예: 사람 모양, 네모형 등)를 적용해 시각화할 수 있다.</p>
<p>백그라운드 설정, 폰트 다운로드, 컬러 맵 지정 등 세부 설정도 가능하며, 정보 전달력이 높은 네모 형태를 권장한다.</p>
<p>import matplotlib.pyplot as plt from wordcloud import WordCloud</p>
<p>font_path = r”C:.otf”</p>
</section>
<section id="워드클라우드-생성" class="level1">
<h1>워드클라우드 생성</h1>
<p>wordcloud = WordCloud( font_path=font_path, background_color=‘white’, colormap=“Accent”, width=600, height=400 ).generate_from_frequencies(doc_top)</p>
<p>plt.figure(figsize=(8, 10)) plt.imshow(wordcloud) plt.axis(‘off’) plt.show()</p>
<p>TF - IDF 결과 텀은 단어, 단어들의 빈도, 워드클라우드도 사용 이것이 결합된 형태가 TF - IDF임</p>
<p>단어 뿐만아니라 문서 전체도 고려 한다.</p>
<ol type="1">
<li>워드 클라우드의 문제점, 본문에서 자주 등장하는 것이 높은 가중치를 문맥에 따라서는 다른 의미(완전히 다른 단어)를 가질 수 있음 또한, 그 단어는 낮은 가중치일 수도 있음</li>
</ol>
<p>즉, 데이터가 진짜 말하고자 하는 것을 찾는 인사이트에서는 부적합할 수 있음.</p>
<p>단순한 빈도만으로는 판별하기 애매하다.</p>
<ol start="2" type="1">
<li>문서의 길이의 따라 사용 어휘의 중요도가 바뀔 수 있다.</li>
</ol>
<p>특정 단어가 포함된 문서가 몇 개가 되느냐? d=문서, t=단어, 특정 단어가 나타나는 문서수의 역수(역수의 로그를 취해준 개념)</p>
<p>각 문서에 포함된 단어 카운트 - DTM 행렬</p>
<p>이는 특정 문서에서만 많이 나오지만 전체 문서에서는 적은 단어와 전체적으로 많이 나오게 분포하지만 개별 문서에서는 적게 나오는 단어 2가지가 존재하고 그 중 후자가 더 중요한 가중치를 가진다.</p>
<p>로그를 취해서 소수점으로 나오고 TF-IDF를 곱한다. 이떄 여기저기 많이 나오면 상대적인 가중치가 비슷하고 낮게 나옴</p>
<p>먼저, 단어들을 문자열로 만들어 주어야 한다. 명사들의 문자열 리스트 만들고, sklearn 가져오기.</p>
</section>
<section id="명사들의-문자열-구성" class="level1">
<h1>명사들의 문자열 구성</h1>
<p>doc_noun = [] for i in range(0, len(data[“doc_token_noun”])): doc_noun.append(’ ’.join(data[‘doc_token_noun’][i])) # 각 문서의 명사들을 str로 연결</p>
<p>너무 희박한 것들은 제외할 수도 있다.(최소치, 최대치)</p>
</section>
<section id="텍스트-문서-모음을-단어-tf-idf-행렬로-변환" class="level1">
<h1>텍스트 문서 모음을 단어 tf-idf 행렬로 변환</h1>
<p>from sklearn.feature_extraction.text import TfidfVectorizer vec_y = TfidfVectorizer(min_df=0.01, max_df=0.95)</p>
</section>
<section id="문서의-1-95로-나타나는-단어들을-고려" class="level1">
<h1>문서의 1% ~ 95%로 나타나는 단어들을 고려</h1>
<p>Y = vec_y.fit_transform(doc_noun) print(Y)</p>
<p>10번째 문서 21번째 단어이다. +1</p>
<p>k개의 평균을 갖는다는 것. 비지도, 타겟X 타겟이 있어, 예측을 시도하는 지도학습과는 달리 어떤 패턴을 가진 그룹이 있는지를 보려는 것.</p>
<p>구조화, 군집 분석을 시도하는 것.</p>
<p>임의의 k개의 중심점을 지정, 각각의 개별 데이터를 가장 가까운 곳으로 할당시킴 이 거리를 유클리드의 거리를 한다.</p>
<p>그 그룹이 생성되면 그 그룹 안에서 새로운 중심점을 찾음 그 중심점을 가지고 위의 일련의 과정을 더 이상 중심점이 움직이지 않을 때까지 반복한다.</p>
<p>합리적인 k를 찾는 방법 - 대표적으로 엘보우 기법 팔굽치 처럼 꺾이는 지점을 k값으로 정하는 것.</p>
<p>2개에서 6개 정도가 타당하다 너무 적거나 많으면 의미가 없음.</p>
<p>거리에 대한 SSE 손실함수 구하는 과정 10번 반복</p>
<p>import os os.environ[“OMP_NUM_THREADS”] = “2” # 선택 사항</p>
<p>import matplotlib.pyplot as plt from sklearn.cluster import KMeans</p>
<p>def elbow(X): sse = []</p>
<pre><code>for i in range(1, 10):
    km = KMeans(n_clusters=i, n_init=10, 
                algorithm='lloyd', random_state=0)
    km.fit(X)
    sse.append(km.inertia_)
    print(i)

plt.plot(range(1, 10), sse, marker='o')
plt.xlabel('K')
plt.ylabel('SSE')
plt.xticks(range(1, 10))
plt.show()</code></pre>
<p>elbow(X)</p>
<p>conda install -c conda-forge pyldavis</p>
<p>model_y = KMeans(n_clusters=2, algorithm=‘lloyd’, random_state=0) # 모델 정의 model_y.fit(Y) # 모델 학습</p>
<p>print(“Doc Top terms for each cluster”) order_centroids = model_y.cluster_centers_.argsort()[:, ::-1] # 클러스터 중심 정렬 terms_y = vec_y.get_feature_names_out() # 단어 목록</p>
<p>for i in range(2): # 두 개의 클러스터에 대해 반복 print(“Cluster %d:” % i) for ind in order_centroids[i, :50]: # 각 클러스터의 상위 50개 단어 출력 print(‘%s’ % terms_y[ind]) print(‘’)</p>
<p>데이터 프레임의 형식</p>
<p>import pandas as pd</p>
</section>
<section id="클러스터-중심에서-가장-중요한-단어-인덱스-정렬" class="level1">
<h1>클러스터 중심에서 가장 중요한 단어 인덱스 정렬</h1>
<p>order_centroids = model_y.cluster_centers_.argsort()[:, ::-1] terms_y = vec_y.get_feature_names_out()</p>
</section>
<section id="각-클러스터의-상위-50개-단어-수집" class="level1">
<h1>각 클러스터의 상위 50개 단어 수집</h1>
<p>top_terms = {}</p>
<p>for i in range(2): # 클러스터 수만큼 반복 top_terms[f’Cluster {i}’] = [terms_y[ind] for ind in order_centroids[i, :50]]</p>
</section>
<section id="dataframe으로-변환" class="level1">
<h1>DataFrame으로 변환</h1>
<p>df_top_terms = pd.DataFrame(top_terms) df_top_terms</p>
<p>1 . 제목2 더 나아가 워드 클러스터링과 토픽 모델링을 통해 텍스트의 의미 구조를 분석할 수 있다.</p>
<p>워드 클러스터링은 문서 내 단어 빈도를 기반으로 단어들을 군집화하는 방법으로, TF (Term Frequency) 및 IDF (Inverse Document Frequency) 값을 활용해 중요 단어를 판단합니다.</p>
<p>이후 유클리디안 거리 기반의 K-means와 같은 알고리즘으로 최적의 군집을 형성합니다.</p>
<p>토픽 모델링은 문서 집합에서 주제를 추출하는 기법으로, LDA(Latent Dirichlet Allocation) 같은 확률 기반 모델을 활용합니다.</p>
<p>혼잡도 그래프와 일관성 지표 등을 통해 토픽 수를 결정하고, 각 토픽의 특징을 평가합니다. 이를 통해 시스템화된 분석 체계를 구축할 수 있습니다.</p>


</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/tm/tm_05_0.html</guid>
  <pubDate>Mon, 14 Apr 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>3장: 네이버 카페 크롤링</title>
  <dc:creator>파이썬기반 SNS텍스트 데이터마이닝 개정판</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/tm/tm_03_1.html</link>
  <description><![CDATA[ 





<p>네이버 카페 크롤랑에 대해 다루고자 한다.</p>
<p>합칠려면 모든 변수가 동일하게 들어가야 한다.</p>
<p>from selenium import webdriver # 브라우저 자동화 from bs4 import BeautifulSoup as BS # html 내용 파싱 from selenium.webdriver.common.by import By # 다양한 방법으로 엘리먼트를 찾기 from selenium.webdriver.common.keys import Keys # Keys 클래스 가져오기(키보드 입력 제어)</p>
<p>import pandas as pd # 데이터 조작 및 분석 import datetime # 날짜와 시간 연산 import requests # Http 요청을 보내기 import pickle # 파이썬 객체 직렬화 import time # 코드 실행 속도 조절 import re # 정규 표현식 사용</p>
<ol type="1">
<li></li>
</ol>
<p>driver = webdriver.Chrome() driver.get(‘https://search.naver.com/search.naver?ssc=tab.cafe.all&amp;sm=tab_jum&amp;query=%EB%85%B8%EC%9D%B8+%EB%B6%80%EC%96%91&amp;nso=so%3Ar%2Cp%3Afrom20240301to20240325’)</p>
<ol start="3" type="1">
<li></li>
</ol>
<p>title_list = [] url_list = []</p>
<section id="검색-결과에서-모든-제목-링크-요소-가져오기-스크롤-다운-포함" class="level1">
<h1>검색 결과에서 모든 제목 링크 요소 가져오기 (스크롤 다운 포함)</h1>
<p>for _ in range(2): # 5번 스크롤 내리기 (필요에 따라 조절 가능) driver.execute_script(“window.scrollTo(0, document.body.scrollHeight);”) # 스크롤 맨 아래로 이동 time.sleep(1) # 데이터 로딩을 기다리기 위해 1초 대기</p>
<p>titles = driver.find_elements(By.XPATH, “//*<span class="citation" data-cites="id">[@id='main_pack']</span>/section/div[1]/ul/li/div/div[2]/div[2]/a”)</p>
<p>for i, title_element in enumerate(titles, start=1): # 1부터 카운트 시작 try: title_list.append(title_element.text) # 제목 추가 url_list.append(title_element.get_attribute(“href”)) # URL 추가</p>
<pre><code>except Exception as e:
    print(f"오류 발생: {e}")  # 오류 메시지 출력

if i % 10 == 0:  # 진행 상황 출력 (10개 단위)
    print(f"진행 중: {i}개 완료")</code></pre>
<p>print(“데이터 수집 완료!”) # 최종 완료 메시지 출력</p>
<ol start="4" type="1">
<li></li>
</ol>
</section>
<section id="본문-좋아요-수-댓글-수-댓글-이미지-수-영상-수를-저장할-리스트-초기화" class="level1">
<h1>본문, 좋아요 수, 댓글 수, 댓글, 이미지 수, 영상 수를 저장할 리스트 초기화</h1>
<p>new_doc = []<br>
like_cnt = []<br>
comment_cnt = []<br>
comment_list = []<br>
img_cnt = []<br>
div_cnt = []</p>
</section>
<section id="카페-글-크롤링" class="level1">
<h1>카페 글 크롤링</h1>
<p>for i in range(len(url_list)): url_path = url_list[i] # URL 불러오기 driver.switch_to.window(driver.window_handles[0]) # 첫 번째 탭으로 이동 driver.execute_script(f”window.open(‘{url_path}’)“) # 새 탭에서 URL 실행 driver.switch_to.window(driver.window_handles[1]) # 두 번째 탭으로 이동</p>
<pre><code>time.sleep(2)  # 2초 대기

try:
    iframes = driver.find_elements(By.TAG_NAME, 'iframe')  # 카페 iframe 찾기
    
    if len(iframes) &gt; 0:
        # iframe 전환
        driver.switch_to.frame('cafe_main') # ifame의 첫부분
        html = driver.page_source           # html 가져오고
        soup = BS(html, 'html.parser')      # html 파싱하라

        # 본문 추출
        try:
            a = soup.find('div', class_='article_viewer').get_text() # 값을 가져와라
        except:
            # 본문을 찾지 못할 경우
            a = 'null'

        # 좋아요 수 추출
        try:
            b = soup.find('em', class_='u_cnt _count').get_text()
        except:
            b = 'null'

        # 댓글 수 추출
        try:
            c = soup.find('strong', class_='num').get_text()
        except:
            c = 'null'

        # 댓글 추출
        try:
            d = "\n".join([t.get_text() for t in soup.find_all('span', class_='text_comment')])
        except:
            d = 'null'

        # 이미지 수 추출
        e = len(soup.find_all('img', class_='se-image-resource'))

        # 영상 수 추출
        f = len(soup.find_all('div', class_='pzp-ui-dimmed pzp-dimmed pzp-pc_dimmed'))

        # iframe에서 기본 컨텐츠로 전환
        driver.switch_to.default_content()
    else:
        a, b, c, d, e, f = 'null', 'null', 'null', 'null', 0, 0  # iframe이 없을 경우 기본값

    # 데이터 저장
    new_doc.append(a)
    like_cnt.append(b)
    comment_cnt.append(c)
    comment_list.append(d)
    img_cnt.append(e)
    div_cnt.append(f)

except Exception as e:
    # 오류 발생 시 기본값 저장
    new_doc.append('null')
    like_cnt.append('null')
    comment_cnt.append('null')
    comment_list.append('null')
    img_cnt.append(0)
    div_cnt.append(0)
    print(f"Error occurred at index {i}")

finally:
    # 현재 열린 탭 닫기
    driver.close()
    time.sleep(0.3)  # 0.3초 대기
    driver.switch_to.window(driver.window_handles[0])  # 첫 번째 탭으로 복귀

# 매 10번째 URL마다 진행 상황 출력
if (i + 1) % 10 == 0:
    print(f"진행 상황: {i + 1}/{len(url_list)}")</code></pre>
<ol start="5" type="1">
<li></li>
</ol>
</section>
<section id="크롤링-데이터를-데이터프레임으로-변환" class="level1">
<h1>크롤링 데이터를 데이터프레임으로 변환</h1>
<p>raw_data = pd.DataFrame() # 초기화 raw_data[‘title’] = title_list # 제목 리스트 raw_data[‘doc’] = new_doc # 본문 리스트 raw_data[‘like’] = like_cnt # 좋아요 수 리스트 raw_data[‘comment_cnt’] = comment_cnt # 댓글 수 리스트 raw_data[‘comment_list’] = comment_list # 댓글 리스트 raw_data[‘img’] = img_cnt # 이미지 수 리스트 raw_data[‘div’] = div_cnt # 영상 수 리스트 raw_data[‘ch’] = ‘naver’ # 채널 정보 raw_data[‘ch2’] = ‘cafe’ # 채널 정보 (세부)</p>
</section>
<section id="데이터프레임을-pickle-파일로-저장" class="level1">
<h1>데이터프레임을 pickle 파일로 저장</h1>
<p>file_path = “C:/Users/jkl12/텍스트마이닝/” # 슬래시 사용 with open(file_path + “노인부양cafe.pkl”, “wb”) as f: pickle.dump(raw_data, f)</p>
</section>
<section id="크롬-드라이버-종료" class="level1">
<h1>크롬 드라이버 종료</h1>
<p>driver.quit()</p>
</section>
<section id="저장된-pickle-파일을-불러오기" class="level1">
<h1>저장된 pickle 파일을 불러오기</h1>
<p>with open(file_path + “노인부양cafe.pkl”, “rb”) as f: temp_file = pickle.load(f)</p>
</section>
<section id="데이터프레임을-csv-파일로-저장" class="level1">
<h1>데이터프레임을 CSV 파일로 저장</h1>
<p>temp_file.to_csv(file_path + “노인부양cafe.csv”, index=False, encoding=“utf-8-sig”)</p>


</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/tm/tm_03_1.html</guid>
  <pubDate>Mon, 31 Mar 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>4장: 크롤링 데이터 전처리</title>
  <dc:creator>파이썬기반 SNS텍스트 데이터마이닝 개정판</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/tm/tm_04_0.html</link>
  <description><![CDATA[ 





<p>크롤링 데이터의 통합 및 전처리에 대해 다루고자 한다.</p>
<p>너저문한 데이터를 정리</p>
<p>개행문자는 스페이스바를 눌렸기에 생기는 것임. 이를 처리하는 것이 전처리 과정임.</p>
<p>의미있는 인사이트를 얻기 위해서 정리</p>
<p>원데이터, 쿠팡에서 들어오는 데이터는 트랜젝션데이터(거래 데이터) 어떤 고객이 가입, 비가입, 어떤 카드로 결제, 회원가입 정보(최소한의 정보), 배송을 위한 성명, 휴대폰 번호, 본인인증 정도, - 고객의 프로파일링, 또는 데모그래픽 데이터 품목명, 가격명, 시간대, 카드 정보 – 정형데이터 이러한 필드로 저장됨, 댓글 정보 – 비정형 데이터, 사람마다 쓰는 댓글 양이 다름 고객의 반응을 보기 위해 전처리를 시도함, 이는 IT팀, 마케팅팀, MD가 사용</p>
<p>성별을 구별하는 방법</p>
<p>룰세팅을 하여 전처리 필요 없이 데이터를 뽑아서 써야 됨 여기선 가공 변수를 만드는 것이 필요함(예: 특정한 시간대에서 발생되는 매출)</p>
<p>품목별 페이지에 대한 로그분석, 리뷰 데이터, 댓글의 패턴, 쿠키로 데이터 가져오기 SKT 전화요금제,만 있을 경우, 전화거래량 패턴 분석 정도 밖에 할 수 없음. 이름으로 성별을 판별 –</p>
<p>추정을 하는 것임</p>
<p>02 정규표현식</p>
<p>import re text = ‘core core883core’ re.findall(r’, text)</p>
<section id="단어-중간에-있는디" class="level1">
<h1>단어 중간에 있는디</h1>
<p>re.findall(r’’, text)</p>
<p>re.findall(r’1’, text)</p>
<p>text = ‘12 month 365 days 2023?’ re.findall(r’, text)</p>
<p>text = ‘12 month 365 days 2023?’ re.findall(r’’, text) # 숫자에 해당되는 걸 다 가져와</p>
<p>re.findall(r’+’, text) # 숫자를 제외한 모든 것</p>
<p>text = ‘Wow! 999. This is a wonderful place.’ w_text = re.findall(r’+’, text) w_text # 특수문자를 제외한 모든 문자출력</p>
<p>text = ‘Wow! 999. This is a wonderful place.’ w_text = re.findall(r’+’, text) w_text</p>
<p>text = ‘Wow! 999. This is a wonderful place.’ w_text = re.findall(r’+’, text) w_text</p>
<p>text = ‘Wow! 999. This is a wonderful place.’ w_text = re.findall(r’+’, text) w_text # 특수문자까지 포함하여 출력</p>
<p>03 데이터 합치기</p>
<ol type="1">
<li>라이브러리 불러오기</li>
</ol>
<p>import pandas as pd import pickle import os import re</p>
<ol start="2" type="1">
<li>데이터 병합하기</li>
</ol>
</section>
<section id="파일-저장-위치" class="level1">
<h1>파일 저장 위치</h1>
<p>file_path = r’C:\’</p>
</section>
<section id="pkl-파일-로드-함수" class="level1">
<h1>pkl 파일 로드 함수</h1>
<p>def pklopen(text): f = open(file_path + ‘{}.pkl’.format(text),“rb”) a = pickle.load(f) f.close() return a</p>
</section>
<section id="수집된-데이터" class="level1">
<h1>수집된 데이터</h1>
<p>data1 = pklopen(‘노인부양blog’) data2 = pklopen(‘노인부양cafe’) data3 = pklopen(‘노인부양cafe2’)</p>
</section>
<section id="데이터-결합" class="level1">
<h1>데이터 결합</h1>
</section>
<section id="행row-방향으로-데이터를" class="level1">
<h1>행(row) 방향으로 데이터를</h1>
</section>
<section id="밑으로-합치는concatenate-방식" class="level1">
<h1>밑으로 합치는(concatenate) 방식</h1>
<p>data = pd.concat([data1, data2, data3])</p>
</section>
<section id="수집된-데이터가-모두-같은-컬럼-구조를-갖는다면" class="level1">
<h1>수집된 데이터가 모두 같은 컬럼 구조를 갖는다면,</h1>
</section>
<section id="위에서-아래로-이어붙이는-방식으로-결합된다." class="level1">
<h1>위에서 아래로 이어붙이는 방식으로 결합된다.</h1>
</section>
<section id="각-채널-사이즈-확인" class="level1">
<h1>각 채널 사이즈 확인</h1>
<p>data.groupby([‘ch’, ‘ch2’]).size()</p>
<ol start="3" type="1">
<li>인덱스 재설정하기</li>
</ol>
</section>
<section id="인덱스를-0-1-2-로-초기화하고" class="level1">
<h1>인덱스를 0, 1, 2, …로 초기화하고,</h1>
</section>
<section id="기존-인덱스는-새로운-열로-남기지-않도록-하는-명령어." class="level1">
<h1>기존 인덱스는 새로운 열로 남기지 않도록 하는 명령어.</h1>
</section>
<section id="주로-데이터-정제-후-인덱스를-깔끔하게-맞출-때-사용된다." class="level1">
<h1>주로 데이터 정제 후 인덱스를 깔끔하게 맞출 때 사용된다.</h1>
<p>data = data.reset_index(drop=True) data</p>
<p>채널별 수집한 데이터의 병합 결과</p>
<p>04 데이터 전처리</p>
<ol start="4" type="1">
<li>한글화</li>
</ol>
<p>정제, 정규화, 토큰화의 3단계를 거친다. 비정형 데이터일 경우,</p>
<p>문서 날리기</p>
<p>100 정열</p>
<p>f = open(file_path + ‘노인부양병합’, ‘wb’) pickle.dump(data, f) f.close()</p>
<p>f = open(file_path + ‘노인부양병합’, ‘rb’) docs = pickle.load(f) f.close() docs</p>
</section>
<section id="병합된-데이터를-피클-파일로-저장-및-출력한-것으로" class="level1">
<h1>병합된 데이터를 피클 파일로 저장 및 출력한 것으로</h1>
</section>
<section id="아래와-같이-파일이-저장된-것을-확인할-수-있다." class="level1">
<h1>아래와 같이 파일이 저장된 것을 확인할 수 있다.</h1>
</section>
<section id="제목-본문-댓글의-한글화-및-특수문자-제거" class="level1">
<h1>제목, 본문, 댓글의 한글화 및 특수문자 제거</h1>
<p>for i in range(len(docs)): docs.loc[i, ‘title’] = re.sub( r”[^0-9a-zA-Zㄱ-ㅎㅏ-ㅣ가-힣]“,”“, str(data.loc[i, ‘title’]))</p>
<pre><code>docs.loc[i, 'doc'] = re.sub(
    r"[^0-9a-zA-Zㄱ-ㅎㅏ-ㅣ가-힣]", "", str(data.loc[i, 'doc']))

docs.loc[i, 'comment_cnt'] = re.sub(
    r"[^0-9]", "", str(docs.loc[i, 'comment_cnt']))

docs.loc[i, 'comment_list'] = re.sub(
    r"[^0-9a-zA-Zㄱ-ㅎㅏ-ㅣ가-힣]", "", str(data.loc[i, 'comment_list']))</code></pre>
<p>docs</p>
</section>
<section id="조건에-맞는-row만-남기기" class="level1">
<h1>조건에 맞는 row만 남기기</h1>
<p>docs = docs[ ~( (docs[‘doc’].str.len() &lt; 2) | (docs[‘doc’].str.isspace()) )].reset_index(drop=True) 안에 ^를 넣을 때 한글만 가져오기</p>
<ol start="5" type="1">
<li>문자형으로는 카우트 할 수 없으므로</li>
</ol>
</section>
<section id="like-comment_cnt-img-div의-데이터-타입을-숫자로-변환" class="level1">
<h1>like, comment_cnt, img, div의 데이터 타입을 숫자로 변환</h1>
</section>
<section id="변환-중-에러-발생-시-nan으로-처리" class="level1">
<h1>변환 중 에러 발생 시 NaN으로 처리</h1>
<p>docs[‘like’] = pd.to_numeric(docs[‘like’], errors=‘coerce’).astype(‘Int64’) docs[‘comment_cnt’] = pd.to_numeric(docs[‘comment_cnt’], errors=‘coerce’).astype(‘Int64’) docs[‘img’] = pd.to_numeric(docs[‘img’], errors=‘coerce’).astype(‘Int64’) docs[‘div’] = pd.to_numeric(docs[‘div’], errors=‘coerce’).astype(‘Int64’)</p>
<p>docs</p>
<p>원데이터와 값이 일치하는 지 확인하기.</p>
<ol start="6" type="1">
<li>숫자형 결측치로 단어, 또는 문장, 형태소 분석 어간, 어근 어조 어미, 단순 띄어쓰기만으로는 힘듦, 형태소 분석을 쓰는 것임</li>
</ol>
<p>자립 형태소, 의존형태소</p>
<p>Okt, 메캅, 코모란, 한나눔, 꼬꼬마</p>
<p>from tqdm import tqdm # 진행상황 시각화 from konlpy.tag import Komoran</p>
</section>
<section id="komoran-형태소-분석기-초기화" class="level1">
<h1>Komoran 형태소 분석기 초기화</h1>
<p>komoran = Komoran() # 클래스의 인스턴스 지정 # 이는 형태소 분석기 하나를 준비해서 계속 쓰기 위함이다.</p>
<ol start="7" type="1">
<li>형태소 분석을 하고 명사들을 리스트로 저장</li>
</ol>
<p>이름은 단순하게 지정해도 상관없지만 너무 이름이 단순하면 이를 구별하거나 변수를 이해하기 어려으므로 다른 사람도 알아볼 수 있도록 객관적으로 판단하여 룰 세팅을 하는 것이 좋음</p>
<p>title_token_list = [] # 제목의 형태소를 담아낼 리스트 title_token_noun = [] # 제목의 명사를 담아낼 리스트</p>
<p>for i in tqdm(range(len(docs))): # for문 - :</p>
<pre><code># komoran.pos() 메서드를 사용하여 형태소 분석 실시
pos = komoran.pos(str(docs['title'][i]))

# komoran.nouns() 메서드를 사용하여 추출하고 리스트에 저장
noun = [term for term in komoran.nouns( # 명사만 추출하며,
    str(docs['title'][i])) if len(term) &gt; 1] # 명사의 길이는 2 이상이어야 한다.

title_token_list.append(pos)
title_token_noun.append(noun)</code></pre>
<p>리스트 이름구조 형태내용</p>
<p>title_token_list [[(‘단어’, ‘품사’), …], …] 모든 형태소와 품사 정보 title_token_noun [[‘명사’, ‘명사’], …] 2글자 이상 명사만</p>
<ol start="8" type="1">
<li>본문 토큰화 # 본문 형태소 및 명사 리스트 doc_token_list = [] doc_token_noun = []</li>
</ol>
<p>for i in tqdm(range(len(docs))):</p>
<pre><code>pos = komoran.pos(u'{}'.format(docs['doc'][i]))

noun = [term for term in komoran.nouns(
    u'{}'.format(docs['doc'][i])) if len(term) &gt; 1]

doc_token_list.append(pos)
doc_token_noun.append(noun)</code></pre>
</section>
<section id="댓글-형태소-및-명사-리스트" class="level1">
<h1>댓글 형태소 및 명사 리스트</h1>
<p>comment_token_list = [] comment_token_noun = []</p>
<p>for i in tqdm(range(len(docs))):</p>
<pre><code>pos = komoran.pos(u'{}'.format(docs['comment_list'][i]))

noun = [term for term in komoran.nouns(
    u'{}'.format(docs['comment_list'][i])) if len(term) &gt; 1]

comment_token_list.append(pos)
comment_token_noun.append(noun)</code></pre>
<p>형태소 분석만으로는 전처리가 끝났다고 볼 수 없다 아래 쓸대없는 불용어 때문에 찾고자 하는 문맥을 못 볼 수 있다.</p>
<p>예를 들면, 광고글이 있는데 이는 광고글을 쓴 자가 정성스럽게 알맞은 단어 (의미없는 개행 문자 등만을 나열하지 않는) 말 그대로의 정돈된 글이기 떄문에 이를 제거하려면 일일이 광고글을 제거해야 한다.</p>
<p>그러므로, 불용어 처리까지 해야 한다.</p>
<p>다만, 불용어 처리에도 의미가 있는 명사를 제거하지 않도록 주의해야 한다. 예를 들어, ‘la’ 라는 문자만 본다면 의미없는 불용어라고 착각할 수 있다. 그러나 이는 LA를 의미하며, 미국 현지에서는 la, La, lA, LA와 같이 다양하게 사용되는 것으로 나타났다.</p>
<p>따라서 이러한 불용어 처리 전에는 혹은 처리 중에 이러한 용어들이 나온다면 즉시 문서나 원데이터를 들여다봐서 실제로 그 값이 어떤 문맥상에서 어떤 의미를 지니는지를 확인해야 한다.</p>
<p>어휘에 대한 이해를 할 수 있어야 한다.</p>
<ol start="9" type="1">
<li>불용어 사전 다운받기</li>
</ol>
<p>stopwords-ko/stopwords-ko.txt at master · stopwords-iso/stopwords-ko</p>
<p>Korean stopwords collection. Contribute to stopwords-iso/stopwords-ko development by creating an account on GitHub.</p>
<p>github.com # 불용어 사전 기반 불용어 리스트 정리 f = open( file_path + “stopwords-ko.txt”, “r”, encoding=“UTF-8”) # UTF-8 인코딩으로 불용어 파일 열기</p>
<p>st = f.readlines() # 한 줄씩 읽어서 리스트에 저장 f.close()</p>
</section>
<section id="줄-끝-개행-문자-제거" class="level1">
<h1>줄 끝 개행 문자 제거</h1>
<p>st = [word.strip() for word in st] st</p>
<ol start="10" type="1">
<li><p>불용어 사전 깔끔하게 만들기 stw = [word.strip() for word in st if word.strip() != ’’] stw</p></li>
<li><p>나만의 불용어 사전 만들기 # 사용자가 정의한 불용어 추가 # 목적: 순수한 노인부양과 관련된 이야기 수집 # 광고글을 제외하기 위한 사용자 지정 불용어 사전 # 사용자가 정의한 불용어 추가 user_stopwords = [ ‘노인’, ‘부양’, ‘무자’, ‘양의’, ‘기초’, ‘노인학’, ‘계급’, ‘보험’, ‘고령’, ‘경제’, ‘바탕’, ‘국가’, ‘어르신’,‘지역’, ‘생각’, ‘포함’, ‘사업’, ‘한부모’, ‘일상생활’, ‘국민’, ‘확인’, ‘우리나라’, ‘적용’, ‘위해’, ‘기본’, ‘수준’, ‘예방’, ‘방법’, ‘주택’, ‘가능’, ‘방안’, ‘진행’, ‘행위’, ‘등의’, ‘대한민국’, ‘내년’, ‘개념’, ‘모집’, ‘개선’, ‘자격증’, ‘대상자’, ‘자격’, ‘과제’, ‘토론’, ‘청주’, ‘감소’, ‘증가’, ‘대의’, ‘추천’, ‘자부’, ‘경우’, ‘게시판’, ‘자금’, ‘본인’, ‘사람’, ‘연령’, ‘등급’, ‘활동’, ‘정부’, ‘평균’, ‘일반’, ‘파일’, ‘자의’, ‘더보’, ‘주간’, ‘기대’, ‘결과’, ‘통해’, ‘인가’, ‘자료’, ‘두레’, ‘포트’, ‘사이트’, ‘회원’, ‘다운’, ‘추가’, ‘완성’, ‘포인트’, ‘다운로드’, ‘충전’, ‘신규’, ‘제휴’, ‘작성’, ‘이벤트’, ‘저도’, ‘바우’, ‘해주’, ‘아래’, ‘링크’, ‘자가’, ‘해주시’, ‘등록’, ‘특례’, ‘네이버’, ‘구부’, ‘다이’, ‘이얼’, ‘마나’, ‘한일’, ‘서로’, ‘이다’, ‘현재’, ‘해서’, ‘댓글’, ‘하기’, ‘니다’, ‘이하’, ‘안녕하세요’, ‘해도’, ‘오늘’, ‘하면’, ‘키메’, ‘고맙습니다’, ‘이고’, ‘제가’, ‘내세’, ‘가요’, ‘만세’, ‘이노’, ‘때문’, ‘블로그’, ‘블로거’, ‘카페’, ‘만원’, ‘보내기’, ‘질문’, ‘재가’, ‘한국’, ‘세계’, ‘사회’, ‘가족’, ‘기준’, ‘서비스’, ‘장기’]</p></li>
</ol>
</section>
<section id="불용어-리스트-확장" class="level1">
<h1>불용어 리스트 확장</h1>
<p>stw.extend(user_stopwords)</p>
</section>
<section id="불용어-리스트-csv-파일로-저장" class="level1">
<h1>불용어 리스트 CSV 파일로 저장</h1>
<p>import csv</p>
<p>with open(‘불용어 리스트’, “w”) as file: writer = csv.writer(file) writer.writerow(stw)</p>
<ol start="12" type="1">
<li><p>정리된 불용어를 각문서의 제목, 본문, 댓글에서 제거 for word in stw: for i in range(len(title_token_noun)): # 제목에서 불용어 제거 while word in title_token_noun[i]: title_token_noun[i].remove(word)</p>
<pre><code># 본문에서 불용어 제거
while word in doc_token_noun[i]:
    doc_token_noun[i].remove(word)

# 댓글에서 불용어 제거
while word in comment_token_noun[i]:
    comment_token_noun[i].remove(word)</code></pre></li>
</ol>
</section>
<section id="문서파일-docs에-적용" class="level1">
<h1>문서파일 docs에 적용</h1>
<p>docs[‘title_token_noun’] = title_token_noun # 제목 명사 리스트 docs[‘title_token_list_pos’] = title_token_list # 형태소+품사 리스트</p>
<p>docs[‘doc_token_noun’] = doc_token_noun # 본문 명사 리스트 docs[‘doc_token_list_pos’] = doc_token_list # 형태소+품사 리스트</p>
<p>docs[‘comment_token_noun’] = comment_token_noun # 본문 명사 리스트 docs[‘comment_token_list_pos’] = comment_token_list # 형태소+품사 리스트</p>
<ol start="13" type="1">
<li>불용어를 제거한 최종 파일 저장 및 불러오기 # pickle로 저장 (최초 1회만 실시) import pickle with open(file_path + “total_doc.pkl”, “wb”) as f: pickle.dump(docs, f)</li>
</ol>
</section>
<section id="pickle로-다시-불러오기" class="level1">
<h1>pickle로 다시 불러오기</h1>
<p>with open(file_path + “total_doc.pkl”, “rb”) as f: data = pickle.load(f)</p>


</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/tm/tm_04_0.html</guid>
  <pubDate>Mon, 31 Mar 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>3장: 네이버 블로그 크롤링</title>
  <dc:creator>파이썬기반 SNS텍스트 데이터마이닝 개정판</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/tm/tm_03_0.html</link>
  <description><![CDATA[ 





<p>동적 크롤링을 위한 준비 및 네이버 블로그 크롤링 실습에 대해 다루고자 한다.</p>
<p>01 자바 설치 방법</p>
<p>1 . 파이썬과 자바의 관계 일반적으로 파이썬은 자바 없이 독립적으로 실행할 수 있다.</p>
<p>하지만, 특정 라이브러리(예: JPype, PySpark, Jython 등)는 자바(Java)를 필요로 한다.</p>
<p>따라서 사용하려는 기능이 자바 기반이라면, 먼저 자바가 설치되어 있어야 한다.</p>
<p>2 . 자바 설치 여부 확인 Anaconda 프롬프트 실행한 다음 명령어 입력 후 실행.</p>
<section id="자바가-설치되어-있다면-버전-정보가-출력됨." class="level1">
<h1>자바가 설치되어 있다면 버전 정보가 출력됨.</h1>
</section>
<section id="java-is-not-recognized-오류가-발생하면-자바가-설치되지-않은-것임." class="level1">
<h1>“java is not recognized…” 오류가 발생하면 자바가 설치되지 않은 것임.</h1>
<p>java -version</p>
<p>3 . 내 컴퓨터에 자바 설치하기 Oracle 공식 홈페이지에서 JDK 다운로드 설치 후, 환경 변수를 설정해야 한다.</p>
<p>Download the Latest Java LTS Free</p>
<p>Subscribe to Java SE and get the most comprehensive Java support available, with 24/7 global access to the experts.</p>
<p>www.oracle.com</p>
<p>환경 변수 설정 (Windows 기준)</p>
<p>제어판 → 시스템 및 보안 → 시스템 → 고급 시스템 설정 고급 탭 → 환경 변수 버튼 클릭 시스템 변수에서 “새로 만들기” 클릭 변수 이름: JAVA_HOME 변수 값: C:Files-XX.X.X (설치된 JDK 경로 입력) Path 변수 편집 → ;%JAVA_HOME%추가</p>
<p>Anaconda 프롬프트 또는 명령 프롬프트에서 다시 입력하여 정상적으로 출력되는지 확인한다.</p>
<p>02 Selenium을 사용한 동적 크롤링</p>
<p>1 . Selenium 설치 웹 브라우저에서 동적 크롤링 시 가장 많이 사용하는 패키지.</p>
<p>과거에는 웹드라이버 버전에 맞는 경로를 지정해줘야 했지만, 현재는 패키지의 새버전에 의해 자동적으로 맞춰진다.</p>
<p>pip install selenium</p>
<p>2 . 웹드라이버 다운로드 사용하는 브라우저에 맞는 WebDriver를 다운로드해야 한다.</p>
<p>Chrome 다운로드 및 설치 - 컴퓨터 - Google Chrome 고객센터</p>
<p>도움이 되었나요? 어떻게 하면 개선할 수 있을까요? 예아니요</p>
<p>support.google.com 다운로드한 WebDriver를 실행 파일 경로에 두거나, Python 코드에서 직접 경로를 지정해야 한다.</p>
<p>03 네이버 블로그 크롤링</p>
<ol type="1">
<li>라이브러리 불러오기.</li>
</ol>
<p>from selenium import webdriver # 웹 브라우저 자동화 from bs4 import BeautifulSoup as BS # HTML 및 XML 파싱</p>
<p>import pandas as pd # 데이터 조작 및 분석 import requests # HTTP 요청을 보내기 위한 모듈 import datetime # 날짜 및 시간 연산 import pickle # 파이썬 객체 직렬화 import time # 코드 실행 간격 조절 import re # 정규 표현식을 사용하여 문자열 처리</p>
</section>
<section id="selenium에서-다양한-방법으로-html-요소를-찾기" class="level1">
<h1>Selenium에서 다양한 방법으로 HTML 요소를 찾기</h1>
<p>from selenium.webdriver.common.by import By</p>
<ol start="2" type="1">
<li>Selenium을 이용한 네이버 블로그 검색 자동화.</li>
</ol>
</section>
<section id="크롬-드라이버-실행" class="level1">
<h1>크롬 드라이버 실행</h1>
<p>driver = webdriver.Chrome()</p>
</section>
<section id="네이버-블로그-검색-페이지로-이동" class="level1">
<h1>네이버 블로그 검색 페이지로 이동</h1>
</section>
<section id="검색할-키워드-지정-및-데이터-수집기간-설정한-뒤" class="level1">
<h1>검색할 키워드 지정 및 데이터 수집기간 설정한 뒤</h1>
</section>
<section id="복사한-url을-붙여-넣으면-되며-아래-코드는-가독성을-위해-일부러-줄바꿈을-시도함" class="level1">
<h1>복사한 URL을 붙여 넣으면 되며, 아래 코드는 가독성을 위해 일부러 줄바꿈을 시도함</h1>
<p>driver.get(’’’ https://search.naver.com/search.naver? ssc=tab.blog.all&amp;query=%EB%85%B8%EC%9D%B8%20%EB%B6%80%EC%96%91 &amp;sm=tab_opt&amp;nso=so%3Ar%2Cp%3Afrom20240301to20240325’’’.replace(“”, ““))</p>
<p>URL 가져오는 방법</p>
<p>실행 화면</p>
<ol start="3" type="1">
<li>웹 페이지 자동 스크롤 함수.</li>
</ol>
<p>def doScrollDown(whileSeconds): start = datetime.datetime.now() # 스크롤 다운 시작 시간 설정 end = start + datetime.timedelta(seconds=whileSeconds) # 스크롤 다운 종료 시간</p>
<pre><code>while True:
    # 페이지 맨 아래로 스크롤 다운
    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')
    time.sleep(1) # 1초 대기

    # 종료 시간에 도달하면 반복 종료
    if datetime.datetime.now() &gt; end:
        break
        </code></pre>
<p>doScrollDown(2) # 스크롤 다운 시간 설정</p>
<ol start="4" type="1">
<li>웹 페이지에서 제목과 URL 추출하기.</li>
</ol>
</section>
<section id="제목과-url을-저장할-리스트-초기화" class="level1">
<h1>제목과 URL을 저장할 리스트 초기화</h1>
<p>title_list = [] url_list = []</p>
</section>
<section id="현재-페이지에서-클래스명이-title_link인-요소들을-찾음" class="level1">
<h1>현재 페이지에서 클래스명이 ’title_link’인 요소들을 찾음</h1>
<p>titles = driver.find_elements(By.CLASS_NAME, ‘title_link’)</p>
<p>for i, title_element in enumerate(titles): try: # 요소에서 제목을 추출하여 title_list에 추가 title_list.append(title_element.text) # 요소에서 URL을 추출하여 url_list에 추가 url_list.append(title_element.get_attribute(‘href’)) except: print(“오류 발생”) # 예외 발생 시 출력 continue # 오류가 발생해도 다음 요소 처리 계속 진행</p>
<pre><code># 10번째 항목마다 진행 상황 출력
if (i + 1) % 10 == 0:
    print(f"{i + 1}개 수집 완료")</code></pre>
<ol start="5" type="1">
<li>블로그 본문 및 메타데이터 크롤링 자동화.</li>
</ol>
</section>
<section id="크롤링-데이터-저장-리스트-초기화" class="level1">
<h1>1] 크롤링 데이터 저장 리스트 초기화</h1>
<p>new_doc, like_cnt, comment_cnt, comment_list, img_cnt, div_cnt = [], [], [], [], [], []</p>
</section>
<section id="블로그-본문-크롤링" class="level1">
<h1>2] 블로그 본문 크롤링</h1>
<p>for i in range(len(url_list)): url_path = url_list[i] # URL 불러오기 driver.switch_to.window(driver.window_handles[0]) # 첫 번째 탭으로 이동 driver.execute_script(“window.open(‘{}’)”.format(url_path)) # 새 탭 열기(URL 실행) driver.switch_to.window(driver.window_handles[1]) # 두 번째 탭으로 이동</p>
<pre><code>time.sleep(1)  # 1초 대기
try:
    iframes = driver.find_elements(By.TAG_NAME, "iframe")
    d = ''     # 댓글 변수 초기화

    # 댓글 영역의 HTML 코드 가져오기
    if len(iframes) &gt; 0:            # iframes의 존재 확인
        driver.switch_to.frame(0)       # 첫 번째 iframe으로 전환 및 내용 가져옴
        html = driver.page_source       # HTML 코드 가져와 변수 저장
        soup = BS(html, "html.parser")  # 저장된 코드 파싱 및 soup 생성

        # 3] 블로그 본문 추출
        try:
            a = soup.find("div", class_="se-main-container").get_text()
        except: # 블로그 본문을 찾지 못할 경우
            a = soup.find("div", id="postListBody")     # 일반 블로그에 경우
            a = re.sub("[^ㄱ-ㅎㅏ-ㅣ가-힣]", "", str(a)) # 정규표현식 -&gt; 한글만 남김

        # 4] 좋아요 수 추출
        try:
            b = soup.find("em", class_="u_cnt_count").get_text()
        except:
            b = "null"

        # 5] 댓글 수 추출
        try:
            c = soup.find("em", id="commentCount").get_text()
        except:
            c = "null"

        # 6] 댓글 추출
        try: # 댓글을 모두 보기 위해 버튼 클릭
            comment = driver.find_elements(By.CLASS_NAME, "btn_arr")
            comment[-1].click()  # 마지막 댓글 버튼 클릭
            time.sleep(1)
            commentLen = len(driver.find_elements(By.CLASS_NAME, "u_cbox_page"))
            d = "\n".join([comment.text for comment in driver.find_elements(By.CLASS_NAME, "u_cbox_text_wrap")])
        except:
            d = "null"

        # 7] 이미지 및 영상 수 추출
        e = len(soup.find_all("img", class_="se-image-resource egjs-visible"))
        f = len(soup.find_all("div", class_="pzp-ui-dimmed pzp-dimmed pzp-pc__dimmed"))

        # 8] 데이터 리스트에 추가
        new_doc.append(a)
        like_cnt.append(b)
        comment_cnt.append(c)
        comment_list.append(d)
        img_cnt.append(e)
        div_cnt.append(f)

        driver.switch_to.default_content()  # 기본 콘텐츠로 전환
    else:
        # 데이터가 없을 경우 빈 값 추가
        new_doc.append(' ')
        like_cnt.append(' ')
        comment_cnt.append(' ')
        comment_list.append(' ')
        img_cnt.append(' ')
        div_cnt.append(' ')

except Exception as e:
    # 예외 발생 시 에러 메시지와 함께 빈 값 추가
    print(f"Error at {url_path}: {e}")
    new_doc.append(' ')
    like_cnt.append(' ')
    comment_cnt.append(' ')
    comment_list.append(' ')
    img_cnt.append(' ')
    div_cnt.append(' ')

driver.close()  # 현재 탭 닫기
time.sleep(0.3)  # 0.3초 대기

# 매 10번마다 진행 상황 출력
if (i+1) % 10 == 0:
    print(f"진행 상황: {i+1}/{len(url_list)}")</code></pre>
<ol start="6" type="1">
<li>데이터프레임으로 변환.</li>
</ol>
</section>
<section id="크롤링한-데이터를-데이터프레임으로-변환" class="level1">
<h1>크롤링한 데이터를 데이터프레임으로 변환</h1>
<p>raw_data = pd.DataFrame({ “title”: title_list, “doc”: new_doc, “like”: like_cnt, “comment_cnt”: comment_cnt, “commnet_list”: comment_list, “img”: img_cnt, “div”: div_cnt, “ch”: “naver”, “ch2”: “blog” })</p>
</section>
<section id="데이터프레임을-pickle-파일로-저장" class="level1">
<h1>데이터프레임을 pickle 파일로 저장</h1>
<p>file_path = “C:/Users/jkl12/텍스트마이닝/” # 슬래시 사용 with open(file_path + “노인부양blog.pkl”, “wb”) as f: pickle.dump(raw_data, f)</p>
</section>
<section id="크롬-드라이버-종료" class="level1">
<h1>크롬 드라이버 종료</h1>
<p>driver.quit()</p>
</section>
<section id="저장된-pickle-파일을-불러오기" class="level1">
<h1>저장된 pickle 파일을 불러오기</h1>
<p>with open(file_path + “노인부양blog.pkl”, “rb”) as f: temp_file = pickle.load(f)</p>
</section>
<section id="데이터프레임을-csv-파일로-저장" class="level1">
<h1>데이터프레임을 CSV 파일로 저장</h1>
<p>temp_file.to_csv(file_path + “노인부양blog.csv”, index=False, encoding=“utf-8-sig”) # 파일 경로 지정 file_path = r”C:.csv”</p>
</section>
<section id="csv-파일-불러오기" class="level1">
<h1>CSV 파일 불러오기</h1>
<p>df = pd.read_csv(file_path, encoding=“utf-8-sig”) df</p>
<hr>


</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/tm/tm_03_0.html</guid>
  <pubDate>Mon, 17 Mar 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>2장: 네이버 뉴스 기사 제목 크롤링</title>
  <dc:creator>파이썬기반 SNS텍스트 데이터마이닝 개정판</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/tm/tm_02_0.html</link>
  <description><![CDATA[ 





<p>웹 크롤링 개념 및 정적 크롤링 실습에 대해 다루고자 한다.</p>
<section id="데이터-종류" class="level1">
<h1>01 데이터 종류</h1>
<section id="정형-데이터" class="level2">
<h2 class="anchored" data-anchor-id="정형-데이터">1 . 정형 데이터</h2>
<p>(Structured Data)</p>
<p>일정한 형식을 갖춘 데이터로, 데이터베이스의 테이블처럼 행과 열로 정리된다.</p>
<p>예: 엑셀, SQL 데이터베이스, 고객 정보(이름, 나이, 주소 등).</p>
<p>룰세팅(Rule Setting) 데이터를 저장할 때 고정된 형식(테이블, 행/열 구조, 스키마 등)을 미리 정의하는 것.</p>
<p>2 . 비정형 데이터 (Unstructured Data)</p>
<p>형식이 일정하지 않아 체계적으로 저장하기 어려운 데이터.</p>
<p>예: 텍스트(SNS 게시글, 이메일), 이미지, 동영상, 음성 데이터.</p>
<p>주로 자연어 처리(NLP)나 텍스트 마이닝 등의 기법을 활용해 분석.</p>
<p>3 . 반정형 데이터 (Semi-Structured Data)</p>
<p>일정한 구조를 가지지만 완전히 정형화되지 않은 데이터. 태그나 특정한 형식(XML, JSON 등)을 포함하여 구조화가 가능하다.</p>
<p>예: HTML, JSON, XML 파일, 로그 데이터.</p>
<p>02 크롤링</p>
<p>1 . 정적 크롤링 웹 페이지의 HTML 소스 코드를 직접 가져와서 필요한 데이터를 추출하는 방식.</p>
<p>기본적으로, requests 라이브러리로 웹 페이지 HTML을 가져와 BeautifulSoup으로 데이터 추출한다.</p>
<p>페이지 로딩 속도가 빠르고, 서버 부하가 적으나 JavaScript로 생성되는 데이터는 가져올 수 없다.</p>
<p>HTML만으로 필요한 정보를 얻을 수 있다면 → 정적 크롤링이 유리하다.</p>
<p>2 . 동적 크롤링 웹 브라우저를 실제로 실행하여 JavaScript로 로드되는 데이터까지 가져오는 방식.</p>
<p>기본적으로, Selenium이나 Playwright 같은 브라우저 자동화 도구 사용한다.</p>
<p>JavaScript 렌더링된 데이터를 포함하여 크롤링 가능하나, 속도가 느리고, 서버 부하가 높다.</p>
<p>JavaScript로 데이터가 동적으로 로딩된다면 → 동적 크롤링이 필요하다.</p>
<p>03 라이브러리 Jupyter Notebook에서 실행하는 명령어는 기본적으로 일반적인 Python 실행 환경에서도 동일하게 사용할 수 있다.</p>
<p>(예: 터미널, 명령 프롬프트, 다른 IDE)</p>
<p>1 . requests 파이썬에서 HTTP 요청을 보내고 응답을 받을 수 있는 라이브러리로, 주로 웹에서 데이터를 가져오거나 서버에 데이터를 전송하는 데 사용된다.</p>
<p>웹사이트와 데이터를 주고받는 과정에서 사용되는 HTTP 프로토콜을 쉽게 다룰 수 있도록 도와준다.</p>
<p>① GET 요청 - requests.get() 웹 페이지의 정보를 가져올 때 사용된다. 이는 브라우저에서 주소를 입력하고 페이지를 여는 것과 같은 동작이다.</p>
<p>② POST 요청 - requests.post() 서버에 데이터를 전송할 때 사용된다. 회원가입, 로그인, 데이터 저장 등의 작업에서 활용된다.</p>
<p>③ JSON 응답 처리 - response.json() 서버에서 JSON 형식의 데이터를 받으면, .json() 메서드를 사용하여 딕셔너리로 변환할 수 있다.</p>
<p>2 . BeautifulSoup4 HTML/XML 문서를 파싱하여 원하는 데이터를 추출하는 라이브러리로, 문서를 구성하는 요소를 개별적인 구조(태그, 속성, 텍스트 등)로 나눈다.</p>
<p>먼저, HTML 문서를 파싱하여 태그 간의 계층을 이해할 수 있는 트리 구조로 변환한다.</p>
<p>이를 통해 특정 태그나 클래스에 접근할 수 있으며, CSS 선택자를 활용하여 원하는 요소를 쉽게 선택할 수 있다.</p>
<p>또한, get_text() 메서드를 사용하면 태그 내부의 텍스트만 추출할 수 있어 데이터 정제 작업이 용이하다.</p>
<p>3 . selenium 웹 브라우저를 자동으로 제어하는 라이브러리로, 클릭, 입력, 스크롤 등의 동작을 수행할 수 있다.</p>
<p>JavaScript로 동적으로 변경되는 웹 페이지의 데이터도 가져올 수 있어 정적인 크롤링 방식보다 더 유연하다.</p>
<p>이를 사용하려면 Chrome, Firefox 등 웹 브라우저에 맞는 드라이버가 필요하며, 이를 통해 실제 브라우저를 실행하고 조작할 수 있다.</p>
<p>과거에는 웹 브라우저와 드라이버의 버전이 맞아야 했지만, 현재는 자동 업데이트 기능 덕분에 큰 문제가 없다.</p>
<p>4 . pandas 데이터 분석 및 처리를 위한 필수 라이브러리로, CSV, Excel, JSON 등의 다양한 형식의 데이터를 데이터프레임으로 불러와 조작할 수 있다.</p>
<p>또한, 결측값을 처리하거나 특정 조건에 따라 데이터를 필터링하고 정렬하는 등 정리 작업이 가능하다.</p>
<p>뿐만 아니라, 데이터를 그룹화하여 분석할 수 있는 groupby() 기능, 기초 통계를 확인할 수 있는 describe() 메서드,</p>
<p>특정 연산을 적용할 수 있는 apply() 메서드 등을 제공하여, 보다 효과적인 데이터 분석을 지원한다.</p>
<p>04 정적 크롤링 다음은 네이버 뉴스 기사에 대해 정적 크롤링을 수행하는 코드이다.</p>
<ol type="1">
<li>설치된 라이브러리를 불러오는 과정.</li>
</ol>
</section>
</section>
<section id="http-요청을-보내기-위한-라이브러리" class="level1">
<h1>HTTP 요청을 보내기 위한 라이브러리</h1>
<p>import requests</p>
</section>
<section id="html-파싱을-위한-라이브러리" class="level1">
<h1>HTML 파싱을 위한 라이브러리</h1>
<p>from bs4 import BeautifulSoup as bs</p>
</section>
<section id="데이터-분석-및-처리-라이브러리" class="level1">
<h1>데이터 분석 및 처리 라이브러리</h1>
<p>import pandas as pd</p>
<ol start="2" type="1">
<li>사용자가 제공한 값을 바탕으로 추출에 대한 기능을 설정하는 과정.</li>
</ol>
</section>
<section id="첫-줄은-검색어-입력을-위한-변수" class="level1">
<h1>첫 줄은 검색어 입력을 위한 변수</h1>
<p>query = input(‘입력 키워드:’)</p>
</section>
<section id="날짜-및-설정-값-입력-모두-변수이며-함수-호출을-포함함" class="level1">
<h1>날짜 및 설정 값 입력 (모두 변수이며, 함수 호출을 포함함)</h1>
<p>start_date = input(‘시작 날짜 (YYYY.MM.DD):’)<br>
end_date = input(‘마지막 날짜 (YYYY.MM.DD):’)<br>
num_pages = int(input(‘추출 페이지 수 기입:’)) # 입력값을 정수로 변환 csv_filename = input(‘파일명 (예: news.csv):’)</p>
</section>
<section id="한-페이지에-표시되는-기사-수-설정-변수." class="level1">
<h1>한 페이지에 표시되는 기사 수 설정 변수.</h1>
<p>num_articles_per_page = 10 # 정수로 설정.</p>
<p>data = [] # 데이터 저장 리스트 입력 키워드: 부동산</p>
</section>
<section id="일반적으로-최소-3개월-이상의-기간을-확보하는-것이-좋다." class="level1">
<h1>일반적으로 최소 3개월 이상의 기간을 확보하는 것이 좋다.</h1>
<p>시작 날짜 (YYYY.MM.DD): 2025.01.01 마지막 날짜 (YYYY.MM.DD): 2025.03.17</p>
<p>추출 페이지 수 기입: 100 파일명 (예: news.csv): 2025.1Q.csv 2025.1Q.csv 파일 저장 완료! 뉴스 개수: 1000개</p>
<ol start="3" type="1">
<li>웹 크롤링 시 웹사이트에 정상적인 요청을 보내기 위한 헤더 설정.</li>
</ol>
<p>headers = { # User-Agent: Chrome 110 버전을 사용 중인 Windows 10 사용자처럼 # 보이도록 해 서버의 차단을 피하고, 요청을 정상 처리하도록 도움. “User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36” }</p>
<ol start="4" type="1">
<li>반복문을 통해 페이지별로 데이터를 요청하는 과정.</li>
</ol>
</section>
<section id="인덱스를-1로-시작하도록-함" class="level1">
<h1>인덱스를 1로 시작하도록 함</h1>
<p>for page in range(1, num_pages + 1):</p>
<pre><code># 네이버 뉴스 페이지네이션 규칙 적용
start_index = 1 + (page - 1) * 10

# URL 생성
search_url = (
    f"https://search.naver.com/search.naver?where=news&amp;sm=tab_jum&amp;query={query}"
    f"&amp;start={start_index}&amp;pd=3&amp;ds={start_date}&amp;de={end_date}"
)

# HTML 문서 가져오기
response = requests.get(search_url, headers=headers)

if response.status_code != 200:
    print(f"페이지 {page} 요청 실패 (상태 코드: {response.status_code})")
    continue</code></pre>
<ol start="5" type="1">
<li><p>뉴스기사 제목 가져오기.</p>
<p>soup = bs(response.text, ‘html.parser’) # 파싱 titles = soup.select(‘a.news_tit’) # 네이버 뉴스 타이틀 선택자</p>
<p>for title in titles: data.append(title.get_text()) # 추출한 제목 데이터 추가</p>
<p>time.sleep(1) # 요청 간격 조정 (너무 빠르면 차단될 가능성 있음)</p></li>
<li><p>뉴스 제목 데이터를 데이터프레임으로 변환한 뒤, CSV 파일로 저장하는 역할을 한다.</p></li>
</ol>
</section>
<section id="리스트는-단순한-배열이므로-데이터를-체계적으로-정리하기-어렵다." class="level1">
<h1>리스트는 단순한 배열이므로, 데이터를 체계적으로 정리하기 어렵다.</h1>
</section>
<section id="데이터프레임은-표-형태로-데이터를-저장하므로-한눈에-보기-쉽고-컬럼별로-정리할-수-있다." class="level1">
<h1>데이터프레임은 표 형태로 데이터를 저장하므로, 한눈에 보기 쉽고 컬럼별로 정리할 수 있다.</h1>
</section>
<section id="데이터프레임-생성" class="level1">
<h1>데이터프레임 생성</h1>
<p>df = pd.DataFrame(data, columns=[‘뉴스 제목’])</p>
</section>
<section id="csv-저장" class="level1">
<h1>CSV 저장</h1>
<p>csv_filename = input(‘파일명 (예: news.csv):’) df.to_csv(csv_filename, index=False, encoding=‘utf-8-sig’)</p>
<p>print(f”{csv_filename} 파일 저장 완료! 뉴스 개수: {len(df)}개”)</p>
<p>05 데이터 전처리</p>
<ol type="1">
<li>라이브러리 불러오기.</li>
</ol>
<p>from wordcloud import WordCloud # 워드 클라우드 생성 import matplotlib.pyplot as plt # 데이터 시각화 (그래프, 이미지 출력) from collections import Counter # 단어 빈도수 계산을 위한 라이브러리</p>
<p>import re # 정규표현식을 활용한 텍스트 전처리 (특정 문자 제거, 패턴 찾기 등) import pandas as pd # 데이터프레임을 활용한 데이터 처리 및 분석 from konlpy.tag import Okt # 한국어 형태소 분석기(Open Korean Text), (단어 추출 및 품사 태깅)</p>
<ol start="2" type="1">
<li>CSV 파일에서 뉴스 제목 추출 및 결합.</li>
</ol>
</section>
<section id="csv-파일-로드" class="level1">
<h1>CSV 파일 로드</h1>
<p>csv_filename = input(“CSV 파일 경로:”) df = pd.read_csv(csv_filename)</p>
</section>
<section id="nan-값-제거" class="level1">
<h1>NaN 값 제거</h1>
<p>df = df.dropna(subset=[‘뉴스 제목’])</p>
</section>
<section id="c열뉴스-제목을-하나의-문자열로-결합" class="level1">
<h1>C열(뉴스 제목)을 하나의 문자열로 결합</h1>
<p>c_list = df[‘뉴스 제목’].tolist()</p>
</section>
<section id="리스트를-하나의-벡터-자료로-합치기" class="level1">
<h1>리스트를 하나의 벡터 자료로 합치기</h1>
<p>vector = ’ ’.join(c_list)</p>
<ol start="3" type="1">
<li>형태소 분석을 통한 명사 추출 및 빈도수 계산.</li>
</ol>
</section>
<section id="형태소-분석-명사-추출" class="level1">
<h1>형태소 분석 (명사 추출)</h1>
<p>okt = Okt() nouns = okt.nouns(vector)</p>
</section>
<section id="한-글자-단어-제거" class="level1">
<h1>한 글자 단어 제거</h1>
<p>filtered_nouns = [word for word in nouns if len(word) &gt; 1]</p>
</section>
<section id="불용어-리스트" class="level1">
<h1>불용어 리스트</h1>
<p>stop_words = [‘부동산, 한국’] # 필요시 추가</p>
</section>
<section id="불용어-제거" class="level1">
<h1>불용어 제거</h1>
<p>filtered_words = [word for word in filtered_nouns if word not in stop_words]</p>
</section>
<section id="단어-빈도수-계산" class="level1">
<h1>단어 빈도수 계산</h1>
<p>word_counts = Counter(filtered_words) print(word_counts.most_common(10)) # 가장 많이 나온 단어 10개 출력</p>
<p>06 워드 클라우드 워드 클라우드 생성하기.</p>
<p>try: wordcloud = WordCloud( # Windows의 ‘Malgun Gothic’ 폰트 font_path=“C:/Users/jkl12/Downloads/NanumGothicBold.otf”, width=800, height=400, background_color=‘white’, colormap = “Accent” # 칼라맵 ).generate_from_frequencies(word_counts)</p>
<p>except: wordcloud = WordCloud( font_path=None, # 기본 폰트로 설정 (Mac/Linux 대비) width=800, height=400, background_color=‘white’ ).generate_from_frequencies(word_counts)</p>
</section>
<section id="그래프-출력" class="level1">
<h1>그래프 출력</h1>
<p>plt.figure(figsize=(10, 5)) plt.imshow(wordcloud, interpolation=‘bilinear’) plt.axis(‘off’) plt.show() CSV 파일 경로: 2025.1Q.csv [(‘투자’, 139), (‘서울’, 122), (‘금융’, 117), (‘집값’, 94), (‘시장’, 79), (‘거래’, 76), (‘주택’, 71), (‘강남’, 71), (‘아파트’, 66), (‘펀드’, 64)]</p>
<p># 특이한 형태의 시각화는 정보 왜곡을 초래할 수 있으므로, # 가능한 한 전통적인 형태로 출력하는 것이 더 효과적이다.</p>


</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/tm/tm_02_0.html</guid>
  <pubDate>Mon, 10 Mar 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_07_0.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_07_0.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_08_0.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_08_0.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_08_1.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_08_1.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_08_2.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_08_2.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_09_0.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_09_0.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_09_1.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_09_1.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_10_0.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_10_0.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_10_1.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_10_1.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_10_2.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_10_2.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title></title>
  <dc:creator>파이썬을 활용한 데이터 분석과 응용</dc:creator>
  <link>https://shinjihan.github.io/studylog/da/ada/ada_10_3.html</link>
  <description><![CDATA[ 







 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <guid>https://shinjihan.github.io/studylog/da/ada/ada_10_3.html</guid>
  <pubDate>Fri, 27 Sep 2024 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
