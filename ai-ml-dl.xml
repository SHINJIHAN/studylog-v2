<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>StudyLog</title>
<link>https://shinjihan.github.io/studylog/ai-ml-dl.html</link>
<atom:link href="https://shinjihan.github.io/studylog/ai-ml-dl.xml" rel="self" type="application/rss+xml"/>
<description>통계와 AI를 기록하는 개인 블로그</description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Tue, 02 Dec 2025 15:00:00 GMT</lastBuildDate>
<item>
  <title>인공신경망</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_16.html</link>
  <description><![CDATA[ 




<p>딥러닝 모델의 학습 과정은 고차원 매개변수 공간에서의 비선형 최적화 문제로 구성되며, 네트워크는 일반적으로 ’Affine → Batch Normalization → ReLU’의 층 구조를 반복적으로 적용하고 마지막 단계에서 Affine 변환 후 Softmax를 통해 확률적 출력 분포를 생성한다. 이 구조는 표현 학습 과정에서 분산 안정화, 비선형성 확보, 기울기 흐름 유지라는 세 가지 관점에서 수학적으로 정당화된다.</p>
<p>학습 과정의 이론적 핵심 중 하나는 <strong>바이어스-분산 트레이드오프</strong>이다. 바이어스는 모델의 구조적 단순화로 인해 발생하는 체계적 오차이며, 분산은 데이터의 작은 변화에 모델이 과도하게 반응하며 발생하는 민감도이다. 이 두 요소는 역비례적 관계에 있어, 바이어스를 지나치게 줄이기 위해 모델 복잡성을 높이면 분산이 급격히 증가하여 일반화 성능이 악화된다(오버피팅). 반대로 분산을 줄이기 위해 모델을 지나치게 단순화하면 고정적 편향이 커져 언더피팅이 발생한다. 적절한 최적점은 검증 데이터의 경험적 리스크 최소 지점을 찾는 방식으로 설정된다.</p>
<p>오버피팅이 발생하는 상황에서는 모델이 훈련 데이터의 세부적 노이즈 패턴까지 과도하게 학습하는데, 이는 파라미터 수가 데이터에 비해 과도하게 많거나, 데이터 분포의 다양성이 충분치 않을 때 더욱 심화된다. 이를 완화하기 위한 실질적 접근으로는 <strong>상위 다중 정답(top-k) 평가 지표 사용</strong>, <strong>훈련 데이터의 증강</strong>, <strong>범주별 데이터 균형화</strong>, <strong>정규화(regularization)</strong> 등이 있다.</p>
<p>정규화 중에서도 L2 정규화(가중치 감소)는 기하학적 관점에서 파라미터 공간을 L2 볼 안에 구속하는 효과를 갖는다. 손실 함수에 라그랑주 항 형태로 λ‖W‖²가 추가되며, 이는 고차원 공간에서 가중치 벡터의 크기를 제어해 최적점이 과도하게 한 방향으로 치우치지 않도록 한다. 수식적으로는 단순히 항을 더하는 것으로 보일 수 있으나, 실제로는 매개변수 공간의 형태를 바꾸어(implicit geometry alteration) 최적화 경로와 수렴 특성을 근본적으로 변화시키는 역할을 한다.</p>
<p>언더피팅을 해결하기 위해서는 <strong>특징(feature) 확장</strong>, <strong>비선형성이 높은 모델(KNN, SVM, Decision Tree 등)</strong>의 활용, 그리고 <strong>모델 용량 증가</strong>가 효과적이다. 본질적으로 언더피팅은 함수 공간 자체의 표현력이 낮을 때 발생한다.</p>
<p>데이터셋의 규모 또한 모델 성능에 강한 영향을 준다. 데이터가 적으면 분산이 높아지고 신뢰도 낮은 추정이 발생한다. 이를 보완하기 위해 전통적 데이터 증강뿐 아니라, 최근에는 생성형 모델을 통한 고차원적 데이터 증강이 활용된다. 이는 단순 변환 기반 증강보다 데이터 다양성을 보다 풍부하게 확보할 수 있다는 점에서 중요한 의미를 가진다.</p>
<p>드롭아웃(dropout)은 완전 연결 계층(fully connected layer)에서 특정 뉴런을 확률적으로 비활성화하여 특정 패턴에 대한 파라미터 공동 의존성을 줄이는 방식이다. 이는 모델이 특정 경로에 과도하게 적응하는 것을 방지해 일반화 오차를 개선하며, 수학적으로는 앙상블 평균 효과를 근사하는 것으로 해석된다. 단, 드롭아웃은 학습 시에만 적용되고, 추론 단계에서는 비활성화된 뉴런을 포함한 전체 네트워크를 사용한다.</p>
<p>또한, <strong>교차 검증(cross validation)</strong>은 모델의 일반화 오류를 안정적으로 추정하기 위해 데이터셋을 K개의 폴드(fold)로 분할하여 반복적으로 평가하는 방법이다. 이는 단일 분할로 인한 편향을 제거하고 모델의 평균적 성능을 측정하는 데 필수적이다.</p>
<p>종합적으로, 이러한 최적화 기법·정규화 전략·데이터 관리 기법들은 딥러닝에서 안정적인 학습과 일반화 성능 향상의 핵심 요소이며, 실험 환경에서 모델의 성능을 체계적으로 평가하기 위한 기본적 도구들이다.</p>
<hr>
<p>모델링의 목적과 목표 변수의 특성은 평가 지표 선택의 이론적·실무적 정당성을 결정하는 핵심 요소이다. 각 지표는 통계적 특성, 손실 함수의 기하학적 구조, 모델의 오차 감도 등을 반영하고 있으므로, 단순 비교가 아니라 ’데이터 생성 과정(DSG: Data-Generating Process)’과 ’목표 함수의 성질’을 고려해 해석해야 한다.</p>
<ol type="1">
<li><p><strong>예측·회귀 모델의 성능 평가</strong> 회귀 문제에서 사용되는 지표들은 대부분 오차의 분포적 성질과 민감도를 달리한다.</p>
<ul>
<li><strong>MSE(Mean Squared Error)</strong>: 잔차의 제곱을 평균한 값으로, 큰 오차에 대해 제곱 패널티를 부여함으로써 이상치(outlier)에 매우 민감하다. 이는 L2-리스크 최소화와 연결되며, 확률적 관점에서 정규분포 오차 가정에 대한 최대우도추정(MLE)과 동등하다.</li>
<li><strong>RMSE(Root MSE)</strong>: MSE의 제곱근으로 단위를 원래 스케일로 복구한다. 기하학적으로는 L2-거리 기반 손실이며, 곡률이 크기 때문에 경사 기반 최적화에서 강한 페널티를 제공한다.</li>
<li><strong>MAPE(Mean Absolute Percentage Error)</strong>: 상대적 오차 비율을 측정하므로 스케일이 다른 시계열·수요 예측 등에서 많이 사용된다. 다만 목표값이 0에 근접하면 불안정해진다는 결함이 있다.</li>
<li><strong>Weighted Quantile Loss(평균 가중 분위수 손실)</strong>: 분위수 회귀(quantile regression)의 손실로, 비대칭 오차 구조(과소·과대 예측 비용이 다름)를 모델링할 때 적합하다. 수치 예측에서 리스크 기반 의사결정(예: 보험·수요 예측)에 널리 사용된다.</li>
<li><strong>WASE(Weighted Absolute Scaled Error)</strong>: 시계열 예측 평가에서 사용되며, 단순 차분 기반 성능 대비 상대적 향상을 평가할 수 있다.</li>
</ul></li>
<li><p><strong>분류 모델의 성능 평가</strong> 분류 지표는 클래스 불균형, 임계값(threshold), 비용 민감도에 따라 해석이 크게 달라진다.</p>
<ul>
<li><strong>Accuracy(정확도)</strong>: 전체 예측 중 맞춘 비율이지만, 클래스 불균형이 존재할 경우 의미가 급격히 저하된다.</li>
<li><strong>Precision(정밀도 = TP/(TP+FP))</strong>: 양성 예측 중 실제로 양성인 비율로, FP에 대한 비용이 큰 문제에서 핵심 지표가 된다.</li>
<li><strong>Recall(재현율 = TP/(TP+FN))</strong>: 실제 양성 중 모델이 탐지한 비율로, FN 비용이 큰 의료·보안 도메인에서 매우 중요하다.</li>
<li><strong>Confusion Matrix(오차 행렬)</strong>: 클래스 간 오차 구조를 직접 파악할 수 있으며, 이후 ROC·PR 커브 분석의 기초가 된다.</li>
<li><strong>F1 Score</strong>: 정밀도와 재현율의 조화평균으로, 두 지표 간 균형이 중요할 때 사용된다. 특히 불균형 데이터에서 모델 선택에 핵심 지표가 될 수 있다. 분류 문제에서는 단순 지표 나열보다, “어떤 오류가 비용 측면에서 가장 치명적인가?”를 우선적으로 판단해야 한다.</li>
</ul></li>
<li><p><strong>객체 탐지 모델의 성능 평가</strong> 객체 탐지 문제는 공간적 위치(Localization)와 클래스 분류(Classification)가 동시에 존재하는 복합 구조다.</p>
<ul>
<li><strong>IoU(Intersection over Union)</strong>: 예측 박스와 실제 박스의 겹침 비율을 나타내는 핵심 지표로, 공간적 정합도(spatial alignment)를 정량화한다. 특정 IoU 임계값(예: 0.5, 0.75 등)에 따라 AP(Average Precision)을 계산하며, 이는 COCO·Pascal VOC 등 주요 벤치마크의 기본 평가 기준이다.</li>
</ul></li>
</ol>
<p>종합하면, 성능 평가는 단순히 지표를 선택하는 과정이 아니라 <strong>문제의 목적 함수, 오차 비용 구조, 데이터 통계적 특성</strong>을 기반으로 이루어져야 하며, 동일 모델이라도 지표 선택에 따라 결론이 달라질 수 있음을 항상 고려해야 한다.</p>
<hr>
<p>클러스터링은 분류의 한 종류이다. 이것은 비지도 학습이다.</p>
<p>이것의 예시는 회원관리서비스에서 주로 쓰인다. 고객을 관리하고 분류해서 등급을 나누고 그에 걸맞는 서비스를 주는 것이다.</p>
<p>이를 전문용어로 CRM이라 한다.</p>
<p>분류 &gt; 세그멘테이션 &gt; 클러스터링으로 좁아지는 형태</p>
<p>그런 그룹을 많이 만들어서 디테일한 서비스를 제공한다면&nbsp; 이는 좋을 수도 있지만 비용적인 측면이 높을 수 있으니 경영적인 측면에선 덜 디테일한 것이 오히려 실무진 입장에선 좋을 수 있음.</p>
<p>이때 그룹잉의 기준 중 하나인 거리기반 그룹잉이 있다.</p>
<p>하이-인트라-클레스 유사도</p>
<p>로우-인트라-클레스 유사도</p>
<p>둘 중 하나로 데이터 세트를 클래스 구성한다. 이를 통해 클래스 레이블과 클래스 개수를 찾아낸다.</p>
<p>클러스터링 알고리즘 수행 시 선호되는 속성들</p>
<ol type="1">
<li>시간과 공간적 관점에서의 규모</li>
<li>서로 다른 타입(유형)의 데이터를 다룰 수 있는 능력</li>
<li>입력 파라미터들을 결정하기 위한 최소한의 도메인 지식</li>
<li>잡음과 이상치를 다룰 수 있는지 여부, 또한 판별도 해야 함.</li>
<li>입력 레코드의 순서에 민감하지 않아야 함, 최근 과거 상관없이 섞어서 골고루.</li>
<li>사용자 관점의 제약 조건 반영 여부, 코로나 시기 등.</li>
<li>결과에 대한 해석능력과 사용성,&nbsp;</li>
</ol>
<p>거리를 계산할 때, 가장 근접 계산 방법과 가장 멀리 떨어진 계산 방법의 차이는 전향적 계산과 보수적 계산으로 나뉘는 것이다. 이것의 중간인 평균 거리 계산도 있다. 워드 링크잉은 합병괸 클러스터들의 분산을 최소화하려고 한다는 것.</p>
<p>거리 측정 방법의 종류</p>
<ol type="1">
<li><p>유클리드 거리(가장 많이 쓰는 방법, 대각선 즉, 직선 거리) 이것은 항공 네비에서 쓰일 수 있다. 사이킷런에서 파라미터로 p=1로 줄 수 있다.</p></li>
<li><p>맨하튼 거리, 바로 대각선으로 가로지르지 않고 가로 세로 몇 블록인지 가는 방법. 이는 보통 자동차 네비게이션에서 쓰인다. 사잇클런에서 파라미터로 p=2로 줄 수 있다.</p></li>
<li><p>최대 놈, 점들의 분포를 고려한 거리 공분산을 고려한 것. 중심이 아니라 데이터의 분포가 곧 가중치가 된다.</p></li>
<li><p>마할라노비스 거리</p></li>
<li><p>코사인 거리, 문서간 유사도 자카드 계수(희박한 데이터에 유용), 편집거리(검색창 등)도 있다. 피어슨 상관계수. “문서”든 “영화”든 결국 벡터로 표현할 수 있으며, 유사도는 벡터 간 거리로 계산되므로 문서 유사도 방식 그대로 영화 등 다양한 비정형 데이터 추천·검색·분류에 활용된다.</p></li>
<li><p>편집거리의 연산들: 헤밍, 레벤슈타인 거리 등</p></li>
</ol>
<p>알고리즘릭하게 하거나 학습을 시켜서 하거나 둘 중 하나일 것이다.</p>
<p>클러스터링 유형</p>
<ol type="1">
<li>중심 기반(가장 자주 사용하는 방법, 쉬운 개산, 개수 정하기 힘듦)</li>
<li>중간점 기반</li>
<li>밀도 기반</li>
<li>계층적 기반</li>
</ol>
<hr>
<section id="벡터-변환" class="level1">
<h1>03 벡터 변환</h1>
<p>영화의 <strong>장르·감독·가격</strong>처럼 서로 다른 속성(이질적 특징)이 <strong>문서 간 유사도</strong>에 사용될 때는, 모든 속성을 <em>같은 공간에서 비교 가능하도록 변환</em>한 뒤 벡터 형태로 통합한다.</p>
<p>핵심은 <strong>표현 통일 → 벡터화 → 가중 결합 → 유사도 계산</strong>이다.</p>
<ol type="1">
<li>서로 다른 개념을 “벡터 공간”으로 통일</li>
</ol>
<p>문서는 텍스트가 아니어도 <strong>모든 특징을 숫자 벡터(feature vector)</strong>로 바꿀 수 있다.</p>
<p><strong>범주형(장르, 감독)</strong></p>
<ul>
<li><p><strong>One-hot encoding</strong>, <strong>Multi-hot encoding</strong>, <strong>Embedding</strong>을 사용</p></li>
<li><p>예: 장르 = {액션, 드라마, SF}</p>
<ul>
<li>한 영화가 액션·SF라면 → <code>[1, 0, 1]</code></li>
</ul></li>
<li><p>감독도 동일한 방식 → 감독 수가 많으면 embedding 사용</p></li>
</ul>
<p><strong>연속형(가격, 평점, 상영시간)</strong></p>
<ul>
<li>그대로 사용하되 <strong>정규화(normalization)</strong> 적용 예: 가격을 0~1 사이로 스케일링</li>
</ul>
<ol start="2" type="1">
<li>모든 특징을 하나의 대형 벡터로 결합</li>
</ol>
<p>예시:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>특징</th>
<th>표현</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>장르</td>
<td><code>[1, 0, 1, 0, 0]</code></td>
</tr>
<tr class="even">
<td>감독</td>
<td><code>[0, 0, 1, 0, 0, …]</code></td>
</tr>
<tr class="odd">
<td>가격</td>
<td><code>0.42</code></td>
</tr>
<tr class="even">
<td>평점</td>
<td><code>0.88</code></td>
</tr>
</tbody>
</table>
<p>→ 최종 문서 벡터: <code>[1, 0, 1, 0, 0, | 0, 0, 1, 0, 0, … | 0.42 | 0.88]</code></p>
<p>이렇게 하면 “완전히 다른 개념”도 하나의 벡터 안에서 함께 존재할 수 있음.</p>
</section>
<section id="속성별-영향력중요도을-조절" class="level1">
<h1>3. 속성별 영향력(중요도)을 조절</h1>
<p>속성이 본질적으로 다르기 때문에 <strong>가중치(weight)</strong>를 준다.</p>
<p>예:</p>
<ul>
<li>줄거리 텍스트: 50%</li>
<li>장르: 30%</li>
<li>감독: 10%</li>
<li>가격: 10%</li>
</ul>
<p>이를 반영하면,</p>
<ul>
<li>감독이 다르다고 해서 문서 유사도가 0이 되는 것을 방지</li>
<li>가격 같은 숫자형 특징이 과도하게 영향 주는 것도 방지</li>
</ul>
<ol start="4" type="1">
<li>결합된 벡터에 <strong>코사인 유사도</strong>를 적용</li>
</ol>
<p>최종적으로는 두 영화 벡터의 코사인 유사도를 계산:</p>
<p>[ (A, B) = ]</p>
<p>이렇게 하면</p>
<ul>
<li>장르가 비슷하면 해당 부분 벡터가 기여</li>
<li>가격·감독이 비슷하면 그 부분이 기여</li>
<li>전체적으로 종합된 유사도가 나옴</li>
</ul>
<ol start="5" type="1">
<li>핵심 정리</li>
</ol>
<ul>
<li><strong>서로 다른 개념</strong>이어도 → 모두 <strong>동일한 벡터 공간의 차원</strong>으로 변환</li>
<li><strong>각 속성을 수치화</strong>한 뒤 하나의 벡터로 결합</li>
<li>필요하면 <strong>가중치</strong>를 부여</li>
<li>마지막에는 <strong>코사인 유사도</strong>로 비교</li>
</ul>
<hr>
<p>핵심은 <strong>“서로 다른 정보들을 모두 숫자 벡터로 만들어 하나의 ’영화 프로필’로 통합하고, 그 프로필끼리 유사도를 비교한다”</strong>는 점입니다. 이게 가능한 이유는 <strong>모든 종류의 데이터(장르·감독·가격·텍스트 등)는 결국 수치화할 수 있기 때문</strong>입니다.</p>
<ol type="1">
<li>핵심 1: 모든 속성을 한 줄짜리 숫자 벡터로 만든다</li>
</ol>
<p>영화마다 <strong>정리된 요약 정보(프로필)</strong>를 하나의 벡터로 만든다고 생각하면 됩니다.</p>
<p>예:</p>
<ul>
<li>“액션·SF” → [1, 0, 1]</li>
<li>“감독 A” → [0, 1, 0, 0]</li>
<li>“가격 9,000원” → 0.45</li>
<li>“평점 8.3” → 0.83</li>
</ul>
<p>→ 결국 하나의 벡터: <code>[1, 0, 1, 0, 1, 0, 0, 0.45, 0.83]</code></p>
<ol start="2" type="1">
<li>핵심 2: 두 영화 벡터의 거리를 비교하면 ’비슷한 영화’가 된다</li>
</ol>
<p>벡터 A와 벡터 B가 비슷하면 → 영화도 비슷하다고 판단. 다르면 → 유사도가 낮다. 즉, <strong>문서(영화) 간 유사도 = 벡터 간 유사도</strong> 이 원리 하나로 모든 속성이 비교 가능해진다.</p>
<ol start="3" type="1">
<li>핵심 3: 활용되는 곳 (실제 사례)</li>
</ol>
<p><strong>추천 시스템</strong></p>
<ul>
<li>사용자가 본 영화와 비슷한 벡터를 가진 영화를 찾아 추천</li>
<li>장르·감독·가격·평점 모두 반영된 추천 가능</li>
</ul>
<p><strong>콘텐츠 검색</strong></p>
<ul>
<li>“액션이면서 SF 느낌 나는 영화” → 장르 벡터와 유사한 영화 자동 추출</li>
</ul>
<p><strong>마케팅 타겟팅</strong></p>
<ul>
<li>특정 가격대 + 특정 감독 선호 + 특정 장르 조합을 가진 영화군 자동 분류</li>
</ul>
<p><strong>클러스터링(군집)</strong></p>
<ul>
<li>영화 전체를 벡터화 → 비슷한 영화끼리 자동 그룹화</li>
<li>가격/감독/장르 차이까지 포함해 군집 생성 가능</li>
</ul>
<hr>
<p>문서 유사도와 “영화 유사도(메타데이터 기반)”가 <strong>완전히 같은 원리</strong>로 작동한다는 점이 핵심입니다. 즉, <strong>문서를 비교하든 영화를 비교하든 결국 ’특징 벡터 간 거리 비교’라는 한 원리를 공유</strong>합니다.</p>
<ol type="1">
<li>문서 유사도 계산의 본질</li>
</ol>
<p>문서 유사도는 일반적으로 다음 절차를 따릅니다.</p>
<ol type="1">
<li><p>문서를 <strong>특징 벡터(feature vector)</strong>로 변환</p>
<ul>
<li>단어를 TF-IDF, BOW, Embedding 등으로 숫자 벡터화</li>
</ul></li>
<li><p>문서 간 <strong>코사인 유사도</strong>를 계산</p></li>
<li><p>유사한 문서를 찾음</p></li>
</ol>
<p>즉, <strong>문서 → 벡터, 문서 간 유사도 = 벡터 간 유사도</strong> 이 구조입니다.</p>
<ol start="2" type="1">
<li>영화도 “문서 취급”해서 동일한 구조로 비교</li>
</ol>
<p>영화는 텍스트가 아니지만, 다음 속성들을 모두 <strong>숫자 벡터</strong>로 변환할 수 있습니다.</p>
<ul>
<li>장르</li>
<li>감독</li>
<li>배우</li>
<li>상영시간</li>
<li>가격</li>
<li>평점</li>
<li>줄거리 텍스트(TF-IDF, embedding)</li>
</ul>
<p>이걸 하나의 벡터로 합치면, <strong>영화 = 문서와 동일한 ’특징 벡터’가 됨</strong> 따라서 문서 유사도와 완전히 같은 방식으로 비교할 수 있다.</p>
<ol start="3" type="1">
<li>문서 유사도 = 특징 벡터 유사도</li>
</ol>
<p>영화도 문서도 결국, <strong>“특징 벡터끼리의 거리/유사도 계산”</strong>으로 정의됩니다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 54%">
<col style="width: 18%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th>비교 대상</th>
<th>벡터 만드는 방식</th>
<th>유사도 계산</th>
<th>결과</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>문서</td>
<td>단어 벡터(TF-IDF 등)</td>
<td>코사인 유사도</td>
<td>유사 문서</td>
</tr>
<tr class="even">
<td>영화</td>
<td>장르/감독/가격/텍스트 등 통합 벡터</td>
<td>코사인 유사도</td>
<td>유사 영화</td>
</tr>
</tbody>
</table>
<p>둘이 100% 동일한 구조입니다.</p>
<ol start="4" type="1">
<li>활용 방식: 문서 유사도와 완전히 동일</li>
</ol>
<p>문서 유사도가 다음을 가능하게 하듯:</p>
<ul>
<li>비슷한 문서 검색</li>
<li>토픽 클러스터링</li>
<li>문서 분류</li>
<li>유사 문서 추천</li>
</ul>
<p>영화도 같은 방식으로 활용 가능합니다.</p>
<p>예)</p>
<ol type="1">
<li>사용자가 본 영화 A → 벡터(A)</li>
<li>전체 영화 벡터 중 벡터(A)와 가장 가까운 영화들 검색 → <strong>영화 추천 시스템 구현</strong></li>
</ol>
<p>즉,</p>
<blockquote class="blockquote">
<p>문서 추천에서 문서를 “영화”로 바꾸기만 하면 그대로 적용된다.</p>
</blockquote>
<hr>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_16.html</guid>
  <pubDate>Tue, 02 Dec 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>로지스틱 분류</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_11.html</link>
  <description><![CDATA[ 




<p>[주제] 에 대해 다루고자 한다.</p>
<p>01 최적화 알고리즘</p>
<p>Alec Radford’s animations for optimization algorithms</p>
<p>Alec Radford has created some great animations comparing optimization algorithms SGD , Momentum , NAG , Adagrad , Adadelta , RMSprop (unfo…</p>
<p>www.denizyuret.com 기본 SGD 외에 다음과 같은 변형을 자주 사용한다.</p>
<p>SGD (확률적 경사하강) — 큰 데이터셋에 효율적 Momentum — 관성 도입으로 수렴 가속 및 진동 완화 AdaGrad — 좌표별 학습률 적응 Adam — 1차·2차 모멘트를 사용한 적응형 방법 (실무에서 널리 사용; 성능·안정성 우수)</p>
<ol type="1">
<li>모델 검증과 일반화 7.1 K-Fold 교차검증 모델 성능 평가를 위해 데이터를 K개의 폴드(fold)로 나누고, 순차적으로 하나의 폴드를 검증셋으로, 나머지를 학습셋으로 사용한다.</li>
</ol>
<p>데이터를 K등분 (예: 5-fold → 5등분) 각 iteration마다 서로 다른 폴드를 검증셋으로 지정 K번 반복 후 평균 성능 산출 특수 사례: LOOCV(Leave-One-Out CV)</p>
<p>데이터 포인트 하나를 검증셋으로, 나머지를 학습셋으로 사용 데이터가 적을 때 모델 평가를 정밀하게 할 수 있음 7.2 학습률(Learning Rate)과 데이터 전처리 학습률은 경사하강법의 파라미터 갱신 속도를 조절하며, 과도하면 발산, 너무 작으면 수렴 속도가 느려진다. 데이터 전처리는 모델 안정성과 성능 향상에 중요하며, 일반적으로 정규화(normalization), 스케일링(scaling), 결측치 처리 등을 포함한다. 7.3 오버피팅 방지 모델이 학습 데이터에만 과적합되는 것을 방지하기 위해 다양한 전략을 사용한다.</p>
<p>데이터 증강(Data Augmentation): 학습 데이터 변형을 통해 다양성을 확보 특징 수 축소(Feature Selection/Reduction): 불필요한 입력 제거 정규화(Regularization): L1/L2 정규화, 드롭아웃(Dropout) 등 이 과정을 통해 모델은 학습 데이터뿐 아니라 미지의 데이터에서도 일반화 성능을 발휘할 수 있다.</p>
<p>03 퍼셉트론과 다층 신경망 Perceptron &amp;Multi-Layer Neural Network</p>
<p>1 . 신경망의 구조와 활성화 함수 인공신경망(NN)은 생물학적 뉴런을 모사하여 입력 신호를 처리한다.</p>
<p>입력 신호(x0,x1,…x_0, x_1, ​,x1​,…): 다른 뉴런(axon)으로부터 전달되는 신호 가중치(w0,w1,…w_0, w_1, ​,w1​,…): 각 신호의 중요도를 나타내며, 시냅스(synapse)와 유사 가중합(dendrite): 각 입력에 가중치를 곱한 후 합산 <img src="https://latex.codecogs.com/png.latex?z%20=%20%5Csum_i%20w_i%20x_i%20+%20b"></p>
<p>활성화 함수(Activation Function, f): 뉴런의 세포체(cell body)가 총합 입력을 해석하여 출력 신호 생성 <img src="https://latex.codecogs.com/png.latex?y%20=%20f(z)%20=%20f%5CBig(%5Csum_i%20w_i%20x_i%20+%20b%5CBig)"></p>
<p>출력 y는 다음 뉴런(axon)으로 전달되며, 이 신호가 0인지 1인지 또는 확률값인지 결정한다. 이 구조를 MLP이라고 하며, 다층 구성으로 비선형 문제를 해결할 수 있다.</p>
<p>2 . 역사적 배경 Frank Rosenblatt (1957): 퍼셉트론(Perceptron) 제안 — 단층 신경망 기반의 이진 분류기 Widrow &amp; Hoff (1960): ADALINE(Adaptive Linear Neuron) / MADALINE — 가중치 적응 학습 규칙 제안 Widrow-Hoff Rule (Delta Rule) 가중치 학습 과정은 다음과 같다.</p>
<p>가중치 초기화Wi(0)을 임의값으로 설정W_i(0) Wi​(0)을 임의값으로 설정 입력 패턴과 목표 출력 제시 출력 계산 (Hard Limiter) <img src="https://latex.codecogs.com/png.latex?y(t)%20=%20f_h%5CBig(%5Csum_%7Bi=0%7D%5E%7Bn-1%7D%20w_i(t)%20X_i(t)%20-%20%5Cepsilon%5CBig)"></p>
<p>: 임계치 f_h​: 하드리미터 함수 가중치 갱신 <img src="https://latex.codecogs.com/png.latex?W_i(t+1)%20=%20W_i(t)%20+%20%5Calpha%20%5C,%5B%5C,d(t)%20-%20y(t)%5C,%5D%20X_i(t),%20%5Cquad%200%20%5Cle%20i%20%5Cle%20n-1"></p>
<p>: 학습률, 0 &lt; &lt; 1 d(t): 목표 출력값 실제 출력과 목표 출력이 일치하면 가중치는 변하지 않음 반복 수행 출력이 목표에 도달할 때까지 2~4단계 반복</p>
<p>3 . 퍼셉트론을 통한 논리 연산 퍼셉트론은 기본적인 논리 게이트 연산을 구현할 수 있다.</p>
<p>AND, OR 연산: 입력값의 가중합이 임계치(θ)를 초과하면 출력 1, 아니면 0 XOR 연산: 단층 퍼셉트론으로는 직선 결정경계로 구분 불가능 — 다층 퍼셉트론 필요 입력 X_0, X_1 ​AND OR XOR 0, 0 0 0 0 0, 1 0 1 1 1, 0 0 1 1 1, 1 1 1 0 AND: 위쪽 위치, 직선 결정 가능 OR: 아래쪽 위치, 직선 결정 가능 XOR: 직선 결정 불가, 곡선 또는 다층 구조 필요</p>
<p>03 다층 퍼셉트론과 역전파 Backpropagation</p>
<ol type="1">
<li>초기 비관과 연구의 침체기 1969년, Marvin Minsky 교수와 Seymour Papert는 저서 Perceptrons에서 다음과 같이 지적했다.</li>
</ol>
<p>“멀티 레이어 퍼셉트론(Multi-Layer Perceptron)으로 구성하면 문제를 해결할 수는 있지만, 실제로 구현하는 사람은 아무도 없을 것이다.”</p>
<p>이로 인해 퍼셉트론 연구는 <strong>첫 번째 머신러닝 침체기(Artificial Intelligence Winter)</strong>를 맞이하게 되었다.</p>
<p>단층 퍼셉트론으로 XOR와 같은 비선형 문제를 해결할 수 없다는 한계 다층 구조의 학습 방법 부재 2. 역전파(Backpropagation)의 등장 1974년과 1982년, Paul Werbos는 다층 신경망의 학습 문제를 해결할 방법을 제안했으며, 1986년, Geoffrey Hinton 등이 이를 체계화하였다.</p>
<p>핵심 아이디어: 순방향(forward)으로 출력과 실제값의 차이(오차)를 계산 출력층에서 입력층 방향으로 오차를 역전파(backpropagation) 하여 각 가중치를 조정 이로써 단층 퍼셉트론으로 해결할 수 없었던 XOR 등 비선형 문제도 학습 가능하게 되었다.</p>
<ol start="3" type="1">
<li>수학적 원리 다층 퍼셉트론에서 각 뉴런의 출력은 다음과 같이 정의된다.</li>
</ol>
<p>f=wx+bf = w x + bf=wx+b</p>
<p>또는 단계적으로,</p>
<p>g=wx,f=g+bg = w x, f = g + bg=wx,f=g+b</p>
<p><strong>체인룰(Chain Rule)</strong>과 편미분을 이용하여, 출력 오차를 각 층의 가중치에 대해 분배한다. 미분의 기본 정의: ddxf(x)=lim⁡Δx→0f(x+Δx)−f(x)Δx f(x) = _{x } dxd​f(x)=Δx→0lim​Δxf(x+Δx)−f(x)​</p>
<p>예제: 2차원 입력 x1,x2x_1, x_2x1​,x2​와 가중치 w=[5,−7,−11]w = [5, -7, -11]w=[5,−7,−11]일 경우 출력 [y1,y2]=[1,0,0][y_1, y_2] = [1,0,0][y1​,y2​]=[1,0,0]을 얻을 수 있으며, 각 가중치에 대한 기울기를 계산해 오차를 감소시키는 방향으로 업데이트한다. 4. 의미와 의의 역전파 알고리즘은 신경망 학습의 근간이 되었으며, 다층 퍼셉트론 구조는 XOR와 같은 비선형 문제 해결 가능 현재의 딥러닝 모델(Convolutional Neural Network, Transformer 등)도 이 원리를 확장한 것 즉, 단층 퍼셉트론에서 시작한 연구가 다층 구조와 역전파를 통해 현대 신경망의 기초로 발전하게 된 역사적 과정이다.</p>
<p>①②③④⑤⑥⑦⑧⑨ ⋅ ⌎</p>
<p>₀ ₁ ₂ ₃ ₄ ₅ ₆ ₇ ₈ ₉ ⁱ ⁿ / ¹ ² ³ ⁴ ⁵ ⁶ ⁷ ⁸ ⁹ ₋ / α β δ θ ε π μ σ Ω φ ω</p>
<p>− ± × ∑ ∴ ≥ ≤ ≒ ≓ ⋯ ⋮ / ⇨ ←→↑↓↔︎↕ / ℉ ℃</p>
<p>[출처]</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_11.html</guid>
  <pubDate>Tue, 21 Oct 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>현대 AI 연구</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_12.html</link>
  <description><![CDATA[ 




<p>인공지능 발전과 대규모 언어 모델의 CoT 통합 구조에 대해 다루고자 한다.</p>
<p>01 AI의 학문적 발전 인공지능(AI)의 발전은 소프트웨어적 진화와 하드웨어적 진화라는 두 축을 중심으로 병행되어 왔다.</p>
<p>이 두 축은 독립적으로 발전한 것이 아니라, 서로 상호 보완적 관계 속에서 영향을 주고받으며 오늘날의 AI 연구 쳬계를 형성하였다.</p>
<p>1 . 소프트웨어적 발전 ① 인과관계 중심 접근</p>
<p>심볼릭 어프로치, Symbolic AI</p>
<p>AI 연구의 초창기에는 인간의 사고 과정을 모사하기 위해 명시적 인과관계(explicit causality)를 기반으로 한 접근이 시도되었다.</p>
<p>이 시기의 대표적 연구 흐름은 Symbolic AI로, 지식공학(knowledge engineering)을 중심으로 발전하였다.</p>
<p>대표적 사례로는 전문가 시스템(expert system)이 있으며, MYCIN과 DENDRAL이 대표적 예이다.</p>
<p>이러한 시스템은 인간 전문가의 지식을 ’규칙(rule)’과 ’추론(inference)’의 형태로 체계화하여, 명시적으로 저장하고, 이를 이용해 논리적 결론을 도출하는 구조를 가진다.</p>
<p>장점 원인과 결과의 관계가 명확하므로, 시스템의 판단 근거를 추적할 수 있어 설명 가능성(explainability)이 높다.</p>
<p>한계 모든 지식을 사람이 사전에 정의해야 하므로, 현실 세계의 복잡성과 불확실성을 충분히 반영하지 못한다.</p>
<p>② 상관관계 중심 접근</p>
<p>애니매틱 어프로치, Connectionist / Statistical AI</p>
<p>이후 연구자들은 인과관계를 직접 모델링하기 보다는, 데이터로부터 패턴을 학습하는 방향으로 나아갔다.</p>
<p>이것이 바로 연결주의적 또는 통계적 접근으로, 오늘날의 머신러닝 및 딥러닝의 기반이 된다.</p>
<p>이 접근법에서는 대량의 데이터를 수집·정제한 뒤, 심층신경망(deep neural networks) 등의 모델을 학습시켜 결과를 도출한다.</p>
<p>장점 명시적 인과모형 없이도 높은 예측 정확도를 달성하며, 이미지 인식·자연어 처리·음성 인식 등 다양한 분야에서 혁신적 성과를 보였다.</p>
<p>한계 모델 내부 구조가 복잡하고 가중치에 의존하므로, 판단 과정이 불투명한 블랙박스(black box) 문제가 발생한다.</p>
<p>즉, 상관관계를 통해 결과를 도출할 수는 있지만, 그 관계가 ‘왜’ 성립하는가에 대한 설명이 어렵다. 이로 인해 실세계 응용에서 신뢰성과 윤리성의 한계가 제기되었다.</p>
<p>③ 하이브리드 접근 및 설명 가능한 AI</p>
<p>Explainable AI, XAI OR Neuro-Symbolic AI</p>
<p>이러한 한계를 극복하기 위한 새로운 방향으로 설명 가능한 인공지능 연구가 등장하였다.</p>
<p>이는 심볼릭 AI의 논리적 해석력과 연결주의 AI의 학습 능력을 통합하는 하이브리드 AI, 혹은 뉴로-심볼릭 AI의 형태로 발전하고 있다.</p>
<p>이 접근의 핵심은 예측성과 해석성의 통합에 있다.</p>
<p>하이브리드 AI의 운영 구조는 다음과 같다.</p>
<p>예측 단계: 대규모 데이터를 활용하여 통계적 분석과 패턴 인식을 수행함으로써 예측 결과를 생성한다.</p>
<p>설명 단계: 규칙 및 온톨로지 기반의 인과 추론 체계를 활용하여, 예측의 근거를 논리적으로 해석하고 검증한다. 적용 분야: 의료, 금융, 법률 등 설명 가능성이 필수적인 영역. 현재 한계: 완전한 인과적 추론 수준에는 아직 도달하지 못하였으며, 인과적 설명의 내재화(causal reasoning integration)는 여전히 AI 연구의 핵심 과제로 남아 있다.</p>
<p>2 . 하드웨어적 발전 Physical AI</p>
<p>AI의 발전은 알고리즘적 진보를 넘어, 물리적 지능(physical intelligence)의 단계로 확장되었다.</p>
<p>이를 피지컬 AI(Physical AI)라고 불리며, 단순한 연산 능력 향상이 아니라 실제 환경과의 실시간 상호작용을 가능하게 하는 새로운 패러다임을 의미한다.</p>
<p>① 철학적 배경</p>
<p>피지컬 AI의 이론적 기반은 ” 지능은 환경과의 상호작용을 통해 완성된다 ” 는 체화된 인지(embodied cognition) 개념에 있다.</p>
<p>이는 지능을 단순한 계산 능력이 아니라, 신체적 경험과 감각적 피드백을 포함한 총체적 능력으로 본다.</p>
<p>② 실제 구현</p>
<p>이 개념은 자율주행차, 로봇 조작, 드론 제어, 스마트 IoT 기기 등에서 실현되고 있다.</p>
<p>AI 알고리즘이 센서 및 엑추에이터와 결합함으로써, 기계는 외부 자극을 인식하고 판단하며 행동하는 실시간 자율 시스템으로 발전한다.</p>
<p>③ 학문적 의미</p>
<p>단순 기술 확장이 아니라, AI가 스스로 감지, 학습, 행동하는 실체적 지능을 실현하려는 연구 축으로 이해할 수 있다.</p>
<p>하드웨어적 발전은 단순한 기술적 진보가 아닌, AI의 실체적 존재화(realization)로 이해된다.</p>
<p>즉, AI가 데이터로만 존재하던 비물질적 지능에서 벗어나, 감지(sensing)–학습(learning)–행동(acting)의 순환 구조를 스스로 수행하는 단계로 진입한 것이다.</p>
<p>따라서 하드웨어적 진화는 소프트웨어 중심 AI의 한계를 보완하며, 현실 세계 속에서 자율적 판단과 행동 능력을 구현하는 핵심 축으로 평가된다. 이는 향후 지능의 통합적 구현(integrated intelligence)을 실현하기 위한 필수적 토대로 자리 잡고 있다.</p>
<p>02 CoT 통합 구조 Chain-of-Thought Integrated Architecture</p>
<p>대규모 언어 모델(LLM, Large Language Model)은 최근 몇 년간 두 가지 방향으로 발전해왔다.</p>
<p>① 하나는 언어 생성 능력(Language Generation)에 초점을 둔 학습 중심형 모델(Learning-Oriented Model)</p>
<p>② 다른 하나는 논리적 사고(Logical Reasoning)를 내재화한 추론 중심형 모델(Reasoning-Oriented Model)이다.</p>
<p>이 구분은 모델의 구조적 형태보다는, 모델이 최적화하는 목적 함수(Objective Function)와 훈련 패러다임(Training Paradigm)의 차이에 의해 정의된다.</p>
<p>1 . 학습 중심형 모델 Learning-Oriented Model</p>
<p>GPT-3에서 GPT-4.5로 이어지는 계열은 지도 학습(SL)과 자기회귀 언어 모델링(Autoregressive Language Modeling)을 기반으로 한 대표적 학습형 구조이다.</p>
<p>이 모델들은 입력된 문맥(Context)에 대해 다음 단어의 조건부 확률을 최대화하도록 학습된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P(w_t%20%7C%20w_1,%20w_2,%20%5Cldots,%20w_%7Bt-1%7D;%20%5Ctheta)"></p>
<p>(:) 모델의 파라미터 손실 함수: 일반적으로 음의 로그 가능도(Negative Log-Likelihood)로 정의된다. <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D(%5Ctheta)%20=%20-%5Csum_%7Bt=1%7D%5E%7BT%7D%20%5Clog%20P(w_t%20%7C%20w_%7B%3Ct%7D;%20%5Ctheta)"></p>
<p>이 접근은 모델이 방대한 언어 데이터를 통계적으로 모사하며, 언어의 문맥적 패턴을 효율적으로 학습하게 만든다.</p>
<p>GPT-4.5 이하의 모델들은 주로 텍스트 생성(Text Completion), 요약(Summarization), 번역(Translation) 등 언어적 유창성이 필요한 과제에 최적화되어 있다.</p>
<p>그러나 이러한 모델들은 논리적 추론(logical reasoning)과 같은 고차적 사고를 명시적으로 수행하지 못한다는 한계를 지닌다.</p>
<p>2 . 추론 중심형 모델 Reasoning-Oriented Model</p>
<p>이 한계를 보완하기 위해 OpenAI는 2024년 이후 O 시리즈(O1, O1-mini, O3 등)를 개발하였다.</p>
<p>이들 모델은 단순한 언어 예측이 아닌, 사고 과정(CoT)을 내재화하여 논리적·수학적 추론을 수행하도록 설계된 구조이다.</p>
<p>즉, 결과를 곧바로 산출하는 대신, 모델 내부에서 일련의 사고 단계를 거쳐 중간 논리 과정(intermediate reasoning steps)을 생성한 후 최종 응답을 도출한다.</p>
<p>이를 수식적으로 표현하면 다음과 같다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BAnswer%7D%20=%20f_%5Ctheta(%5Ctext%7BPrompt%7D)%20=%20g_%5Ctheta(%5Ctext%7BChain%20of%20Thought%20Steps%7D)"></p>
<p>(g_:)​ 모델 내부의 사고 전개 과정.</p>
<p>즉, 모델은 단순히 단어를 예측하는 확률기계가 아니라, 내재적 추론 구조를 가진 사고 시스템으로 진화한 것이다.</p>
<p>이러한 추론 능력은 별도의 규칙 기반이 아닌, 사전학습(Pretraining)과 인간 피드백 강화학습(RLHF)을 통해 점진적으로 강화된다.</p>
<p>결과적으로 O 시리즈는 언어의 표현 능력보다 사고의 정확성과 합리성을 우선시하는 추론 중심형(reasoning-oriented) 모델로 분류된다.</p>
<p>3 . GPT-5: CoT 기반 통합형 모델 Integrative Model</p>
<p>2025년 발표된 GPT-5는 기존 GPT 계열의 학습 중심형 구조와 O 시리즈의 추론 중심형 구조를 통합한 CoT 기반 하이브리드 LLM 아키텍처로 정의된다.</p>
<p>GPT-5는 입력의 복잡도에 따라 자동으로 두 가지 처리 모드 중 하나를 선택한다.</p>
<p>Fast Mode: 단순 질의에 대한 신속 응답 Deliberative Mode: 복합 문제에 대한 단계적 사고(CoT 기반)로 자동 전환하는 이중 처리 구조를 갖는다. 이 과정을 수식으로 나타내면 다음과 같다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BOutput%7D%20=%20%5Cbegin%7Bcases%7D%20f_%5Ctheta(x)%20&amp;%20%5Ctext%7Bif%20%7D%20x%20%5Cin%20%5Ctext%7Bsimple%20query%7D%20%5C%5C%20f_%5Ctheta(g_%5Ctheta(x))%20&amp;%20%5Ctext%7Bif%20%7D%20x%20%5Cin%20%5Ctext%7Bcomplex%20reasoning%20task%7D%20%5Cend%7Bcases%7D"></p>
<p>(g_(x):) CoT 기반 내부 사고 전개 과정. 이를 통해 GPT-5는 단순 질의응답(Q&amp;A)에서는 빠른 응답을 제공하고, 복합적인 문제(계획 수립, 코드 분석, 수학적 추론 등)에서는 단계적 사고 절차를 자동으로 활성화한다.</p>
<p>4 . 이론적 통합 관점 학술적 관점에서 보면 GPT-5의 구조적 진화를 요약하면 다음과 같다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BL-O%20GPT%20(%E2%89%A44.5)%7D%20+%20%5Ctext%7BR-O%20O-Series%7D%20%5CRightarrow%20%5Ctext%7BGPT-5%20(Integrated%20CoT%20Model)%7D"></p>
<p>즉, GPT-5는 단순히 매개변수 규모가 확장된 모델이 아니라, 학습 중심적 언어 처리와 추론 중심적 사고 구조를 결합하여 인공지능의 인식 능력(perception)과 사고 능력(reasoning)을 동시에 고도화한 모델로 정의된다.</p>
<p>LLM 발전 모델 비교 구분 모델 계열 중심 개념 주요 기능 학습 중심형 GPT-3 ~ GPT-4.5 언어 패턴 학습 및 문맥 예측 언어 생성, 번역, 요약 등 추론 중심형 O1 ~ O3 논리적 사고 및 CoT 전개 논리·수학적 문제 해결 통합형 GPT-5 언어 생성 + 사고 통합 자동 모드 전환, 고차원 추론 수행</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_12.html</guid>
  <pubDate>Tue, 21 Oct 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>현대 AI 연구</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_13.html</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p>Reporting Date: November. 5, 2025</p>
</blockquote>
<p>엔비디아(NVIDIA)는 인공지능 연산을 위한 GPU 시장의 절대적 선도 기업으로, 최근에는 하드웨어 중심의 성능 향상을 넘어 AI 생태계 전체를 아우르는 플랫폼 전략으로 진화하고 있다. 대표적으로 ‘코스모스(Cosmos) Simulation Model’과 ‘옴니버스(Omniverse)’ 플랫폼은 3D 모델링, 물리 기반 시뮬레이션, 렌더링을 통합하여 현실과 유사한 디지털 트윈(Digital Twin) 환경을 구현하는 기술적 기반을 제공한다. 이러한 시뮬레이션 시스템은 실제 물리 세계의 상호작용을 정밀하게 재현함으로써, AI 에이전트(agent)의 학습, 검증, 최적화 실험을 위한 실증적 환경을 제공한다.</p>
<p>2025년 기준으로 인공지능 연구의 핵심 개념은 에이전트(Agent)이다. 이는 인간의 인지적 판단과 행동을 모사하거나 대리 수행할 수 있는 자율적 지능 시스템을 의미한다.</p>
<p>과거의 대화형 AI는 명시적으로 프로그래밍된 규칙에 의존했으나, 현재는 자연어 프롬프트(prompt)를 통해 고차원적 명령을 직접 해석하고 실행할 수 있다. 이러한 고도화된 시스템의 중심에는 대규모 언어모델(LLM, Large Language Model)이 있으며, 이는 언어적 지식뿐 아니라 시각·음성·문서 등 다양한 데이터 모달리티(modality)를 통합한 멀티모달 구조로 발전하고 있다.</p>
<p>LLM의 기술적 진화는 ‘멀티모달 학습(Multimodal Learning)’ 역량을 중심으로 전개된다. 텍스트, 이미지, 오디오, 비디오 등의 이질적 데이터를 통합적으로 해석하고 상호 연관성을 학습하는 것이 핵심이며, 이는 각 데이터 형식별로 고유한 입출력 구조와 통신 프로토콜을 요구한다.</p>
<p>현재의 LLM은 외부 데이터를 분석하고 가공할 수 있으나, 인간 수준의 자율적 시각 생성 능력에는 아직 도달하지 못한 상태다.</p>
<p>AI의 실질적 응용의 종착점은 ’피지컬 AI(Physical AI)’이다. 이는 로봇, 제조, 물류, 스마트 팩토리 등 물리적 환경에서 실시간으로 인지·판단·행동을 수행할 수 있는 지능형 시스템을 의미한다. 미국은 첨단 반도체 설계 능력을 보유하고 있으나, 제조 기반의 약화로 인해 피지컬 AI의 산업적 적용에는 한계가 존재한다. 반면, 중국은 제조 기술과 산업 자동화 인프라 측면에서 강점을 보유하고 있으나, 미·중 기술 패권 경쟁이 양국 간 협력의 제약 요인으로 작용한다.</p>
<p>이러한 상황 속에서 블랙록(BlackRock), 오픈AI(OpenAI)의 샘 알트먼(Sam Altman), 앤스로픽(Anthropic)의 다리오 아모데이(Dario Amodei), 엔비디아의 젠슨 황(Jensen Huang) 등 AI 생태계를 주도하는 주요 인물들은 한국을 차세대 전략적 거점으로 평가하고 있다. 이는 반도체 제조 분야에서 삼성전자와 SK하이닉스가 가진 기술적 우위와 글로벌 공급망 내 핵심적 위치 때문이다.</p>
<p>한국의 반도체 산업은 엔비디아와 같은 AI 중심 기업의 연산 가속화를 위한 필수적 기반으로 작용하며, 양측의 기술적 상호의존 관계는 AI 반도체 생산 효율을 높이고, 피지컬 AI 산업화의 촉진을 가능하게 하는 협력 생태계를 형성하고 있다.</p>
<hr>
<p>인공지능의 이론적 기반은 크게 두 가지로 구분된다.</p>
<p>첫째, 인과관계 기반의 <strong>지식 모델</strong>은 인간의 논리적 추론과 유사한 방식으로 동작하며, 둘째, 상관관계 기반의 <strong>데이터 모델</strong>은 통계적 학습을 통해 패턴을 식별한다.</p>
<p>즉, 학습 기반 AI의 이해 연결주의(Connectionism) – 데이터에 대한 학습 능력을 이용하여 지능 구현</p>
<p>후자의 대표적 구현이 머신러닝(ML)과 딥러닝(DL)이며, 인공신경망(ANN) 및 생성형 AI 모델이 이에 포함된다.</p>
<hr>
<p>ANN <code>Artificial Neural Network</code> 인간의 신경세포(뉴런) 구조를 모사한 계산 모델이다.</p>
<p>뉴런은 수상돌기(다중 입력), 세포핵(통합 중심), 축삭돌기(단일 출력)로 구성되며, 시냅스(synapse)를 통해 연결된다. 인간의 뇌는 약 1000억 개의 뉴런과 100조 개 이상의 시냅스로 이루어져 있으며, 각 뉴런은 평균 1000개 이상의 시냅스를 형성한다.</p>
<p>입력 신호는 수상돌기를 통해 수집되어 세포핵에서 통합·처리되며, 각 입력의 영향력은 가중치(weight)로 조정된다.</p>
<p>신호가 일정 임계치를 초과하면 <strong>활성화 함수(activation function)</strong>에 의해 출력으로 변환된다.</p>
<p>이때 주로 사용되는 함수는 <strong>역치 함수(threshold function)</strong>와 <strong>시그모이드(sigmoid) 함수</strong>이며, 이는 입력 자극의 강도와 출력 반응의 비선형 관계를 수학적으로 모델링한다.</p>
<p>출력 신호는 축삭돌기를 따라 전도되며, 말단부에서는 아세틸콜린 등의 <strong>신경전달물질</strong>을 통해 다른 뉴런으로 전파된다. 학습 과정에서 형성되는 시냅스의 가중치 변화가 곧 <strong>기억과 학습의 수학적 표현</strong>이다.</p>
<p>시각 정보를 예로 들면, 인간의 눈은 약 700만 개의 원추세포와 1억 2000만 개의 막대세포로 구성되어 색상과 명암을 인식한다. 인공신경망에서는 이러한 시각 입력을 디지털 이미지의 픽셀로 표현하며, 예를 들어 28×28 흑백 필기체 데이터는 784차원 벡터로 변환되어 입력층에 주어진다.</p>
<p>다층 퍼셉트론(MLP, Multi-Layer Perceptron)은 이 벡터 데이터를 여러 은닉층(hidden layer)을 통해 비선형적으로 변환하며, 각 층의 노드 수와 활성화 방식에 따라 인식 정확도가 달라진다.</p>
<p>출력층(output layer)에는 가중치 대신 확률 분포를 계산하는 소프트맥스(Softmax) 함수가 사용된다. 이를 통해 예측 결과를 확률적으로 해석할 수 있으며, TOP-1 또는 TOP-3 정확도를 기준으로 분류 성능을 평가한다.</p>
<p>하지만 모델의 복잡도가 과도하면 과적합(overfitting)이 발생할 수 있으며, 이는 학습 데이터의 특성에 과도하게 종속된 결과를 초래한다. 따라서 모델 구조의 단순화나 규제화(regularization) 기법을 통해 이를 완화한다.</p>
<p>음성 데이터는 또 다른 모달리티를 구성한다. 파형, 주파수, 진동의 패턴을 학습하여 화자 인식, 음성 인식, 다자 음성 분리 등으로 응용된다. 철도나 엘리베이터의 작동음 분석을 통해 고장 여부를 조기 진단하는 산업적 활용도 이에 해당한다.</p>
<p><strong>결국 인식(recognition)은 곧 분류(classification)이다.</strong></p>
<p>신경망이 입력을 해석하고, 그 결과를 특정 클래스에 매핑하는 과정은 본질적으로 확률적 분류 문제이다. 이러한 학습의 핵심은 오차(error)를 줄이는 것이며, 과거에는 복잡한 가중치 구조로 인해 학습이 어려웠으나, 역전파(backpropagation) 알고리즘의 도입으로 이를 해결하였다.</p>
<p>이 혁신으로 인해 인공신경망은 1980년대 후반의 혹한기를 극복하고, 현대 딥러닝의 토대를 구축하게 되었다.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_13.html</guid>
  <pubDate>Tue, 21 Oct 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>인공신경망</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_14.html</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p>Reporting Date: November. 12, 2025</p>
</blockquote>
<section id="인공신경망" class="level1">
<h1>01 인공신경망</h1>
<p><code>Artificial Neural Network, ANN</code><br></p>
<p>인간 두뇌의 신경 연결 구조를 수학적으로 모델링한 계산 체계로서, 입력층(Input Layer), 은닉층(Hidden Layer), 출력층(Output Layer)으로 구성된 계층적 구조를 가진다.</p>
<p>각 층의 뉴런(neuron)은 <strong>비선형 활성화 함수(activation function)</strong>를 통해 입력 신호를 고차원 표현으로 변환하며, 이를 기반으로 단순한 패턴 인식부터 복잡한 비선형 함수의 근사까지 수행할 수 있다.</p>
<p><strong>딥 뉴럴 네트워크</strong> <code>Deep Neural Network, DNN</code> 층의 깊이가 증가함에 따라 다단계 표현 학습이 가능해진 구조.</p>
<p>이는 단순한 비선형 변환의 누적이 아니라, 계층적으로 추상화된 특징(hierarchical features)을 점진적으로 학습하는 체계로서, 데이터의 복잡한 구조를 단계적으로 표현하는 고차원적 학습 모델이다.</p>
<p>DNN의 학습은 손실 함수(loss function)를 최소화하기 위해 가중치(weight)와 편향(bias)을 반복적으로 조정하는 최적화 과정이다. 이 과정은 오차 역전파 알고리즘(backpropagation)과 경사하강법(gradient descent)을 기반으로 하며, 네트워크 출력과 실제값의 차이를 계산하여 각 가중치가 오차에 기여한 정도를 추정하고, 이를 반영해 파라미터를 갱신한다.</p>
<p>층이 깊어질수록 모델의 표현력(expressive power)은 급격히 향상되지만, 동시에 <strong>기울기 소실(vanishing gradient)</strong>, <strong>과적합(overfitting)</strong>, <strong>연산 복잡도(computational complexity)</strong> 등의 문제가 발생한다. 반면, 네트워크의 폭(wide direction)을 확장하면 각 층의 뉴런 수가 증가하여 더 많은 특징(feature) 차원을 학습할 수 있고, 이는 입력 데이터의 다양성과 분류 대상의 복잡성을 반영한다.</p>
<p>따라서 최적의 네트워크 구조 설계는 단순한 경험적 조정(heuristic tuning)을 넘어, 구조적 효율성과 일반화 성능을 동시에 확보하기 위한 <strong>Neural Architecture Search (NAS)</strong>와 같은 자동화된 탐색 기법의 활용으로 발전하고 있다. 이러한 접근은 모델의 성능 향상뿐 아니라, 연산 효율성 및 학습 안정성까지 고려한 체계적 설계를 가능하게 한다.</p>
<p>그러나 이러한 이론적 토대가 확립되기 이전의 초기 신경망은 XOR 문제조차 해결하지 못했다.</p>
<p>이는 당시의 네트워크가 단일 계층 구조로서, AND, OR와 같은 <strong>선형 분리(linearly separable)</strong> 문제만을 처리할 수 있었기 때문이다. 당시에는 순전파(forward propagation)만 존재하였으며, 역방향으로 오차를 전달해 가중치를 수정하는 역전파(backpropagation) 개념이 없었다.</p>
<p>이를 수작업으로 확인하면 다음과 같다. 입력 ( x_1, x_2 )에 대해 AND 연산의 경우 입력 조합 (0,0), (0,1), (1,0), (1,1)에 대해 출력은 각각 0, 0, 0, 1이 되어야 한다. 이를 ( y = f(w_i x_i) )로 표현할 때, 적절한 가중치 ( w_i ) 설정을 통해 0 또는 1로 분리 가능한 선형 결정 경계를 형성할 수 있다. 그러나 XOR 문제는 이러한 단일 선형 경계로는 분리할 수 없으며, 다층 구조와 비선형 활성화 함수의 결합이 필요하다. 다시 말해, XOR 문제는 비선형적 패턴을 학습하기 위한 <strong>은닉층(hidden layer)</strong>의 필요성을 입증한 대표적 사례이다.</p>
<p>이후 다층 퍼셉트론(Multi-Layer Perceptron, MLP)과 역전파 알고리즘이 도입되면서 신경망은 비선형 함수 근사 능력을 획득하였고, 이는 딥러닝의 초석이 되었다.</p>
<p><strong>딥러닝(Deep Learning)</strong>은 단순히 층의 수가 많은 신경망을 의미하지 않는다. 이는 데이터의 구조적 특성과 과업 유형(task type)에 따라 네트워크를 설계하고, 학습의 안정성과 효율성을 확보하기 위한 다양한 최적화 기법을 포함하는 고도화된 신경망 패러다임이다. 예를 들어, <strong>합성곱 신경망(Convolutional Neural Network, CNN)</strong>은 지역적 수용 영역(local receptive field)과 가중치 공유(weight sharing) 구조를 통해 이미지 및 시각적 정보의 공간적 특성을 효율적으로 학습하며, <strong>순환 신경망(Recurrent Neural Network, RNN)</strong>은 시계열 데이터의 시간적 종속성(temporal dependency)을 처리하기 위해 내부 상태(hidden state)를 순환적으로 유지하는 구조를 채택한다.</p>
<p>이처럼 딥러닝은 단순히 전통적 ANN의 확장판이 아니라, 데이터의 형태와 과업의 특성에 맞춰 설계된 다양한 아키텍처와 최적화 전략을 결합한 <strong>고차원 지능 시스템(High-Dimensional Intelligent System)</strong>으로 정의된다. 이는 단순한 계산 모델을 넘어, 인간 지각과 사고의 일부 과정을 수학적으로 구현하려는 인공지능의 핵심 접근 방식이라 할 수 있다.</p>
<hr>
</section>
<section id="역전파-알고리즘" class="level1">
<h1>02 역전파 알고리즘</h1>
<p><code>Backpropagation</code><br> 인공신경망의 학습 과정에서 손실 함수의 기울기를 각 가중치에 대해 효율적으로 계산하기 위해 체인룰(chain rule)을 적용한 미분 기법이다. 이는 네트워크의 출력층에서 계산된 오차를 입력층 방향으로 역전파하여, 각 파라미터가 오차에 미치는 기여도를 정량적으로 평가하고 이를 바탕으로 가중치를 갱신하는 절차로 구성된다.</p>
<p>기본적으로 신경망의 한 층에서 출력 (f)는 다음과 같이 정의된다: (f = w x + b) 여기서 (w)는 가중치(weight), (x)는 입력(input), (b)는 편향(bias)이다. 이 식을 여러 층으로 확장하면, 각 층의 출력은 이전 층의 출력을 입력으로 받아 순차적으로 변환된다. 즉, (a^{(l)} = f<sup>{(l)}(w</sup>{(l)} a^{(l-1)} + b^{(l)})) 로 표현되며, 최종 출력층까지의 연속적 변환은 합성 함수의 형태를 가진다.</p>
<p>이때, 손실 함수 (L)에 대해 각 파라미터의 기울기를 구하려면 체인룰을 사용한다. 예를 들어, ( = ) 와 같이 전개할 수 있다. 이 과정은 네트워크의 각 노드(node)를 연산 단위로, 각 변수(variable)를 데이터 흐름 단위로 해석하여 계산 그래프(computational graph)를 통해 효율적으로 수행된다.</p>
<p>결과적으로, 역전파는 출력층에서 발생한 오차를 기반으로 각 층의 가중치가 손실에 미치는 영향을 편미분으로 추적하고, 이를 반대로 전파하여 파라미터를 갱신한다.</p>
<p>이렇게 얻어진 기울기는 경사하강법(Gradient Descent) 또는 그 변형 알고리즘(Adam, RMSProp 등)에 의해 사용되며, 모델이 손실 함수를 최소화하는 방향으로 학습되도록 한다.</p>
<p>요약하면, 역전파 알고리즘은 다음의 핵심 절차를 따른다:</p>
<ol type="1">
<li><strong>순전파(Forward Propagation)</strong>: 입력 데이터를 네트워크를 통해 전달하여 출력과 손실을 계산한다.</li>
<li><strong>오차 계산(Error Computation)</strong>: 출력층에서 실제값과 예측값의 차이를 기반으로 손실 함수를 계산한다.</li>
<li><strong>역전파(Backpropagation)</strong>: 체인룰을 적용하여 각 파라미터의 기울기를 계산한다.</li>
<li><strong>파라미터 갱신(Parameter Update)</strong>: 계산된 기울기를 바탕으로 경사하강법을 사용해 가중치와 편향을 갱신한다.</li>
</ol>
<hr>
<section id="문제점" class="level2">
<h2 class="anchored" data-anchor-id="문제점">2.1 문제점</h2>
<p><strong>하나의 가중치만을 따로 떼어 분석하면</strong><br> <strong>전체 네트워크의 상호의존적 구조를 반영하지 못한다</strong>는 점이 역전파의 핵심적 난점 중 하나이다.</p>
<ol type="1">
<li><strong>신경망은 공동 기여 시스템이다</strong></li>
</ol>
<p>신경망의 출력은 단일 가중치의 효과가 아니라,<br> 모든 입력 ( x_i )와 가중치 ( w_i ), 그리고 여러 층을 거친 <strong>비선형 합성 함수</strong>의 결과이다.<br> 즉, 각 가중치는 다른 가중치들과의 조합을 통해서만 의미 있는 출력을 만들어낸다.<br></p>
<p>이 때문에 하나의 가중치만 고립적으로 평가하면,<br> <strong>다른 가중치들과의 상호작용(interaction)</strong>을 무시하게 되어 실제 영향도를 정확히 알 수 없다.</p>
<ol start="2" type="1">
<li><strong>역전파는 ’부분 기여’를 계산하는 과정이다</strong></li>
</ol>
<p>역전파 알고리즘의 목적은 각 가중치가 <strong>전체 손실(Loss)에 얼마나 기여했는가</strong>를 계산하는 것이다. 이때 체인룰을 이용해, 출력층에서 발생한 오차가 어떻게 각 가중치 방향으로 퍼져나가는지를 추적한다.</p>
<p>즉, <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20w_i%7D"> 는<br> “모든 다른 파라미터들이 고정되어 있을 때, ( w_i )를 미세하게 변화시켰을 때 손실이 얼마나 변하는가”를 의미한다.<br></p>
<p>다시 말해, <strong>하나의 가중치 변화가 전체 결과에 미치는 ‘국소적 기여도(local contribution)’</strong>를 구하는 것이며, 이는 전체 맥락에서의 상호작용을 미분의 형태로 부분적으로 포착한 것입니다.</p>
<ol start="3" type="1">
<li><strong>그러나 ’전체적 상호작용’은 여전히 남는다</strong></li>
</ol>
<p>역전파는 개별 가중치의 기울기를 구하되, <strong>그 계산 과정에 이미 모든 다른 가중치와 뉴런의 값이 포함</strong>됩니다.<br> 즉, 수학적으로는 고립된 것이 아니라, 계산 그래프(computational graph) 전체를 거쳐 영향을 받아 나온 결과입니다.<br> 그럼에도 불구하고 다음과 같은 한계가 존재합니다.</p>
<ul>
<li><strong>비선형성(Nonlinearity)</strong> 때문에, 다른 가중치가 조금만 달라져도 각 기울기의 상대적 영향이 크게 바뀐다.</li>
<li>따라서 한 시점의 기울기만으로는 “전체 네트워크에서의 근본적 관계”를 완전히 파악할 수 없다.</li>
<li>이로 인해 실제 학습에서는 “한 번의 역전파 결과”보다 “다수의 반복(iteration)을 통한 평균적 수렴”이 중요하다. <br></li>
</ul>
<p>결론적으로 하나의 가중치를 따로 본다면 신경망의 다차원 상호작용을 제대로 볼 수 없다.<br> 그러나 역전파는 바로 그 문제를 <strong>부분 미분의 누적 형태로 해결</strong>합니다.<br></p>
<p>즉, 각 가중치의 기울기를 “다른 파라미터가 고정된 상태에서의 국소적 영향”으로 계산하고,<br> 이를 전체 그래프를 따라 합성함으로써, 전체 시스템이 함께 조정되도록 하는 것입니다.</p>
<p>결국, <strong>하나의 가중치는 단독으로는 의미가 없고</strong>,<br> 오직 “네트워크 전체에서의 미분적 상호작용” 속에서만 의미를 가집니다.</p>
<p>이 점이 신경망이 선형 모델과 본질적으로 다른 이유이며,<br> 딥러닝 학습이 단순한 회귀(regression)가 아닌 <strong>비선형적 협조 최적화(non-linear cooperative optimization)</strong>라는 점을 보여준다.</p>
<hr>
</section>
<section id="해결-방안" class="level2">
<h2 class="anchored" data-anchor-id="해결-방안">2.2 해결 방안</h2>
<p>역전파 + 경사하강법 작동원리<br></p>
<ol type="1">
<li><strong>역전파의 순서적 기울기 계산</strong></li>
</ol>
<p>출력층에서 손실이 계산된 후, 그 오차를 <strong>뒤로 거슬러 올라가며</strong>(backward)<br> 각 층의 가중치가 손실에 어떤 영향을 미치는지를 따져봅니다.<br></p>
<p>즉,</p>
<ul>
<li>마지막 층부터 오차의 영향을 계산하고,</li>
<li>그 결과를 이전 층의 가중치로 전달하며,</li>
<li>각 가중치의 변화 방향(∂L/∂w)을 구합니다.</li>
</ul>
<p>이게 바로 <strong>chain rule</strong>을 층별로 적용하는 과정입니다.</p>
<ol start="2" type="1">
<li><strong>경사하강법(Gradient Descent)</strong></li>
</ol>
<p>각 가중치의 기울기(∂L/∂w)는 “이 방향으로 가면 손실이 증가한다”를 의미합니다. 따라서 반대 방향(−∂L/∂w)으로 이동하면 손실이 감소합니다. 이를 수식으로 표현하면: [ w_{new} = w_{old} - ] 여기서 ()는 학습률(learning rate)로, 이동 속도를 조절합니다.</p>
<p>즉, 각 가중치는 “에러가 줄어드는 방향으로” 조금씩 움직이며, 이 과정이 전체 네트워크에서 동시에 일어납니다.</p>
<ol start="3" type="1">
<li><strong>순차적 파라미터 갱신</strong></li>
</ol>
<p>하나의 가중치 ( w_i )를 업데이트할 때는, 그 시점의 다른 파라미터를 <strong>임시로 고정한 상태</strong>로 취급합니다. 즉, 한 번의 역전파에서는 모든 가중치를 동시에 업데이트하되, 각각은 “현재 다른 값들이 고정되어 있다”는 전제 하에서 계산된 기울기에 따라 움직입니다.</p>
<p>이 점에서 <strong>동시적이면서도 독립적인 최적화 단위</strong>가 형성됩니다. 그 후, 전체 네트워크의 파라미터가 한 번에 갱신되며 다음 반복(iteration)으로 넘어갑니다.</p>
<hr>
</section>
<section id="예제-시그모이드의-연산-흐름-구조" class="level2">
<h2 class="anchored" data-anchor-id="예제-시그모이드의-연산-흐름-구조">2.3. 예제: 시그모이드의 연산 흐름 구조</h2>
<p>시그모이드 함수 <img src="https://latex.codecogs.com/png.latex?%0Ag(z)%20=%20%5Cfrac%7B1%7D%7B1%20+%20e%5E%7B-z%7D%7D%0A"></p>
<p>를 계산 그래프로 풀어쓰면, 다음과 같은 일련의 연산 노드로 표현됩니다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%20%E2%86%92%20(%20*%20-1%20)%20%E2%86%92%20exp%20%E2%86%92%20(%20+1%20)%20%E2%86%92%20(%201/x%20)%20%E2%86%92%20g%0A"></p>
<p>즉,</p>
<ol type="1">
<li>입력값 ( z )에</li>
<li>음수를 곱하고( * -1 ),</li>
<li>지수함수를 취하고( exp ),</li>
<li>1을 더하고( +1 ),</li>
<li>역수를 취하면( 1/x ) 결과적으로 시그모이드 출력 ( g )가 나옵니다.</li>
</ol>
<p>이처럼 단순한 하나의 수식도 <strong>여러 개의 연산 노드로 분해</strong>되어, 각 노드에서 미분(기울기)이 계산되고 역전파될 수 있도록 구성됩니다.</p>
<ol type="1">
<li>복잡한 신경망 = 수식의 확장적 노드화</li>
</ol>
<p>신경망이 복잡해진다는 것은<br> 결국 “이러한 단순한 연산 노드들이 수천, 수만 개로 연결되어 합성된 형태”를 의미합니다.</p>
<p>즉,</p>
<ul>
<li><strong>층이 깊을수록</strong> 합성 함수의 깊이가 늘어나고,</li>
<li><strong>뉴런 수가 많을수록</strong> 병렬적인 연산 노드가 많아지며,</li>
<li>전체 네트워크는 거대한 계산 그래프(computational graph)로 확장된다.</li>
</ul>
<p>이 그래프 상에서 역전파는 체인룰을 적용하여,<br> 출력 노드에서 입력 노드로 기울기를 <strong>노드 단위로 전파(backpropagate)</strong> 한다.<br></p>
<ol start="2" type="1">
<li>직관적으로 보면 신경망의 “복잡성”은 사실 <strong>수학적 표현의 압축 정도</strong>입니다.</li>
</ol>
<p>즉,</p>
<ul>
<li>수식으로는 간단히 적힌 ( g(f(h(x))) ) 같은 표현이,</li>
<li>실제 계산 단계에서는 수십 개의 노드로 세분화되어 구현됩니다.</li>
</ul>
<p>따라서, 복잡해 보이는 신경망도 결국 “단순한 기본 연산들의 반복적 조합”이며, 그 조합을 <strong>노드 그래프 형태로 펼쳐놓은 것</strong>이 바로 신경망 구조입니다.</p>
<hr>
<p>예 — hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2) 같은 표현을 TensorFlow 코드·계산 그래프·TensorBoard 이미지로 웹에서 쉽게 찾을 수 있습니다.</p>
<p>권장 이미지 유형 코드 스니펫과 간단 다이어그램(활성화 함수 흐름). TensorBoard로 그린 연산 그래프(MatMul → Add(b) → Sigmoid). 계산 그래프의 노드(곱셈·덧셈·비선형 연산) 시각화 예시.</p>
<hr>
</section>
<section id="해결-방법2" class="level2">
<h2 class="anchored" data-anchor-id="해결-방법2">2.4 해결 방법2</h2>
<ol type="1">
<li>순전파(Forward Propagation)</li>
</ol>
<p>먼저 신경망은 입력 데이터를 받아 <strong>층을 따라 순방향으로 연산</strong>을 수행합니다.</p>
<p>즉, <img src="https://latex.codecogs.com/png.latex?%0Ax%20%5Crightarrow%20(W_1,%20b_1)%20%5Crightarrow%20L_1%20%5Crightarrow%20(W_2,%20b_2)%20%5Crightarrow%20L_2%20%5Crightarrow%20%5Ccdots%20%5Crightarrow%20%5Chat%7By%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D">: 예측값(hypothesis)</li>
</ul>
<p>이 단계에서는 단지 “현재 가중치로 계산된 결과”를 내는 것뿐입니다.</p>
<ol start="2" type="1">
<li>역전파(Backpropagation)</li>
</ol>
<p>출력값이 실제 정답 (y)와 다르면 손실 함수 (L(y, ))가 커집니다.<br> 이때 <strong>오차를 역방향으로 전파</strong>하여 각 가중치 (w)가 오차에 미친 영향을 계산하고,<br> 그에 따라 가중치를 <strong>오차가 줄어드는 방향으로 미세하게 수정</strong>합니다.</p>
<p>즉, <img src="https://latex.codecogs.com/png.latex?%0Aw%20:=%20w%20-%20%5Ceta%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20w%7D%0A"></p>
<p>이 과정을 데이터셋의 각 샘플(혹은 배치)에 대해 반복하면서 학습이 진행됩니다.</p>
<ol start="3" type="1">
<li>대규모 데이터가 필요한 이유</li>
</ol>
<p>오류를 줄이기 위해서는 <strong>다양한 입력 상황</strong>을 학습해야 합니다.<br> 데이터가 많을수록 네트워크는</p>
<ul>
<li>특정 패턴에 과적합되지 않고,</li>
<li>전체 분포의 일반적 경향을 학습할 수 있습니다.</li>
</ul>
<p>즉, 대규모 데이터는 가중치가 <strong>균형 있게 조정되도록</strong> 도와주며,<br> 이는 결국 일반화 능력(generalization)을 향상시킵니다.</p>
<ol start="4" type="1">
<li>가중치 변화 폭의 수렴</li>
</ol>
<p>학습이 진행될수록</p>
<ul>
<li>손실이 줄어들고,</li>
<li>기울기(gradient)의 크기도 점점 작아집니다.</li>
</ul>
<p>이로 인해 가중치의 변동 폭은 점점 감소하며,<br> 결국 오차가 거의 변하지 않는 <strong>수렴 상태</strong>에 도달합니다.</p>
<p>이때 각 가중치의 분포는 무작위 초기화 상태에서 점차 안정된 정규분포 형태로 가까워집니다.<br> 이는 확률론적으로 “많은 데이터 샘플에 의해 평균적으로 조정된 결과”이기 때문입니다.<br></p>
<ol start="5" type="1">
<li>테스트 데이터로 검증</li>
</ol>
<p>훈련(Training) 과정에서 사용되지 않은 <strong>테스트 데이터(Test set)</strong>를 이용해<br> 학습된 모델이 새로운 데이터에서도 잘 작동하는지 검증합니다.<br></p>
<p>이 과정을 통해 <strong>정확도(accuracy), 손실(loss), 과적합 여부(overfitting)</strong> 등을 평가할 수 있습니다.</p>
<hr>
</section>
</section>
<section id="딥러닝-모델의-일반적인-학습활용-흐름" class="level1">
<h1>03 딥러닝 모델의 일반적인 학습·활용 흐름</h1>
<ol type="1">
<li><p><strong>데이터 준비</strong></p>
<ul>
<li>가능한 범용(대표성 있는) 데이터셋을 수집합니다.</li>
<li>노이즈 제거, 결측치 처리, 정규화 등 <strong>정제·전처리</strong> 과정을 거칩니다.</li>
</ul></li>
<li><p><strong>데이터 분할</strong></p>
<ul>
<li>데이터를 <strong>훈련(train)</strong>, <strong>검증(validation)</strong>, <strong>테스트(test)</strong> 용으로 분리합니다.</li>
<li>훈련용은 모델 학습에, 검증용은 하이퍼파라미터 조정에, 테스트용은 최종 평가에 사용됩니다.</li>
</ul></li>
<li><p><strong>모델 학습</strong></p>
<ul>
<li>훈련 데이터로 신경망을 학습시키고,</li>
<li>검증 데이터를 이용해 과적합을 방지하며 모델을 조정합니다.</li>
</ul></li>
<li><p><strong>사전학습(Pre-training)</strong></p>
<ul>
<li>최근에는 이 과정을 대규모 데이터와 연산 자원을 활용해<br> <strong>미리 학습된 모델(Pre-trained model)</strong> 로 구축합니다.</li>
<li>이렇게 만들어진 모델은 <strong>전이학습(Transfer Learning)</strong> 을 통해 다른 사용자가 자신의 데이터에 맞게 재학습(fine-tuning) 할 수 있다.</li>
</ul>
<p>일반적으로 <strong>범용적 특징을 학습하는 방향</strong>으로 진행됩니다.<br> 즉, 특정 과제 하나에 집중하지 않고, 가능한 한 <strong>많은 데이터와 다양한 패턴을 포괄</strong>하도록 설계됩니다.</p>
<p><strong>방향: 일반적 패턴 학습</strong></p>
<ul>
<li>모델은 “고양이 인식” 같은 구체적 과제가 아니라, <strong>시각·언어·음성 등에서 공통적으로 나타나는 일반 구조</strong>를 학습합니다.</li>
<li>예: 이미지 모델은 “모서리, 질감, 색 대비” 같은 기본 시각적 특징을, 언어 모델은 “문법, 어순, 의미 관계” 같은 일반 언어 규칙을 익힙니다.</li>
</ul>
<p><strong>이유: 효율성과 재사용성</strong></p>
<ul>
<li><strong>학습 효율</strong>: 모든 사용자가 처음부터 대규모 학습을 수행하는 것은 비효율적이므로, 공통 패턴을 미리 학습시켜 두면 이후엔 적은 데이터로도 빠르게 성능을 낼 수 있습니다.</li>
<li><strong>전이 가능성</strong>: 범용적 특징을 배우면, 이후 특정 과제(예: 감정 분석, 질병 분류)에 일부 가중치만 미세조정(fine-tuning)하여 쉽게 적응할 수 있습니다.</li>
</ul>
<p><strong>결과적으로</strong></p>
<ul>
<li>사전학습은 “넓게 → 얕게” 학습하는 과정이며,</li>
<li>전이학습은 “좁게 → 깊게” 구체화하는 과정입니다.</li>
</ul>
<p>즉, <strong>사전학습은 공통 기반을 다지는 단계</strong>, <strong>전이학습은 목적에 맞게 세부 조정을 하는 단계</strong>입니다.</p></li>
</ol>
<hr>
<ul>
<li><p><strong>뒤쪽(출력층 근처)부터 조정하는 이유</strong>: 뒤로 갈수록 네트워크가 <strong>더 구체적이고 과제 특화된 특징</strong>을 표현합니다. 따라서 전이학습 시에는 이 부분만 미세하게 조정해도 충분히 새로운 과제에 적응할 수 있습니다.</p></li>
<li><p><strong>앞쪽(입력층 근처)을 수정하지 않는 이유</strong>: 초기층은 대부분의 데이터(이미지, 텍스트 등)에서 <strong>공통적으로 나타나는 일반적 특징</strong>을 이미 잘 학습하고 있기 때문입니다. 이 부분을 건드리면 오히려 기존의 범용적 표현력이 손상될 수 있습니다.</p></li>
<li><p><strong>그러나</strong>, 충분한 데이터, 연산 자원(GPU 등), 시간, 그리고 안정적인 학습 설계가 가능하다면 <strong>앞단부터 전체 네트워크를 재학습(fine-tuning)</strong> 하는 것이 성능 면에서는 더 이상적입니다. 이는 기존 가중치를 초기값으로 삼아, 모델 전체가 새로운 도메인에 맞게 완전히 재적합되는 방향입니다.</p></li>
</ul>
<hr>
<section id="tensorflow" class="level3">
<h3 class="anchored" data-anchor-id="tensorflow"><strong>TensorFlow</strong></h3>
<ul>
<li><strong>Google이 개발한 딥러닝 프레임워크(저수준)</strong>.</li>
<li>수학 연산 그래프를 직접 구성하고, GPU/TPU에서 최적화된 학습을 수행.</li>
<li>내부적으로 매우 강력하지만 코드가 복잡하고 구현 난이도가 높음.</li>
</ul>
</section>
<section id="keras" class="level3">
<h3 class="anchored" data-anchor-id="keras"><strong>Keras</strong></h3>
<ul>
<li><strong>TensorFlow 위에서 동작하는 고수준 API</strong>.</li>
<li>직관적인 코드로 모델 설계·학습·평가를 쉽게 수행할 수 있게 함.</li>
<li>초기에는 독립 프레임워크였으나, 현재는 <strong>TensorFlow에 통합(<code>tf.keras</code>)</strong> 되어 표준 인터페이스로 사용됨.</li>
<li>즉, <strong>TensorFlow의 고급 래퍼(wrapper)</strong> 역할.</li>
</ul>
</section>
<section id="pytorch" class="level3">
<h3 class="anchored" data-anchor-id="pytorch"><strong>PyTorch</strong></h3>
<ul>
<li><strong>Facebook(현재 Meta)</strong> 가 개발한 프레임워크로, TensorFlow보다 <strong>동적 계산 그래프</strong>(Dynamic Graph)를 지원.</li>
<li>직관적이며 Python 코드와 유사하게 동작하므로 <strong>연구·프로토타입 개발에 적합</strong>.</li>
<li>최근에는 TensorFlow보다 산업·연구 양쪽에서 더 많이 쓰이는 추세.</li>
</ul>
</section>
<section id="정리-비교" class="level3">
<h3 class="anchored" data-anchor-id="정리-비교">정리 비교</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 10%">
<col style="width: 38%">
<col style="width: 10%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th>구분</th>
<th>주요 개발사</th>
<th>그래프 방식</th>
<th>추상화 수준</th>
<th>대표 용도</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>TensorFlow</td>
<td>Google</td>
<td>정적(Static) → 동적 혼합 지원</td>
<td>중간</td>
<td>대규모 배포, 산업용</td>
</tr>
<tr class="even">
<td>PyTorch</td>
<td>Meta</td>
<td>동적(Dynamic)</td>
<td>중간~고</td>
<td>연구, 실험, 학습</td>
</tr>
<tr class="odd">
<td>Keras</td>
<td>Google</td>
<td>TensorFlow 기반</td>
<td>가장 고수준</td>
<td>교육, 빠른 프로토타입</td>
</tr>
</tbody>
</table>
<p>결론적으로,</p>
<blockquote class="blockquote">
<p><strong>“TensorFlow → Keras”</strong> 는 상하관계(저수준 ↔︎ 고수준)이고, <strong>“TensorFlow ↔︎ PyTorch”</strong> 는 경쟁·대체 관계입니다. 따라서 ’고도화된 순서’라기보다 <strong>사용자 친화성과 추상화 수준이 높아진 방향</strong>으로 이해하는 것이 맞습니다.</p>
</blockquote>
<hr>
</section>
</section>
<section id="section" class="level1">
<h1>02</h1>
<ol type="1">
<li><strong>배치 경사하강법 (Batch Gradient Descent)</strong></li>
</ol>
<ul>
<li>전체 데이터셋을 <strong>한 번에</strong> 사용하여 손실 함수의 기울기를 계산.</li>
<li>즉, 한 epoch(모든 데이터 1회 학습)마다 <strong>한 번의 가중치 갱신</strong>만 수행.</li>
<li>정확하지만 계산량이 매우 크며, 대규모 데이터에서는 비효율적.</li>
</ul>
<ol start="2" type="1">
<li><strong>확률적 경사하강법 (Stochastic Gradient Descent, SGD)</strong></li>
</ol>
<ul>
<li>전체 데이터 중 <strong>하나의 샘플만(random)</strong> 선택하여 매번 가중치를 갱신.</li>
<li>즉, 데이터 1개 → 순전파 → 역전파 → 가중치 갱신.</li>
<li>계산이 빠르지만, 매번의 갱신이 불안정하고 진동(노이즈)이 많음.</li>
</ul>
<ol start="3" type="1">
<li><strong>미니배치 경사하강법 (Mini-batch Gradient Descent)</strong></li>
</ol>
<ul>
<li>위 두 방법의 절충안.</li>
<li><strong>배치</strong>와 <strong>확률적(SGD)</strong> 사이에 위치한 <strong>별도의 변형(variation)</strong>입니다.</li>
<li>즉, “하위 요소”가 아니라 <strong>같은 계열의 또 다른 종류</strong>입니다.</li>
<li>전체 데이터에서 <strong>랜덤하게 일정 크기(batch size)의 샘플 묶음</strong>을 선택하여 한 번의 갱신을 수행.</li>
<li>GPU의 병렬 행렬 연산에 최적화되어 있어 <strong>가장 일반적으로 사용</strong>됨.</li>
<li>“배치 경사하강법”이라 할 때 보통 이 방식을 의미하는 경우가 많음.</li>
</ul>
<ol type="1">
<li><strong>GPU 연산의 역할</strong></li>
</ol>
<ul>
<li>미니배치는 <code>행렬 연산</code> 단위로 묶이므로, GPU의 <strong>병렬 처리 성능</strong>을 최대한 활용 가능.</li>
<li>따라서 학습 속도가 대폭 향상됨.</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 11%">
<col style="width: 9%">
<col style="width: 11%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>방식</th>
<th>데이터 사용</th>
<th>연산 속도</th>
<th>안정성</th>
<th>실제 사용</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>배치(Batch)</td>
<td>전체</td>
<td>느림</td>
<td>매우 안정적</td>
<td>거의 안 씀 (대규모 데이터 비효율)</td>
</tr>
<tr class="even">
<td>확률적(SGD)</td>
<td>1개</td>
<td>매우 빠름</td>
<td>불안정</td>
<td>드묾</td>
</tr>
<tr class="odd">
<td>미니배치(Mini-batch)</td>
<td>일부 묶음</td>
<td>빠름</td>
<td>안정적</td>
<td><strong>표준</strong></td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<colgroup>
<col style="width: 37%">
<col style="width: 14%">
<col style="width: 17%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>구분</th>
<th>사용 데이터 크기</th>
<th>특징</th>
<th>관계</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Batch GD</strong></td>
<td>전체 데이터</td>
<td>매우 안정적, 느림</td>
<td>가장 기본형</td>
</tr>
<tr class="even">
<td><strong>Stochastic GD (SGD)</strong></td>
<td>1개 샘플</td>
<td>매우 빠름, 불안정</td>
<td>Batch GD의 확률적 형태</td>
</tr>
<tr class="odd">
<td><strong>Mini-batch GD</strong></td>
<td>일부 샘플 묶음</td>
<td>속도와 안정성의 균형</td>
<td><strong>Batch와 SGD의 중간형</strong></td>
</tr>
</tbody>
</table>
<p><strong>관계를 비유로 보면</strong></p>
<ul>
<li><strong>Batch</strong>: 전체 학생의 시험 평균을 계산 → 정확하지만 오래 걸림.</li>
<li><strong>SGD</strong>: 학생 한 명의 점수만 보고 평균을 추정 → 빠르지만 들쭉날쭉.</li>
<li><strong>Mini-batch</strong>: 학생 10명 단위로 묶어 평균 → 속도와 정확성의 균형.</li>
</ul>
<p>즉, 미니배치는 <strong>두 극단(전체 vs 단일)의 절충형</strong>이지, 둘 중 하나의 하위 개념이 아닙니다.</p>
<p><strong>수식적 관점</strong></p>
<p>손실 함수 ( J() )의 기울기를 구할 때:</p>
<ul>
<li><p><strong>Batch:</strong> (J() = _{i=1}^{m}L(x_i, y_i; ))</p></li>
<li><p><strong>SGD:</strong> (J() = L(x_i, y_i; )) (단일 샘플)</p></li>
<li><p><strong>Mini-batch:</strong> (J() = _{i B}L(x_i, y_i; )) (B는 랜덤하게 선택된 샘플 집합)</p></li>
</ul>
<hr>
<ol type="1">
<li>에폭(Epoch) 전체 학습 데이터셋이 <strong>한 번 모두 신경망을 통과한 횟수</strong>를 의미합니다.</li>
</ol>
<ul>
<li>데이터셋 전체를 미니배치 단위로 쪼개서</li>
<li>각 배치를 순차적으로 학습시킨 뒤,</li>
<li><strong>모든 배치를 1회 처리 완료하면 → 1에폭(epoch)</strong> 이 됩니다.</li>
</ul>
<ol start="2" type="1">
<li>왜 미니배치에서 중요해졌나?</li>
</ol>
<p>배치 경사하강법에서는</p>
<ul>
<li>한 번의 학습(기울기 계산) = 모든 데이터 사용 → 사실상 “1에폭 = 1회 학습”이었습니다. 그래서 <strong>에폭이라는 개념이 크게 필요하지 않았습니다.</strong></li>
</ul>
<p>반면 <strong>미니배치 방식</strong>에서는</p>
<ul>
<li>전체 데이터를 여러 묶음(batch)으로 나누어 학습하므로</li>
<li>한 번의 학습이 데이터 전체를 보지 않습니다. 따라서 “전체 데이터를 한 번 다 돌렸는가?”를 <strong>추적하기 위한 지표로 ’에폭’이 등장</strong>한 것입니다.</li>
</ul>
<ol start="3" type="1">
<li>예시로 보면</li>
</ol>
<p>데이터가 10,000개이고, 배치 크기(batch size)가 100이면,</p>
<ul>
<li>한 에폭 = 10,000 / 100 = <strong>100번의 미니배치 업데이트</strong>로 구성됩니다.</li>
<li>에폭이 10이라면 → 총 <strong>1,000번(=100×10)</strong> 가중치 갱신이 일어납니다.</li>
</ul>
<ol start="4" type="1">
<li>스텝(Step)</li>
</ol>
<ul>
<li>실제로 <strong>한 번의 가중치 업데이트</strong>를 의미합니다.</li>
<li>따라서 <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bsteps%20per%20epoch%7D%20=%20%5Cfrac%7B%5Ctext%7B%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EA%B0%9C%EC%88%98%7D%7D%7B%5Ctext%7Bbatch%20size%7D%7D%0A"></li>
</ul>
<p>예: 10,000개 데이터, batch size = 100 → 1 epoch = 100 steps, 10 epoch 학습 = 1,000 steps.</p>
<hr>
<p><strong>모든 데이터가 최소 한 번은 학습에 사용되도록 보장하기 위한 개념</strong>입니다.</p>
<ol type="1">
<li>미니배치의 확률적 샘플링 문제</li>
</ol>
<p>미니배치 경사하강법에서는 전체 데이터셋에서</p>
<ul>
<li><p><strong>랜덤하게 일부 샘플(batch)</strong>을 뽑아 학습합니다.</p></li>
<li><p>하지만 완전히 랜덤하게만 뽑으면,</p>
<ul>
<li>어떤 데이터는 여러 번 선택되고</li>
<li>어떤 데이터는 한 번도 선택되지 않을 가능성이 생깁니다.</li>
</ul></li>
</ul>
<p>이러면 학습이 <strong>데이터 전체 분포를 제대로 반영하지 못하게</strong> 됩니다.</p>
<ol start="2" type="1">
<li>이를 해결하기 위한 개념이 ‘에폭(Epoch)’</li>
</ol>
<p>그래서 학습 과정에서는 보통 다음과 같이 진행합니다:</p>
<ol type="1">
<li>전체 데이터셋을 한 번 <strong>셔플(shuffle)</strong> 한다.</li>
<li>셔플된 데이터를 <strong>미니배치 단위로 나눈다.</strong></li>
<li>나뉜 모든 배치를 한 번씩 학습시킨다. → <strong>이게 1에폭</strong></li>
<li>다음 에폭에서는 다시 셔플하여 <strong>새로운 확률적 조합</strong>으로 배치를 구성.</li>
</ol>
<p>이렇게 하면,</p>
<ul>
<li>각 데이터는 에폭당 <strong>정확히 한 번씩 학습에 참여</strong>,</li>
<li>여러 에폭이 반복되며 <strong>데이터 전체 분포를 다양하게 반영</strong>할 수 있게 됩니다.</li>
</ul>
<ol start="3" type="1">
<li>에폭은 “샘플링 균형의 최소 단위”</li>
</ol>
<blockquote class="blockquote">
<ul>
<li>미니배치: 데이터 일부를 한 번 학습시키는 단위</li>
<li>에폭: <strong>모든 데이터가 최소 한 번 학습에 포함되었는지 보장하는 단위</strong></li>
</ul>
</blockquote>
<p>이 두 개념이 결합되어야</p>
<ul>
<li>학습 효율성(속도)과</li>
<li>데이터 다양성(일반화 성능)을 동시에 확보할 수 있습니다.</li>
</ul>
<hr>
<ol type="1">
<li>확률적 경사하강법(SGD)의 장점</li>
</ol>
<ul>
<li>무작위성(Randomness) 때문에 <strong>지역 최적해(local minimum)</strong>에서 빠져나올 가능성이 높습니다.</li>
<li>큰 데이터셋에서도 <strong>빠른 업데이트</strong>가 가능해 효율적입니다.</li>
</ul>
<ol start="2" type="1">
<li>그러나 한계도 명확합니다</li>
</ol>
<ul>
<li>매번 소수의 샘플만으로 기울기를 계산하므로 <strong>기울기 추정의 분산이 큼</strong> → 학습이 <strong>불안정하게 요동</strong>함.</li>
<li><strong>학습률(learning rate)</strong>을 적절히 조정하지 않으면 발산하거나 너무 느리게 수렴함.</li>
<li><strong>전역 최적해(global optimum)</strong>까지는 수렴하기 어려움.</li>
<li>큰 데이터셋에서는 여전히 <strong>비효율적 반복 계산</strong>이 많음.</li>
</ul>
<ol start="3" type="1">
<li>그래서 등장한 것이 “Adam (Adaptive Moment Estimation)”</li>
</ol>
<p>Adam은 이러한 단점을 보완하기 위해 개발된 <strong>적응형(Adaptive) 최적화 알고리즘</strong>입니다. SGD의 확률성과 모멘텀(momentum), RMSProp의 학습률 보정 방식을 결합했습니다.</p>
<p><strong>Adam의 핵심 아이디어</strong></p>
<ul>
<li><strong>1차 모멘트(기울기의 평균)</strong>와</li>
<li><strong>2차 모멘트(기울기의 제곱 평균)</strong>을 동시에 추적. 이를 이용해 <strong>각 파라미터마다 다른 학습률을 자동 조정</strong>합니다.</li>
</ul>
<p>[ m_t = <em>1 m</em>{t-1} + (1 - _1) g_t] [ v_t = <em>2 v</em>{t-1} + (1 - _2) g_t^2] [ _{t+1} = _t - ]</p>
<p>이 식을 통해 Adam은</p>
<ul>
<li>진동을 줄이고,</li>
<li>수렴 속도를 높이며,</li>
<li>SGD보다 <strong>안정적이고 효율적인 학습 경로</strong>를 확보합니다.</li>
</ul>
<hr>
<p>https://www.geeksforgeeks.org/digital-logic/implementation-of-xor-gate-from-and-or-and-not-gate/ 해당 페이지는 XOR 게이트(배타적 논리합)의 구현 방법을 설명하면서, 기본 게이트인 AND 게이트, OR 게이트, NOT 게이트 을 이용해 XOR 게이트를 어떻게 구성할 수 있는지 그림과 논리식으로 보여주고 있습니다.</p>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_14.html</guid>
  <pubDate>Tue, 21 Oct 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>인공신경망</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_15.html</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p>Reporting Date: November. 19, 2025</p>
</blockquote>
<p>머신러닝에서 최적화(optimization)는 곧 고차원 매개변수 공간(parameter space)에서 최소점을 탐색하는 문제이며, 이 관점에서 학습 알고리즘은 본질적으로 탐색 알고리즘이다.</p>
<p>인공신경망의 맥락에서는 이를 학습 알고리즘이라 부르며, 가장 대표적인 접근이 확률적 경사하강법(Stochastic Gradient Descent, SGD)이다.</p>
<p>SGD는 손실 함수(loss function)의 기울기를 소량의 미니배치(mini-batch)로 근사하여 계산하기 때문에 계산 비용이 낮고 대규모 데이터셋에서도 효율적이다. 그러나 이러한 근사적 기울기는 <strong>통계적 분산이 크기 때문에 갱신 경로가 불안정하게 진동</strong>한다.</p>
<p>이 문제를 완화하기 위해 도입된 개념이 모멘텀(momentum)이다. 이는 물리학적 관점에서 관성(inertia)과 마찰력(friction)을 도입한 것으로, 갱신 벡터를 단순히 현재 기울기만으로 결정하지 않고 이전 갱신의 방향성을 누적해 속도 벡터를 형성한다.</p>
<p>결과적으로 최적화 경로는 비평면적(local curvature)의 영향을 덜 받고 안정적으로 수렴하며, 협곡형 지형(ravine)에서 진동을 줄이는 데 효과적이다.</p>
<section id="적응형-학습률" class="level2">
<h2 class="anchored" data-anchor-id="적응형-학습률">적응형 학습률</h2>
<p><code>adaptive learning rate</code> AdaGrad는 학습 과정에서 각 파라미터의 변화량에 따라 학습률을 자동 조정한다. 기울기의 제곱 누적합을 기반으로 학습률을 축소하기 때문에 자주 변하는 파라미터는 더 빠르게 학습률이 감소하고, 드물게 변하는 파라미터는 학습률이 상대적으로 유지된다. 이는 데이터의 기하학적 구조에 따라 비등방적(anisotropic) 최적화를 수행하는 효과가 있다.</p>
<p>Adam(Adaptive Moment Estimation)은 모멘텀과 AdaGrad의 장점을 결합한 비선형 최적화 알고리즘으로, 1차 및 2차 모멘트(기울기의 평균과 분산)를 동시에 추정한다.</p>
<p>AdaGrad처럼 학습률이 급격히 감소하여 학습이 조기 정지되는 문제를 완화하고, 모멘텀 기반 탐색보다 진동이 적으며 빠른 초기 수렴 속도를 갖는다. 실험적으로 Adam은 다양한 비정상적(non-stationary) 목적 함수에서 강건하며, 딥러닝 모델 전반에서 사실상 표준으로 사용된다.</p>
<p>최적화와 독립적으로, 모델의 일반화 성능을 향상하기 위해 정규화 기법이 도입되며 대표적인 것이 L2 정규화(weight decay)이다. 이는 가중치를 작게 유지함으로써 오버피팅을 방지하고, 매개변수 공간에서 불필요한 자유도를 억제함으로써 더 안정적인 표현 학습을 유도한다. 이는 통계학적 관점에서는 리지 회귀(ridge regression)의 페널티 항과 동일한 역할을 한다.</p>
</section>
<section id="가중치-초기화" class="level2">
<h2 class="anchored" data-anchor-id="가중치-초기화">가중치 초기화</h2>
<p><code>weight initialization</code> 학습 안정성을 결정하는 중요한 요소.</p>
<p>Xavier 초기화는 시그모이드 함수와 같은 대칭적 활성화 함수에서, 전방/역방 전파 시 분산이 일정하게 유지되도록 설계된 방식으로 표준편차를 (1/)에 비례하도록 설정한다.</p>
<p>ReLU 계열 함수에서는 활성 뉴런 비율이 달라지기 때문에 분산 유지 조건이 다르게 정의되며, 이에 기반한 He 초기화는 표준편차를 ()로 확장하여 표현력을 높이고 초기 활성화의 비선형 왜곡을 방지한다.</p>
<p>초기화가 중요한 이유는 깊은 신경망에서 발생하는 <strong>기울기 소실(vanishing gradient)</strong> 때문이다. 이는 활성화 함수의 포화 구간(saturation region)에서 기울기가 거의 0에 가까워지는 현상으로, 특히 시그모이드 함수는 입력이 조금만 크거나 작아도 기울기가 소멸한다. 이로 인해 초기 레이어는 거의 학습되지 않으며, 네트워크 전체가 비효율적으로 수렴한다. ReLU 함수는 양의 영역에서 기울기가 일정하게 유지되기 때문에 기울기 소실 문제를 근본적으로 완화하고, 깊은 모델의 학습을 가능하게 만든 핵심 요인이다.</p>
<p>딥러닝 분야에서 비교 실험은 필수적이며, 다양한 최적화 알고리즘과 초기화 전략을 CIFAR-10과 같은 벤치마크 데이터셋에서 체계적으로 검증하는 과정은 모델 성능 평가의 표준 절차다. 이러한 데이터셋은 역사적으로 많은 연구자(예: 마빈 민스키와 관련된 초기 신경망 논쟁 이후의 연구 흐름)에 의해 발전해 왔으며, 현대적 딥러닝 모델의 성능 비교와 구조적 혁신을 검증하는 중요한 실험 환경을 제공한다.</p>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_15.html</guid>
  <pubDate>Tue, 21 Oct 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>인공신경망</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_17.html</link>
  <description><![CDATA[ 




<blockquote class="blockquote">
<p>Reporting Date: December. 10, 2025</p>
</blockquote>
<p>클러스터링 군집화 계층적 클러스터링에서 응집형과 분리형으로 나뉜다. 완전 연결 기반 상위 클러스터 구성 방법 - 점들 사이의 거리 계산. 허용치 범위 안에 있으면 묶는다.</p>
<p>밀도 기반 클러스터링 DBSCAN 4개이상이 포함되면 하나의 클러스터로 인정. 코어와 경계 데이터로 나뉜다.</p>
<p>이 방식은 차원의 저주 문제 발생 가능. 데이터의 차원이 증가 시 해당 공간의 부피가 기하급수적으로 증가하게 되고 모델을 추정을 위해</p>
<p>노이즈 데이터는 데이터셋이 아닌 클러스터 관점에서의 노이즈인 것이다. 코드: 어떤 결과의 차이가 있는지?</p>
<p>–</p>
<p>클러스터링 방법을 이용해서 추천방법을 활용할 수 있다.</p>
<p>예제: 스포티파이 - 음악 컨텐츠의 풍부. 추천의 정확도가 높다. 카페에서의 매출 영향은 음료 뿐만 아니라 음악도 해당됨.</p>
<p>고려해야 될 요소 회원가입, 사용자의 인구통계학적 속성 정보 콘텐츠의 속성 정보, 이용정보, 구매정보</p>
<p>쉬운 - 내용 기반 추천 콘텐츠의 피처를 갖고 벡터변환-유사도 계산 알려진 선호 아이템들의 집합에 대해 내용을 분석 개념은 간단하다. 가장 쉽게 개발할 수 있는 것이다. 콜드 스타트 문제가 없음.</p>
<p>중간 - 인구통계학적 추천, 인구학적 그룹잉을 통한 방법이며 카이제곱 분석을 한다. 다만 노이즈에 약하다.</p>
<p>어려운 - 협력적 여과 추천(이용 정보) 여기에서는 콜드스타트 문제가 발생한다. 유사도 계산 - 예측값 계산 아이템에 내용 정보가 없어도 추천 가능 다만 고객 수가 많아질 수록 시간 소요 증가 희소성 문제 발생 가능. 다른 분야를 추천하지 않음. 롱테일 문제</p>
<p>아마존은 아이템 기반 협력적 추천 기법을 사용하였다. 인구통계학적으로 가로 방향으로 묶지 않고 아이템 간에 세로 방향으로 묶는다. 해당 아이템을 좋아한다면, 다른 아이템도 좋아할 확률 계산.</p>
<p>넥플리스는 협력 필터링 기반 알고리즘이며, 이때 최초로 나옴 베이지안 분류, 증가하에서 가설일 가능성으로 계산. 동시 발생 상관관계, 연관성 규칙의 측량 방법, 지지도, 향상도 뉴럴 네트워크</p>
<p>유튜브, 뉴럴렛, 벡터, 협력적 기법 혼합 사용.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_17.html</guid>
  <pubDate>Tue, 21 Oct 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>단계별 머신러닝 학습</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_10.html</link>
  <description><![CDATA[ 




<p>시그모이드, 소프트맥스, 다층 퍼셉트론 등에 대해 다루고자 한다.</p>
<p>01 다중 회귀 Multiple Regression</p>
<p>앞서 살펴본 단일 입력(단변량, single variable) 회귀모델은 하나의 독립 변수만을 고려하였다.</p>
<p>그러나 실제 데이터 분석에서는 여러 입력값을 동시에 반영하는 다중 회귀 모델이 보다 현실적이고 효과적으로 활용된다.</p>
<p>이 모델은 여러 독립 변수(feature)를 기반으로 종속 변수(target)를 예측하며, 복잡한 현실 세계의 관계를 선형적으로 근사할 수 있다.</p>
<p>다중 회귀의 기본 구조는 단일 회귀와 동일하다. 입력 변수의 개수만 증가하고, 이에 대응하는 가중치(weight) 역시 벡터 형태로 확장된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D%20=%20w_1%20x_1%20+%20w_2%20x_2%20+%20%5Cdots%20+%20w_n%20x_n%20+%20b"></p>
<p>w_i: 각 특성(feature)에 대한 가중치, x_i: 입력 변수, b: 절편(bias)</p>
<p>1 . 벡터와 행렬 기반 연산 입력 변수가 증가하더라도 손실함수의 계산 원리는 변하지 않는다. 다만, 계산의 복잡성이 높아지므로, 가중치와 입력값을 벡터 또는 행렬 형태로 표현된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D,%20%5Cquad%20%5Cmathbf%7Bw%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%201%7D,%20%5Cquad%20%5Chat%7B%5Cmathbf%7By%7D%7D%20=%20%5Cmathbf%7BX%7D%5Cmathbf%7Bw%7D%20+%20%5Cmathbf%7Bb%7D"></p>
<p>m: 데이터 포인트(샘플)의 수 n: 특성(feature)의 수 이러한 행렬 표현을 통해 모든 샘플에 대한 예측을 단일 연산으로 수행할 수 있어 모델 학습 과정의 계산 효율성(computational efficiency)이 크게 향상된다.</p>
<p>2 . 핵심 선형대수 연산 핵심 연산은 다음과 같다.</p>
<p>① 내적(dot product)</p>
<p>두 벡터의 방향과 크기를 비교하는 연산으로, 회귀에서는 예측값 계산 및 유사도 측정((cos θ))에 주로 활용된다.</p>
<p>② 외적(cross product)</p>
<p>두 벡터에 수직인 새로운 벡터를 생성하며, (sin θ)를 통해 방향성을 표현한다. 다만 외적은 회귀 분석이나 유사도 계산보다는 물리적 벡터 계산에서 주로 사용된다.</p>
<p>고차원 연산과 병렬 처리 다중 입력 연산은 수많은 곱셈과 덧셈을 포함하므로, 입력 차원이 커질수록 연산 부하가 기하급수적으로 증가한다. 특히 이미지, 영상, 음성 등 대규모 데이터셋에서는 이 문제가 더욱 두드러진다.</p>
<p>이러한 연산 복잡도를 해결하기 위해 병렬 연산(parallel computation)기법이 적용되며, 대표적으로 GPU가 사용된다.</p>
<p>GPU는 수천 개의 코어를 이용해 행렬 및 벡터 연산을 동시에 수행하므로, 3차원 좌표 변환이나 2차원 이미지 처리 등 고속 연산 환경에서 탁월한 성능을 발휘한다.</p>
<p>또한 CUDA와 같은 GPU 전용 병렬처리 라이브러리 사용 시 AI 모델 학습 과정에서 연산 속도를 획기적으로 향상시킬 수 있다.</p>
<p>이와 같이 확장된 회귀모델의 기반에는 선형대수(linear algebra)가 자리하고 있으며, 모든 계산은 행렬 곱, 내적, 외적 등 선형대수적 연산 원리에 의해 수행된다.</p>
<p>3 . 스케일링과 정규화 scaling &amp; normalization</p>
<p>다중 회귀 모델의 학습 과정에서는 입력 데이터의 스케일 차이가 학습 안정성과 예측 정확도에 큰 영향을 미칠 수 있다.</p>
<p>이를 방지하기 위해, 각 특성(feature)을 동일한 기준으로 조정하는 스케일링과 정규화 과정이 필수적이다.</p>
<p>① 스케일링</p>
<p>각 변수의 단위나 값의 범위 차이로 인해 특정 특성이 모델 학습 과정에서 과도하게 영향을 미치는 문제를 방지한다.</p>
<p>예: 각 값에 대해 최대값 또는 범위를 기준으로 나누어 0~1 범위로 조정</p>
<p>② 정규화</p>
<p>Z-점수 정규화를 적용하여, 데이터를 평균 0, 표준편차 1의 정규분포로 변환하면 특성 간 스케일 불균형을 더욱 효과적으로 완화할 수 있다.</p>
<p>예: 데이터가 타원형 분포를 가진 경우 각 값을 최대값으로 나누어 원형 형태로 정규화할 수 있다.</p>
<p>이러한 변환을 수행하면 손실 함수의 등고선(contour)이 타원형에서 원형으로 바뀌어, 경사하강법의 수렴 속도와 안정성이 향상된다.</p>
<p>즉, 모든 입력값을 동일한 기준으로 인식하도록 조정하여 모델이 보다 균형 잡힌 방식으로 최적화를 수행하게 만든다.</p>
<p>참고로, 변동계수(CV)는 데이터의 상대적 분산을 평가하는 보조 지표로 활용될 수 있으나, 본 장에서는 필수 적용 사항은 아니다.</p>
<p>02 분류와 비선형 함수의 개념 Classification &amp; Nonlinear Functions</p>
<p>앞서 다중 및 다항 회귀를 통해 연속적인 수치값을 예측하는 모델 구조를 살펴보았다.</p>
<p>그러나 실제 문제의 상당수는 단순한 수치 예측이 아닌, “이것이냐, 저것이냐”와 같은 범주형(class) 결과를 요구한다.</p>
<p>이처럼 출력값이 명확히 구분되는 문제에서는 회귀(regression) 대신 분류(classification) 개념이 사용된다.</p>
<p>그중에서도 두 가지 범주를 구분하는 가장 기본적인 형태가 이진 분류(binary classification) 이다.</p>
<p>대표적인 활용 사례는 다음과 같다.</p>
<p>스팸 메일 탐지: 스팸 / 정상 소셜 미디어 콘텐츠 노출 결정: 보이기 / 숨기기 신용카드 부정 거래 탐지: 정상 / 이상 MRI 영상 판독: 정상 / 비정상 이와 같이, 분류 문제는 연속적 수치 예측과 달리 출력값이 불연속적이고 범주형이라는 점에서 학습 방식과 손실 함수, 모델 설계 측면에서 특수성을 가진다.</p>
<p>1 . 회귀에서 분류로의 전환 선형 회귀는 입력값의 선형 결합을 통해 연속적인 출력값을 생성한다.</p>
<p>그러나 분류 문제에서는 출력이 특정한 범위 내에 속해야 하며, 즉 결과값이 “0 또는 1”, “긍정 혹은 부정”처럼 해석 가능한 확률 형태로 제한될 필요가 있다.</p>
<p>예를 들어, 종양의 크기에 따라 악성(1)과 양성(0)을 분류하는 문제를 생각해보자.</p>
<p>데이터에서 “크기 40 이상일 때 악성” 으로 정의하면, 단순 선형 모델은 30 ~ 40 사이에 결정 경계선(decision boundary)을 그어 두 범주를 구분할 수 있다.</p>
<p>그러나 새로운 데이터에서 70 이상의 값이 등장하면, 기존 경계선이 더 이상 유효하지 않아 새로운 기준선 재설정 문제가 발생한다.</p>
<p>이러한 한계를 해결하기 위해, 선형 출력값을 0 ~ 1 사이로 압축하여 확률적으로 해석 가능한 비선형 변환 함수(activation function)가 도입된다.</p>
<p>그중 가장 대표적인 예가 시그모이드 함수이다.</p>
<p>2 . 시그모이드 함수 Sigmoid Function</p>
<p>시그모이드 함수는 실수 입력값 (z)를 받아 이를 0 ~ 1 사이의 실수 값으로 변환하는 비선형 함수이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma(z)%20=%20%5Cfrac%7B1%7D%7B1%20+%20e%5E%7B-z%7D%7D"></p>
<p>여기서 (z)는 이전 장에서 다룬 선형 결합 (WX)에 해당한다. 즉, 회귀모델의 출력값을 시그모이드 함수에 통과시켜 확률(probability) 형태로 변환하는 과정이다.</p>
<p>확률적 해석 가능</p>
<p>입력값이 매우 크면 1에 근접 입력값이 매우 작으면 0에 근접 이 함수는 ” 연속적인 선형 출력을 상·하한이 존재하는 구간으로 압축하는 변환 ” 으로 이해할 수 있다.</p>
<p>부드러운 결정 경계</p>
<p>S자 곡선(S-shaped curve)을 형성하며, 입력값이 증가에 따라 악성일 확률이 점진적으로 증가한다. 선형 출력이 비선형적으로 압축되어, 부드러운 결정 경계를 제공한다.</p>
<p>미분 연속성</p>
<p>미분이 연속적이므로, 경사하강법과 같은 최적화 알고리즘에서 기울기 계산이 원활하다.</p>
<p>이러한 특성 덕분에 시그모이드 함수는 암 진단(양성/음성), 이메일 스팸 분류(스팸/정상) 등 이진 분류 문제에서 확률 기반 의사결정을 수행하는 핵심 요소로 활용된다.</p>
<p>3 . 하이퍼볼릭 탄젠트 함수 Hyperbolic tangent Function</p>
<p>시그모이드 함수와 유사하게, 하이퍼볼릭 탄젠트(tanh) 함수도 입력값을 비선형적으로 변환하는 함수이다.</p>
<p>이 함수는 다음과 같이 정의된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctanh(z)%20=%20%5Cfrac%7Be%5E%7Bz%7D%20-%20e%5E%7B-z%7D%7D%7Be%5E%7Bz%7D%20+%20e%5E%7B-z%7D%7D"></p>
<p>출력값은 -1 ~ 1 사이에 위치한다. 중심이 0 에 있어, 시그모이드보다 학습 과정에서 안정성이 높다. 예: 감정 분석에서 긍정(+1)과 부정(-1)을 구분, 좋아요/싫어요 같은 양방향 선택 구조를 다룰 때 유용하다.</p>
<p>단, 음의 출력 범위를 포함하므로 연산적으로 시그모이드보다 약간 복잡하며, 데이터 특성에 따라 선택적으로 적용된다.</p>
<p>비교표 함수 출력 범위 중심값 주 용도 장점 시그모이드 0 ~ 1 0.5 확률 기반 이진 분류 확률적 해석 용이, 단순 하이퍼볼릭 탄젠트 -1 ~ +1 0 양극적 분류(긍정/부정) 중심 0, 학습 안정성 높음 시그모이드와 tanh는 모두 선형 회귀 결과를 비선형적으로 변환하여 확률 또는 분류 경계를 생성하는 역할을 한다.</p>
<p>이러한 활성화 함수의 도입은 회귀모델이 “연속 예측”에서 “범주 판별”로 확장되는 전환점이며, 이후의 심층신경망(Deep Neural Network) 구조에서도 핵심적 역할을 수행한다.</p>
<p>03 다중 입력 확장</p>
<p>1 . 가설 Hypothesis</p>
<p>단일 입력 로지스틱 회귀에서처럼, 여러 입력(feature)을 동시에 고려할 경우에도 원리는 동일하다.</p>
<p>입력값의 선형 결합 (z = WX + b)를 시그모이드 함수에 통과시키면 출력값이 0 ~ 1 사이의 확률로 변환된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?h(X)%20=%20%5Csigma(WX%20+%20b)%20=%20%5Cfrac%7B1%7D%7B1%20+%20e%5E%7B-(WX+b)%7D%7D">​</p>
<p>이 확률값은 주어진 입력이 특정 범주에 속할 가능성을 의미하며, 이를 통해 이진 분류 문제에서 직관적이고 안정적인 의사결정이 가능하다.</p>
<p>2 . 다중 입력 확장 Multivariate Input</p>
<p>현실 세계의 데이터는 단일 입력보다는 여러 독립 변수(feature)를 동시에 고려해야 하는 경우가 많다.</p>
<p>다중 입력의 경우에도 선형 결합의 구조는 동일하며, 단지 입력 벡터와 가중치 벡터를 확장하여 계산한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?z%20=%20W_1%20x_1%20+%20W_2%20x_2%20+%20%5Cdots%20+%20W_n%20x_n%20+%20b%20=%20WX%20+%20b"></p>
<p>이렇게 계산된 다중 입력 결과는 소프트맥스(Softmax) 함수를 통해 정규화될 수 있다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BSoftmax%7D(z_i)%20=%20%5Cfrac%7Be%5E%7Bz_i%7D%7D%7B%5Csum_j%20e%5E%7Bz_j%7D%7D"></p>
<p>소프트맥스는 각 범주의 확률 합이 1이 되도록 조정하며, 출력값이 여러 클래스 중 하나로 분류될 수 있도록 확률 기반 해석 제공</p>
<p>다중 클래스 분류 문제에서 필수적인 역할을 수행한다.</p>
<p>3 . 다중 클래스(Softmax + 원-핫) 확장 다중 클래스 문제에서는 각 클래스 k에 대해 선형 점수(score)를 계산하고 소프트맥스(Softmax)로 확률분포를 얻는다.</p>
<p><img src="https://latex.codecogs.com/png.latex?s_k%20=%20w_k%5E%5Ctop%20x%20+%20b_k,%5Cqquad%20p_k=%5Cfrac%7Be%5E%7Bs_k%7D%7D%7B%5Csum_j%20e%5E%7Bs_j%7D%7D"></p>
<p>손실은 다중 클래스 크로스엔트로피(원-핫 레이블 y 기준):</p>
<p><img src="https://latex.codecogs.com/png.latex?J=-%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi=1%7D%5Em%5Csum_%7Bk%7D%20y%5E%7B(i)%7D_k%20%5Clog%20p_k%5E%7B(i)%7D">​</p>
<p>구조적으로 퍼셉트론과 유사하며, 신경망(NN)의 전단계로 이해할 수 있다.</p>
<p>4 . 다층 페셉트론 Multi-Layer Perceptron, MLP</p>
<p>단일 로지스틱 회귀와 다중 입력 확장을 기반으로, 구조를 여러 층으로 확장하면 다층 퍼셉트론이 된다.</p>
<p>각 층에서는 선형 변환과 비선형 활성화가 반복 적용되며, 입력 간의 복잡한 상호작용과 패턴을 학습할 수 있다.</p>
<p>MLP는 심층 신경망(DNN)의 기본 단위로, 다층 구조를 통해 비선형적 결정 경계와 복잡한 데이터까지 패턴 학습이 가능하다.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_10.html</guid>
  <pubDate>Mon, 20 Oct 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>SVM: 비확률적 마진 기반 분류기</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_07.html</link>
  <description><![CDATA[ 




<p>SVM, 즉 비확률적 마진 기반 분류기에 대해 다루고자 한다.</p>
<p>수준별 이해도 ① 데이터 정제 및 전처리</p>
<p>대상: 기존 IT 인력 요구 수준: 기본적인 이해로 충분하며, 실무 적용 중심 내용: 결측치 처리, 이상치 제거, 형식 변환 등 데이터의 품질을 높이는 작업 ② 모델링(연계 결합, 파이프라인 구성)</p>
<p>대상: 석사 및 박사 수준의 연구자 요구 수준: 심층적인 이해와 설계 능력 필요 내용: 모델의 구조 설계, 학습 및 추론 과정의 최적화, 다양한 알고리즘의 조합 및 실험 ③ 알고리즘 설계</p>
<p>대상: 석사 및 박사 수준의 연구자 요구 수준: 이론적 배경과 수학적 이해가 필수 내용: 새로운 알고리즘의 개발, 기존 알고리즘의 개선, 수학적 모델링 및 분석 이러한 단계별 구분은 일반적으로 데이터 과학 및 AI 분야에서의 역할 분담과 학습 경로를 반영한 것이다.</p>
<p>실무에서는 데이터 정제 및 전처리가 핵심적인 역할을 하며, 연구 및 개발 단계에서는 모델링과 알고리즘 설계가 중심이 된다.</p>
<p>우리는 이번 과정에서 모델링(연계 결합 및 파이프라인 구성) 단계에 초점을 맞춰 배워볼 것이다.</p>
<p>01 서포트 벡터 머신 Support Vector Machine, SVM</p>
<p>SCRIPT https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js 기본적으로 선형 분리(linear separator) 찾는 알고리즘.</p>
<p>데이터가 선형적으로 구분되지 않을 경우, 커널(kernel)을 이용하여 입력 데이터를 더 높은 차원 공간으로 사상(mapping)한 뒤 선형 판별을 수행한다.</p>
<p>대표적인 예로 다항식 커널(polynomial kernel) 은 다음과 같이 정의된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?K(%5Cmathbf%7Bx%7D,%20%5Cmathbf%7By%7D)%20=%20(%5Cmathbf%7Bx%7D%5E%5Ctop%20%5Cmathbf%7By%7D%20+%20c)%5Ed"></p>
<p>이 커널은 입력 벡터의 고차항 조합을 암시적으로 고려한다.</p>
<p>또한, 명시적으로 모든 고차항을 계산하지 않아도 커널 트릭(kernel trick) 을 통해 고차원 특징 공간에서의 내적을 효율적으로 대체할 수 있다.</p>
<p>① 특징(feature) / 속성, 변수</p>
<p>데이터의 각 관측치는 여러 개의 속성으로 구성되며, 이를 (x_1, x_2, , x_n)​으로 표현한다.</p>
<p>이때 이 (n)개의 속성을 차원(dimension) 이라고 한다.</p>
<p>② 차수(degree)</p>
<p>일반적으로 다항식(polynomial)의 최고 지수(exponent)를 의미한다.</p>
<p>예: 다차원 입력 ((x_1, x_2)) 에 대해 (x_1^2), (x_1 x_2), (x_2^2) 등 고차항(high-order term) 을 추가하면 모델은 비선형(곡선 형태) 관계를 표현할 수 있게 된다.</p>
<p>02 데이터의 벡터 표현 데이터는 점과 방향성을 갖는 벡터(vector) 로 표현될 수 있다.</p>
<p>벡터는 스칼라(scalar)와 달리 크기뿐 아니라 방향을 가지며, 이를 표현하기 위해서는 시작 좌표와 끝 좌표가 필요하다.</p>
<p>한편, 어떤 점 ((x_1, x_2, , x_n))도 원점을 기준으로 하면 원점에서 그 점까지의 벡터로 간주할 수 있다. 즉, 점과 벡터는 서로 밀접한 개념이며, 데이터는 수학적으로 이러한 벡터 형태로 표현된다.</p>
<p>자연어 처리(NLP)에서는 문장을 단어(토큰) 단위로 나누고, 각 단어를 하나의 임베딩 벡터(embedding vector) 로 나타낸다.</p>
<p>이를 다음과 같이 표현할 수 있다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D_i%20=%20(x_%7Bi1%7D,%20x_%7Bi2%7D,%20%5Cdots,%20x_%7Bid%7D)%20%5Cin%20%5Cmathbb%7BR%7D%5Ed"></p>
<p>(i:) 문장 내 단어의 인덱스 (d:) 임베딩 공간의 차원(dimension) 모든 단어 벡터는 동일한 차원 (d)를 가지며, 유사한 의미를 가진 단어들은 벡터 공간상에서 가까운 위치에 존재한다. 이러한 벡터 표현은 문장 내 의미적 관계를 수치적으로 분석할 수 있게 해 준다.</p>
<p>03 토큰 수와 표현의 제약</p>
<p>1 . 언어 모델의 입력 구조 언어 모델은 입력할 수 있는 토큰(token) 의 수에 제한이 있다. 즉, 모델은 정해진 최대 토큰 길이(max token length) 이내의 입력만 처리할 수 있다.</p>
<p>또한, 각 토큰은 고정된 차원 (d)의 임베딩 벡터(embedding vector) 로 변환되므로, 모델의 입력 공간 역시 차원이 고정되어 있다고 할 수 있다.</p>
<p>① 고전적 표현 방식</p>
<p>Bag-of-Words 또는 One-hot Encoding 에서는 문장 내 각 단어의 존재 여부를 0과 1로 표시하여 표현하였다.</p>
<p>예: 특정 단어가 문장에 포함되어 있으면 1, 포함되지 않으면 0으로 나타내는 방식.</p>
<p>② 현대적 표현 방식</p>
<p>임베딩 기반 모델(embedding-based model) 에서는 이진값이 아닌 실수(real-valued) 벡터를 사용하며, 단어의 의미 유사성과 문맥 정보를 함께 반영한다.</p>
<p>이로써 모델은 단순한 단어 포함 여부를 넘어, 단어 간의 의미적 관계와 문맥적 상호작용까지 학습할 수 있다.</p>
<p>2 . 문장의 벡터 표현과 유사도 계산 문장은 이러한 단어(토큰)들의 벡터로 구성되며, 전체 문장은 다차원 공간 상의 하나의 점(vector) 으로 표현된다.</p>
<p>문장 간의 유사도는 두 벡터 간의 거리(distance) 나 코사인 유사도(cosine similarity) 를 통해 측정할 수 있으며, 거리가 가까울수록 의미적으로 유사한 문장으로 해석된다.</p>
<p>그러나 실제 데이터는 차원이 매우 높고, 대부분의 값이 0인 희소(sparse) 형태를 띤다.</p>
<p>이러한 고차원 희소 표현은 계산 비용은 크고 메모리 효율은 낮아, 이를 더 작은 차원으로 변환하는 차원 축소(dimensionality reduction) 가 필요하다.</p>
<p>차원 축소는 본래 의미 구조를 최대한 보존 및 데이터 압축 과정이다.</p>
<p>대표적인 기법: PCA(주성분분석), SVD(특이값 분해), 워드 임베딩(word embedding) 등.</p>
<p>이 과정을 통해 얻어진 밀집 벡터(dense vector) 는 정보가 효율적으로 압축된 형태로, 계산 효율이 높고 모델이 의미적 관계를 더욱 잘 학습할 수 있다.</p>
<p>이러한 벡터는 저차원 공간으로 투영(projection) 되어, 이후의 학습, 분류, 또는 유사도 계산 등의 연산에 활용된다.</p>
<p>04 SVM의 핵심 개념</p>
<p>Support Vector Machines (SVM): An Intuitive Explanation</p>
<p>Everything you always wanted to know about this powerful supervised ML algorithm</p>
<p>medium.com</p>
<p>출처: Tibrewal (2021), Medium – Support Vector Machines (SVM)</p>
<p>1 . 결정 경계 Decision Boundary</p>
<p>SVM은 두 클래스를 분리하는 초평면 (^ + b = 0) 을 찾는다.</p>
<p>쉽게 말해, 데이터를 두 클래스(예: 빨간 점 vs 파란 점)로 나누는 선(2차원) 또는 초평면(3차원 이상) 을 찾는 것이며, 핵심 목표는 두 클래스 사이의 “간격”을 최대화하는 초평면을 찾는 것이다.</p>
<p>초평면의 수학적 표현과 조건 결정 경계: (^ + b = 0) 마진 경계: (^ + b = +1) 또는 (^ + b = -1) 서포트 벡터 조건: (y_i(^_i + b) = 1)</p>
<p>2 . 마진 Margin</p>
<p>결정 경계와 서포트 벡터 사이의 거리. SVM은 이 마진을 최대화하는 초평면을 찾는다.</p>
<p>마진이 넓을수록 모델의 일반화 능력이 향상되어, 새로운 데이터가 들어와도 결정 경계가 잘못 분류될 가능성이 줄어든다.</p>
<p>즉, 마진 크기와 분류 오류 확률은 반비례 관계에 있다.</p>
<p><img src="https://latex.codecogs.com/png.latex?P_%7B%5Ctext%7Berror%7D%7D%20%5Cpropto%20%5Cfrac%7B1%7D%7B%5Cgamma_2%7D"></p>
<p>SVM은 “마진 최대화 문제” 를 풀어 초평면을 결정한다. 수학적으로는 다음 문제를 푼다:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmin_%7B%5Cmathbf%7Bw%7D,%20b%7D%20%5Cfrac%7B1%7D%7B2%7D%20%5C%7C%5Cmathbf%7Bw%7D%5C%7C%5E2%20%5Cquad%20%5Ctext%7Bs.t.%7D%20%5C;%20y_i(%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D_i%20+%20b)%20%5Cge%201"></p>
<p>(:) 초평면의 법선 벡터(normal vector) ( b ; : ; ) 편향(bias) (y_i:) 클래스 레이블(+1 또는 -1) (_i:) 각 데이터 점 이 문제는 Lagrange 승수법 및 이중 문제(dual problem)를 통해 풀 수 있으며, 서포트 벡터만으로도 최적의 초평면을 결정할 수 있다.</p>
<p>3 . 서포트 벡터 Support Vectors</p>
<p>결정 경계 또는 마진 경계에 가장 가까운 데이터 포인트들. 쉽게 말해, “초평면을 밀었을 때 점들이 가장 먼저 닿는 위치”이다.</p>
<p>이 점들은 초평면의 위치와 방향을 결정하며, 나머지 점들은 보통 결정 경계에 영향을 주지 않는다.</p>
<p>(단, soft margin SVM에서는 일부 내부 점이 영향을 줄 수도 있다.)</p>
<p>05 SVM의 최적화 문제 앞서 설명한 마진 최대화 문제에서, 이상치가 존재하거나 데이터가 완전히 선형적으로 분리되지 않는 경우 슬랙 변수 (_i)를 도입한다.</p>
<p>이는 약간의 분류 오류를 허용하면서 마진 최대화가 가능해, 각 데이터 포인트의 결정 경계에서의 거리를 고려하는 힌지 손실 함수로 최적화 문제를 정의한다.</p>
<p>SVM의 최적화 문제는 다음과 같이 표현된다:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmin_%7B%5Cmathbf%7Bw%7D,%20b%7D%20%5Cfrac%7B1%7D%7B2%7D%20%7C%7C%5Cmathbf%7Bw%7D%7C%7C%5E2%20+%20C%20%5Csum_%7Bi=1%7D%5E%7BN%7D%20%5Cxi_i"></p>
<p>단, 제약 조건은 다음과 같다:</p>
<p><img src="https://latex.codecogs.com/png.latex?y_i%20(%5Cmathbf%7Bw%7D%5E%5Ctop%20%5Cmathbf%7Bx%7D_i%20+%20b)%20%5Cgeq%201%20-%20%5Cxi_i,%20%5Cquad%20%5Cxi_i%20%5Cgeq%200%20%5Cquad%20%5Cforall%20i"></p>
<p>(_i:) 슬랙 변수(허용 오차) (C:) 정규화 파라미터</p>
<p>1 . 슬랙 변수 &amp; 힌지 손실 Slack Variable &amp; Hinge Loss</p>
<p>슬랙 변수 (_i)는 각 데이터 포인트가 결정 경계에서 얼마나 벗어났는지를 나타낸다.</p>
<p>이는 힌지 손실 함수와 동일한 역할을 한다:</p>
<p><img src="https://latex.codecogs.com/png.latex?L(y_i,%20f(%5Cmathbf%7Bx%7D_i))%20=%20%5Cmax(0,%201%20-%20y_i%20f(%5Cmathbf%7Bx%7D_i))"></p>
<p>여기서 (f(_i) = ^_i + b)이다. 이 함수는 다음과 같은 경우에 대해 다르게 동작한다:</p>
<p>(_i)가 정확하게 분류됨, 마진을 만족하는 경우: 손실 0 (_i)가 정확하게 분류됨, 마진 내에 있는 경우: 양의 손실 (_i)가 잘못 분류됨: 큰 손실 이러한 손실은 모델이 마진을 넓히고 오차를 최소화하도록 유도한다.</p>
<p>2 . 비선형 분류를 위한 커널 방법 비선형 데이터의 경우, SVM은 커널 함수를 사용하여 고차원 특성 공간으로 데이터를 매핑한다. 이는 선형적으로 분리 불가능한 데이터를 선형적으로 분리할 수 있게 된다.</p>
<p>커널 함수는 다음과 같은 형태를 가진다:</p>
<p><img src="https://latex.codecogs.com/png.latex?K(%5Cmathbf%7Bx%7D_i,%20%5Cmathbf%7Bx%7D_j)%20=%20%5Cphi(%5Cmathbf%7Bx%7D_i)%5E%5Ctop%20%5Cphi(%5Cmathbf%7Bx%7D_j)"></p>
<p>(())는 특성 공간으로의 매핑 함수(basis function, kernel)로, 커널 트릭을 사용하면 내적 계산만으로 고차원 공간에서의 계산을 효율적으로 수행할 수 있다.</p>
<p>현실 데이터에서는 선형 관계보다는 비선형 관계가 더 흔하다.</p>
<p>예: AND, OR 게이트는 선형적으로 분리 가능하지만 XOR 게이트는 선형 경계로 구분할 수 없으며, 이를 해결하려면 2차원 이상의 고차원 공간으로 매핑해야 직선(초평면)으로 구분 가능하다.</p>
<p>따라서 XOR 문제와 같이 선형 분리가 어려운 문제를 표현하기 위해 AI 연구자들은 원 공간(original space)에서 고차원 매핑 공간(mapping space)으로 데이터를 변환하는 개념을 도입했다.</p>
<p>이때 사용되는 함수들을 커널 함수(kernel function)라 부르며, 매핑된 공간(mapping space)에서는 비선형 데이터가 선형적으로 분리 가능해진다.</p>
<p>대표적인 커널 함수: 선형(linear), Gaussian (RBF), 다항식(polynomial), sigmoid 등.</p>
<p>한편, 데이터 처리 과정에서 발생하는 노이즈는 측정 오류나 무작위 변동에 의해 생기는 것으로 일반적으로 제거를 고려한다.</p>
<p>반면 이상치는 데이터 패턴에서 벗어난 극단적인 값으로 유의미한 정보를 포함할 수 있어 분석에 포함되기도 한다.</p>
<p>노이즈와 이상치를 구분하는 기준은 보통 도메인 전문가의 판단에 따라 결정된다.</p>
<p>4 . 최적화 문제의 이중 문제 Dual Problem</p>
<p>SVM의 최적화 문제는 이중 문제로 변환할 수 있으며, Lagrange 승수 (_i)를 도입하여 다음과 같이 표현된다:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmax_%7B%5Calpha%7D%20%5Csum_%7Bi=1%7D%5E%7BN%7D%20%5Calpha_i%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi,j=1%7D%5E%7BN%7D%20%5Calpha_i%20%5Calpha_j%20y_i%20y_j%20K(%5Cmathbf%7Bx%7D_i,%20%5Cmathbf%7Bx%7D_j)"></p>
<p>단, 제약 조건은 다음과 같다:</p>
<p><img src="https://latex.codecogs.com/png.latex?0%20%5Cleq%20%5Calpha_i%20%5Cleq%20C,%20%5Cquad%20%5Csum_%7Bi=1%7D%5E%7BN%7D%20%5Calpha_i%20y_i%20=%200"></p>
<p>이 이중 문제를 풀면 최적의 (_i)를 얻을 수 있으며, 이를 통해 초평면의 계수 ()와 (b)를 계산할 수 있다.</p>
<p>06 모델 일반화와 조정</p>
<p>1 . 하이퍼파라미터 상수 (C)는 슬랙 변수에 부여되는 패널티 강도(regularization strength)를 조절한다.</p>
<p>(C)가 크면: 오차를 최소화하려는 경향이 강해져 과적합 위험 증가 (C)가 작으면: 마진 증가 및 일부 오차를 허용하여 일반화 성능 향상 즉, (C) 값은 결정 경계의 유연성을 결정하는 핵심 요인이다. 이 값을 조정하는 과정을 하이퍼파라미터 튜닝(Hyperparameter Tuning) 또는 파인튜닝(Fine-Tuning)이라 한다.</p>
<p>2 . 전이학습 Transfer Learning</p>
<p>모델이 학습 데이터에는 잘 맞지만, 새로운 데이터(테스트 데이터)에서는 성능이 저하되는 경우를 과적합이라 한다.</p>
<p>이를 방지하려면 다양한 데이터에 대해 잘 작동하는 일반화 능력이 필요하다.</p>
<p>딥러닝에서는 이러한 일반화를 위해 이미 대규모 데이터(예: 기사, 위키피디아 등)로 학습된 사전 학습 모델(Pre-trained Model)을 기반으로 하는 전이학습(Transfer Learning)이 활용된다.</p>
<p>전이학습은 기존 지식을 새로운 도메인에 적용하는 과정이며, 특정 분야의 데이터로 추가 학습하여 세부 조정을 수행하는 단계를 파인튜닝이라 한다.</p>
<p>결국, SVM에서의 (C) 조정과 같이 전이학습 및 파인튜닝 역시 “기존 모델의 일반화 능력을 유지하면서 특정 목적에 맞게 조정하는 과정”이라는 공통 원리를 가진다.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_07.html</guid>
  <pubDate>Tue, 23 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>의사결정트리 실습</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_08.html</link>
  <description><![CDATA[ 




<p>의사결정트리 실습에 대해 다루고자 한다.</p>
<p>01 커널 서포트 벡터 머신 Kernel Support Vector Machine</p>
<p>1 . 제목2 %matplotlib inline import numpy as np import matplotlib.pyplot as plt</p>
<section id="랜덤-시드-설정" class="level1">
<h1>랜덤 시드 설정</h1>
<p>np.random.seed(0)</p>
</section>
<section id="xor-데이터-생성" class="level1">
<h1>XOR 데이터 생성</h1>
<p>X_xor = np.random.randn(200, 2) y_xor = np.logical_xor(X_xor[:, 0] &gt; 0, X_xor[:, 1] &gt; 0) y_xor = np.where(y_xor, 1, 0)</p>
</section>
<section id="클래스별-산점도" class="level1">
<h1>클래스별 산점도</h1>
<p>plt.scatter(X_xor[y_xor == 1, 0], X_xor[y_xor == 1, 1], c=‘b’, marker=‘o’, label=‘class 1’, s=50) plt.scatter(X_xor[y_xor == 0, 0], X_xor[y_xor == 0, 1], c=‘r’, marker=‘s’, label=‘class 0’, s=50)</p>
</section>
<section id="그래프-옵션" class="level1">
<h1>그래프 옵션</h1>
<p>plt.legend() plt.xlabel(“x1”) plt.ylabel(“x2”) plt.title(“XOR Problem”) plt.show()</p>
<p>%matplotlib inline import numpy as np import matplotlib.pyplot as plt from sklearn.svm import SVC import matplotlib as mpl</p>
</section>
<section id="xor-데이터-생성-1" class="level1">
<h1>XOR 데이터 생성</h1>
<p>np.random.seed(0) X_xor = np.random.randn(200, 2) y_xor = np.logical_xor(X_xor[:, 0] &gt; 0, X_xor[:, 1] &gt; 0) y_xor = np.where(y_xor, 1, 0)</p>
</section>
<section id="xor-plot-함수-정의" class="level1">
<h1>XOR plot 함수 정의</h1>
<p>def plot_xor_flipped(X, y, model, title, xmin=-3, xmax=3, ymin=-3, ymax=3): XX, YY = np.meshgrid( np.arange(xmin, xmax, (xmax-xmin)/100), np.arange(ymin, ymax, (ymax-ymin)/100) ) ZZ = np.reshape( model.predict(np.array([XX.ravel(), YY.ravel()]).T), XX.shape ) # 색상 반전 ZZ = 1 - ZZ</p>
<pre><code>plt.contourf(XX, YY, ZZ, alpha=0.5, cmap=mpl.cm.Paired)
plt.scatter(X[y == 1, 0], X[y == 1, 1], c='b', marker='o', label='class 1', s=50)
plt.scatter(X[y == 0, 0], X[y == 0, 1], c='r', marker='s', label='class 0', s=50)
plt.xlim(xmin, xmax)
plt.ylim(ymin, ymax)
plt.title(title)
plt.xlabel("x1")
plt.ylabel("x2")
plt.legend()</code></pre>
</section>
<section id="결정-경계-시각화" class="level1">
<h1>결정 경계 시각화</h1>
<p>svc = SVC(kernel=‘linear’) svc.fit(X_xor, y_xor) plot_xor_flipped(X_xor, y_xor, svc, “Classification Result by Linear SVC XOR”) plt.show()</p>
<p>import numpy as np from sklearn.preprocessing import FunctionTransformer</p>
</section>
<section id="기저-함수-정의" class="level1">
<h1>기저 함수 정의</h1>
<p>def basis(X): return np.vstack([X[:, 0]<strong>2, np.sqrt(2)<em>X[:, 0]</em>X[:, 1], X[:, 1]</strong>2]).T</p>
</section>
<section id="테스트용-배열-생성" class="level1">
<h1>테스트용 배열 생성</h1>
<p>x = np.arange(8).reshape(4, 2) x</p>
<p>FunctionTransformer(basis).fit_transform(x)</p>
<p>import matplotlib.pyplot as plt from sklearn.preprocessing import FunctionTransformer</p>
</section>
<section id="기저-함수-변환" class="level1">
<h1>기저 함수 변환</h1>
<p>X_xor2 = FunctionTransformer(basis).fit_transform(X_xor)</p>
</section>
<section id="변환된-특징으로-산점도" class="level1">
<h1>변환된 특징으로 산점도</h1>
<p>plt.scatter(X_xor2[y_xor == 1, 0], X_xor2[y_xor == 1, 1], c=“b”, s=50, label=“class 1”) plt.scatter(X_xor2[y_xor == 0, 0], X_xor2[y_xor == 0, 1], c=“r”, s=50, label=“class 0”) plt.legend() plt.show()</p>
<p>02 ㄷ SVM with various Kernels</p>
<p>import matplotlib.pyplot as plt from sklearn.pipeline import Pipeline from sklearn.preprocessing import FunctionTransformer from sklearn.svm import SVC</p>
</section>
<section id="한글-폰트-설정" class="level1">
<h1>— 한글 폰트 설정 —</h1>
<p>plt.rc(‘font’, family=‘Malgun Gothic’) # Windows: ‘Malgun Gothic’, Mac: ‘AppleGothic’, Linux: ‘NanumGothic’ plt.rcParams[‘axes.unicode_minus’] = False # 마이너스 기호 깨짐 방지</p>
<p>def plot_xor(X, y, model, title, xmin=-3, xmax=3, ymin=-3, ymax=3): XX, YY = np.meshgrid( np.arange(xmin, xmax, (xmax-xmin)/100), np.arange(ymin, ymax, (ymax-ymin)/100) ) ZZ = np.reshape( model.predict(np.array([XX.ravel(), YY.ravel()]).T), XX.shape )</p>
<pre><code># 색상 반전
ZZ = 1 - ZZ  

plt.contourf(XX, YY, ZZ, alpha=0.5, cmap=plt.cm.Paired)
plt.scatter(X[y == 1, 0], X[y == 1, 1], c='b', marker='o', label='class 1', s=50)
plt.scatter(X[y == 0, 0], X[y == 0, 1], c='r', marker='s', label='class 0', s=50)
plt.xlim(xmin, xmax)
plt.ylim(ymin, ymax)
plt.title(title)
plt.xlabel("x1")
plt.ylabel("x2")
plt.legend()</code></pre>
</section>
<section id="적용" class="level1">
<h1>적용</h1>
<p>plot_xor(X_xor, y_xor, basismodel, “기저함수 SVC 모형을 사용한 XOR 분류 결과”) plt.show()</p>
</section>
<section id="시그모이드-커널-svc-학습" class="level1">
<h1>시그모이드 커널 SVC 학습</h1>
<p>sigmoidsvc = SVC(kernel=“sigmoid”, gamma=2, coef0=2) sigmoidsvc.fit(X_xor, y_xor)</p>
</section>
<section id="xor-데이터-결정-경계-시각화" class="level1">
<h1>XOR 데이터 결정 경계 시각화</h1>
<p>plot_xor(X_xor, y_xor, sigmoidsvc, “Sigmoid SVC”) plt.show()</p>
<p>rbfsvc = SVC(kernel=“rbf”).fit(X_xor, y_xor) plot_xor(X_xor, y_xor, rbfsvc, “RBF SVC”) plt.show()</p>
<p>plot_xor(X_xor, y_xor, SVC(kernel=“rbf”, gamma=2). fit(X_xor, y_xor), “RBF SVC (gamma=2)”) plt.show()</p>
<p>plot_xor(X_xor, y_xor, SVC(kernel=“rbf”, gamma=50). fit(X_xor, y_xor), “RBF SVC (gamma=50)”) plt.show()</p>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_08.html</guid>
  <pubDate>Tue, 23 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>경사하강법 (Gradient Descent)</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_09.html</link>
  <description><![CDATA[ 




<p>Reporting Date: October. 01, 2025 선형대수를 통한 기계학습의 수학적 기초와 최적화 원리에 대해 다루고자 한다.</p>
<p>목차 01 지도학습의 기본원리 02 손실 함수와 최적화의 원리 03 경사하강법 04 손실 함수 최적화</p>
<p>SCRIPT https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js 01 지도학습의 기본 원리 지도학습(SL)은 인공지능 학습 방법 중 가장 기초적이면서도 널리 사용되는 형태이다.</p>
<p>지도학습에서는 입력값(input)과 그에 대응하는 정답값(output)이 모두 주어진 데이터를 바탕으로, 모델이 입력과 출력 간의 규칙을 학습한다.</p>
<p>1 . 데이터셋의 구성과 의미 지도학습에 사용되는 데이터셋(dataset)은 이미 발생한 사건이나 관측 결과를 정리한 형태로, 각 데이터 샘플은 입력 변수(독립변수)와 이에 대응하는 결과 변수(종속변수)를 포함한다.</p>
<p>즉, 데이터셋은 “입력과 출력이 모두 알려진 과거의 기록” 으로 AI 모델은 이러한 데이터로부터 입력과 출력 사이의 관계를 학습한다.</p>
<p>학습 데이터에서 도출된 관계를 일반화하여 새로운 데이터에서도 올바른 예측을 수행할 수 있는 알고리즘을 찾는 것이 핵심 목표이다.</p>
<p>모델은 학습 과정에서 단순한 암기가 아니라, 데이터에 내재된 규칙과 패턴을 포착해 새로운 상황에도 적용 가능한 일반적 모델을 만든다.</p>
<p>이를 통해 미지의 입력값에 대해서도 합리적인 예측을 수행할 수 있다.</p>
<p>2 . 데이터의 품질과 양의 중요성 정확하고 신뢰할 수 있는 모델을 얻기 위해서는 데이터셋의 양적 충족도와 질적 우수성이 필수적이다.</p>
<p>양적 요인</p>
<p>데이터 샘플의 수가 많을수록 다양한 패턴을 학습할 수 있으며, 모델이 학습 데이터에만 과도하게 적합되는 과적합 문제를 줄이는 데 도움이 된다.</p>
<p>질적 요인</p>
<p>데이터에 포함된 노이즈(noise)가 적고, 대표성 있는 다양한 사례를 포함할수록 실제 현상을 정확하게 반영할 수 있다.</p>
<p>또한, 데이터 편향(bias)을 최소화하는 것이 중요하며, 이를 통해 모델이 특정 유형의 데이터에만 편향되지 않고 일반화 능력을 유지할 수 있다.</p>
<p>결과적으로 지도학습에서 얻어지는 모델의 정확성과 신뢰성은 데이터의 양과 질, 다양성에 의해 결정된다.</p>
<p>따라서 학습 데이터셋의 설계와 전처리 과정은 모델 성능을 좌우하는 핵심 요소라 할 수 있다.</p>
<p>3 . 회귀 regression</p>
<p>지도학습의 기본 구조를 가장 단순히 보여주는 예이다.</p>
<p>회귀 문제에서는 입력값 ( x ) 와 출력값 ( y ) 가 주어질 때, 두 변수 간의 관계를 나타내는 함수적 표현을 학습한다.</p>
<p>이를 위해 모델은 먼저 임의의 가중치(weight) ( w ) 와 절편(bias) ( b ) 를 설정하고, 가설 함수(hypothesis function)를 다음과 같이 정의한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D%20=%20wx%20+%20b"></p>
<p>이 함수는 주어진 데이터를 가장 잘 설명하는, 즉 오차가 최소화되는 최적의 직선(best-fit line)을 찾는 것을 목표로 한다.</p>
<p>4 . 손실 함수와 학습의 핵심 원리 모델이 예측한 값 ()​와 실제 값 (y)의 차이를 오차(error)라고 하며, 모든 데이터의 오차를 합산 또는 평균하여 얻은 값을 손실(loss) 또는 비용 함수(cost function)라고 한다.</p>
<p>손실 함수는 모델이 얼마나 부정확한지를 수치적으로 평가하는 척도이며, 이 값을 최소화하는 것이 곧 학습의 핵심 목표이다.</p>
<p>가장 일반적인 예로, 평균제곱오차(MSE)는 다음과 같이 표현된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?L%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D(y_i%20-%20%5Chat%7By%7D_i)%5E2"></p>
<p>모델은 학습 과정에서 이 손실 함수를 최소화하도록 가중치 ( w ) 와 절편 ( b ) 를 반복적으로 조정한다. 이 과정은 경사하강법과 같은 최적화 알고리즘을 통해 이루어진다.</p>
<p>02 손실 함수와 최적화의 원리 모델 학습의 본질은 손실(loss)을 최소화하는 방향으로 파라미터(parameter)를 조정하는 과정이다.</p>
<p>손실 함수는 모델의 예측값과 실제값 간의 차이를 수치적으로 평가하는 지표로, 학습의 목표는 이 차이를 가능한 한 작게 만드는 것이다.</p>
<p>1 . 손실 함수 Loss Function</p>
<p>모델의 예측 결과가 실제 데이터와 얼마나 다른지를 측정한다. 이 함수를 계산하는 방식에는 여러 가지가 있으며, 문제의 특성에 따라 적절한 형태가 선택된다.</p>
<p>① L1 손실 (Mean Absolute Error, MAE)</p>
<p>각 오차의 절댓값을 더한 뒤 평균한 손실이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?L_%7B1%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%7Cy_i%20-%20%5Chat%7By%7D_i%7C"></p>
<p>특징: 이상치(outlier)에 덜 민감하며, 오차 분포가 고르게 반영된다. ② L2 손실 (Mean Squared Error, MSE)</p>
<p>오차를 제곱한 뒤 평균하는 방식이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?L_%7B2%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20(y_i%20-%20%5Chat%7By%7D_i)%5E2"></p>
<p>특징: 제곱 연산으로 인해 큰 오차(이상치)에 더 큰 패널티를 부여한다. 응용: 회귀 문제에서 가장 널리 사용되는 손실 함수다.</p>
<p>L2 손실의 특성과 이상치 민감성 L2 손실은 예측값과 실제값의 오차를 제곱하여 평균한 값으로 계산된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?L2%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum%20(y_i%20-%20%5Chat%7By_i%7D)%5E2"></p>
<p>이 제곱 연산으로 인해 오차가 커질수록 손실값이 기하급수적으로 증가한다.</p>
<p>따라서 데이터에 이상치가 존재할 경우, 그 점의 오차가 전체 손실값에 매우 큰 영향을 미친다.</p>
<p>이로 인해 L2 손실을 사용하는 모델은 이상치에 민감하게 반응하며, 모델이 이상치 방향으로 왜곡될 가능성이 있다.</p>
<p>반면 L1 손실은 오차의 절댓값을 사용하므로 오차가 커지더라도 선형적으로 증가한다. 따라서 L1 손실은 이상치의 영향을 상대적으로 덜 받으며 강건(robust) 하다고 평가된다.</p>
<p>이러한 특성 때문에, L2 손실은 일반적인 데이터에서 더 매끄럽고 안정적인 최적화를 제공하지만, 이상치가 많은 데이터에는 부적합할 수 있다.</p>
<p>반대로 L1 손실은 이상치가 많은 환경에서 더 신뢰할 수 있는 결과를 제공한다.</p>
<p>[요약 비교] 구분 L1 손실 (MAE) L2 손실 (MSE) 계산 방식 오차의 절댓값 오차의 제곱 이상치 영향 작음 (강건함) 큼 (민감함) 손실 증가 특성 선형적 제곱적 (기하급수적) 주 용도 이상치가 많은 데이터 일반적인 데이터 대표적 활용 로버스트 회귀 선형회귀 MSE의 제곱근을 취하면 RMSE (Root Mean Squared Error)가 되며, 이는 실제 데이터의 단위와 동일한 척도를 제공하므로 결과 해석이 직관적이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?RMSE%20=%20%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20(y_i%20-%20%5Chat%7By%7D_i)%5E2%7D">​</p>
<p>2 . 손실 함수의 일반화 — Lₚ 노름 손실 함수는 일반적으로 Lₚ 노름(norm)의 형태로 확장할 수 있다. 이는 오차의 절댓값을 (p) 제곱하여 평균한 뒤, 다시 (p) 제곱근을 취하는 방식이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?L_p%20=%20%5Cleft(%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%7Cy_i%20-%20%5Chat%7By%7D_i%7C%5Ep%20%5Cright)%5E%7B1/p%7D"></p>
<p>(p = 1) 일 때 L1 손실, (p = 2) 일 때 L2 손실로 귀결된다. (p) 값이 커질수록 큰 오차에 더 민감해진다.</p>
<p>3 . 비선형 회귀와 손실 함수의 구분 다항 회귀(Polynomial Regression)는 손실 함수의 형태를 바꾸는 것이 아니다.</p>
<p>입력 변수 (x) 에 대해 (x^2, x^3, ) 와 같은 고차항(feature)을 추가하여 모델의 가설 함수(hypothesis)를 비선형으로 확장함으로써 데이터의 비선형적 관계를 표현한다.</p>
<p>즉, 손실 함수는 회귀 문제에서 그대로 사용되며(L1, L2 등), 모델이 복잡해짐에 따라 가설 함수가 비선형 구조를 가지게 되는 것이다.</p>
<p>4 . 교차 엔트로피 손실 함수 Cross-Entropy Loss</p>
<p>① 이진(Binary)</p>
<p>이진 분류에서의 손실 함수는 다음과 같다.</p>
<p><img src="https://latex.codecogs.com/png.latex?J(w,b)=-%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi=1%7D%5E%7Bm%7D%5Cbig%5B%5C,y%5E%7B(i)%7D%5Clog%20H(x%5E%7B(i)%7D)%20+%20(1-y%5E%7B(i)%7D)%5Clog(1-H(x%5E%7B(i)%7D))%5C,%5Cbig%5D"></p>
<p>실제값과 예측이 일치하면 손실이 0에 가깝고, 다르면 손실이 급격히 커진다.</p>
<p>로그 형태이므로 확률이 극단적으로 틀릴수록 패널티가 커져 모델을 강하게 교정한다.</p>
<p>② 범주형 또는 다중 클래스</p>
<p>Categorical &amp; Multiclass</p>
<p>회귀 문제에서 손실이 오차의 크기를 기반으로 계산되는 반면,</p>
<p>분류(classification) 문제에서는 모델의 출력 확률 분포와 실제 정답 확률 분포 간의 차이를 평가한다.</p>
<p>이때 주로 사용되는 것이 교차 엔트로피 손실이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?L%20=%20-%5Csum_%7Bi=1%7D%5E%7Bn%7D%20y_i%20%5Clog(%5Chat%7By%7D_i)"></p>
<p>의미: 모델의 예측 확률이 실제 정답에 가까울수록 손실 값이 작아진다. 특징: 다중 클래스 분류 문제에 특히 유용하다.</p>
<p>5 . 최적화 Optimization</p>
<p>손실 함수가 정의되면, 모델의 목표는 이 손실 함수를 최소화하는 파라미터(가중치 (w), 절편 (b))를 찾는 것이다.</p>
<p>이처럼 손실을 최소로 만드는 방향으로 파라미터를 반복적으로 조정하는 과정을 최적화라 하며, 손실이 가장 작은 지점에서의 파라미터 조합을 최적해(optimal solution)라고 한다.</p>
<p>손실 함수를 시각화하면, 가로축은 파라미터 w, 세로축은 손실값으로 나타나는 곡선 형태(일반적으로 2차 함수형태)로 표현된다.</p>
<p>이때 모델이 손실을 줄이기 위해 이동해야 하는 방향을 수학적으로 계산하는 핵심 도구가 기울기(gradient)이다.</p>
<p>기울기는 특정 지점에서의 손실 함수의 변화율로, 손실이 증가하거나 감소하는 방향성과 속도를 알려준다.</p>
<p>따라서 최적화 과정은 기울기를 이용해 손실이 감소하는 방향으로 파라미터를 이동시키는 과정이라 할 수 있다.</p>
<p>가장 널리 사용되는 최적화 방법은 경사하강법(Gradient Descent)이다.</p>
<p>경사하강법은 손실 함수의 기울기를 계산한 뒤, 그 반대 방향(손실이 줄어드는 방향)으로 파라미터를 반복적으로 갱신한다.</p>
<p>이를 수식으로 표현하면 다음과 같다.</p>
<p><img src="https://latex.codecogs.com/png.latex?w%20:=%20w%20-%20%5Ceta%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20w%7D,%20%5Cquad%20b%20:=%20b%20-%20%5Ceta%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20b%7D"></p>
<p>(:) 학습률(learning rate)로, 한 번의 갱신에서 얼마나 크게 이동할지를 결정한다. 학습률이 너무 크면 최적점을 지나쳐 발산할 수 있고, 너무 작으면 수렴 속도가 느려질 수 있다.</p>
<p>따라서 적절한 학습률 설정은 최적화의 안정성과 효율성에 매우 중요하다.</p>
<p>6 . 손실 최소화 &amp; 우도 최대화의 관계 손실 함수는 일반적으로 최소화(minimization)의 관점에서 정의되지만,</p>
<p>확률적 접근에서는 반대로 우도(likelihood)를 최대화(maximization)하는 방식으로 동일한 목표를 달성할 수 있다.</p>
<p>예: 최대우도추정(MLE): 주어진 데이터가 특정 파라미터 하에서 관측될 확률(우도)을 가장 크게 만드는 값을 찾는다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmax_%7B%5Ctheta%7D%20%5Cmathcal%7BL%7D(%5Ctheta)%20%5Cquad%20%5CLeftrightarrow%20%5Cquad%20%5Cmin_%7B%5Ctheta%7D%20%5B-%5Clog%20%5Cmathcal%7BL%7D(%5Ctheta)%5D"></p>
<p>즉, 로그 함수의 단조 증가 성질에 따라 우도를 최대화하는 문제는 음의 로그 우도를 최소화하는 문제와 동일하다.</p>
<p>따라서 실제 학습 과정에서는 (-())를 손실 함수로 정의하고 이를 최소화한다.</p>
<p>지도학습과 대비되는 예시: 강화학습 지도학습과 달리 강화학습(RL)에서는 모델이 환경과 상호작용하며 얻는 보상(reward)을 최대화하는 방향으로 정책(policy)을 학습한다.</p>
<p>즉, 손실 함수가 최소화의 대상이라면, 보상 함수는 그 반대 방향인 최대화의 대상이다.</p>
<p>이처럼 AI의 학습 목표는 ’최소화’와 ’최대화’의 두 관점으로 표현될 수 있으며, 결국 이는 모두 가장 합리적(최적의) 매개변수 조합을 찾는 문제로 귀결된다.</p>
<p>03 경사 하강법 Gradient Descent, GD</p>
<p>기계학습에서 손실 함수를 최소화하여 모델의 파라미터 ((w, b))를 최적화하는 가장 기본적이면서 핵심적인 학습 알고리즘(Learning Algorithm)이다.</p>
<p>1 . 기본 원리 모델 파라미터 (w)를 임의의 초기값으로 설정한다. 현재 파라미터에서 손실 함수 (L(w))를 미분하여 기울기를 계산한다. 손실이 감소하는 기울기의 반대 방향으로 (w)를 반복적으로 갱신(update)함으로써 최적점을 찾아간다.</p>
<p>① 1차원(고등학교 수준) — 순간변화율(접선 기울기)</p>
<p>함수 (f(x))에서 한 점 (x)의 순간변화율(도함수)는 다음과 같다.</p>
<p><img src="https://latex.codecogs.com/png.latex?f'(x)=%5Clim_%7Bh%5Cto0%7D%5Cfrac%7Bf(x+h)-f(x)%7D%7Bh%7D"></p>
<p>이 값은 (x) 근처에서 함수의 선형 근사(접선)를 제공한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?f(x+h)%5Capprox%20f(x)+f'(x)%5Ccdot%20h"></p>
<p>즉, 접선은 ’그 점 근처에서 함수가 어떻게 움직이는지 선형적으로 근사한 직선’이다.</p>
<p>② 다변수(머신러닝의 손실 함수) — 기울기(gradient)</p>
<p>머신러닝에서는 (x) 하나가 아니라 여러 파라미터가 벡터 형태로 계산된다. 변수 벡터 (w^n)에 대한 손실 (L(w))의 기울기는 모든 편미분을 모은 모은 벡터로 정의된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cnabla%20L(w)%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20w_1%7D(w)%5C%5C%5B2mm%5D%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20w_2%7D(w)%5C%5C%5B1mm%5D%20%5Cvdots%5C%5C%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20w_n%7D(w)%20%5Cend%7Bbmatrix%7D."></p>
<p>이 벡터은 각 좌표에서의 순간변화율을 모아 놓은 것이며, 함수가 가장 빠르게 증가하는 방향을 가리킨다.</p>
<p>① 기울기와 이동 방향</p>
<p>음수 기울기일 때 (L(w) &lt; 0) <img src="https://latex.codecogs.com/png.latex?w%20%5Cleftarrow%20w%20-%20(-%7C%5Cnabla%20L(w)%7C)%20=%20w%20+%20%7C%5Cnabla%20L(w)%7C"></p>
<p>→ (w)의 값이 증가하여 기울기가 0이 되는 방향으로 이동한다.</p>
<p>양수 기울기일 때 (L(w) &gt; 0) <img src="https://latex.codecogs.com/png.latex?w%20%5Cleftarrow%20w%20-%20%7C%5Cnabla%20L(w)%7C%20=%20w%20-%20%7C%5Cnabla%20L(w)%7C"></p>
<p>→ (w)의 값이 감소하여 기울기가 0이 되는 방향으로 이동한다.</p>
<p>즉, 기울기의 부호와 상관없이 항상 최소점으로 이동한다.</p>
<p>② 학습률 ()의 역할</p>
<p>학습률은 한 번 이동할 때의 크기를 조절한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?w%20%5Cleftarrow%20w%20-%20%5Ceta%20%5Cnabla%20L(w)"></p>
<p>()가 작으면 한 걸음씩 천천히 이동 → 안정적 수렴 ()가 크면 한 번에 크게 이동 → 빠른 수렴 가능하지만, 최적점을 지나치거나 발산 위험 존재</p>
<p>그래프 상에서 (w)를 점으로 보고, 접선 기울기가 0이 될 때까지 경사를 따라 한 걸음씩 내려가는 것으로 비유할 수 있다.</p>
<p><img src="https://latex.codecogs.com/png.latex?w_t%20=%20w_%7Bt-1%7D%20-%20%5Ceta%20%5Cnabla%20L(w_%7Bt-1%7D)"></p>
<p>(w_t:)​ t 번째 반복에서의 파라미터 (L(w_{t-1}):) 손실 함수의 기울기 (:) 학습률(learning rate), 한 번에 이동하는 크기 학습률은 알고리즘 성능에 중요한 영향을 미친다.</p>
<p>너무 크면: 최적해를 지나치거나 발산할 수 있다. 너무 작으면: 수렴 속도가 느려 학습 시간이 길어진다.</p>
<p>Mastering Gradient Descent: Optimizing Neural Networks with Precision(Omkar Hankare)</p>
<p>2 . 하이퍼파라미터 hyperparameter</p>
<p>학습률과 같이 학습 과정에서 사용자가 설정하는 조정 가능한 값들.</p>
<p>하이퍼파라미터의 적절한 선택은 학습 효율과 모델 성능에 큰 영향을 준다. 이를 최적화하는 과정을 하이퍼파라미터 튜닝(tuning)이라고 한다.</p>
<p>경사하강법의 효율과 안정성을 높이기 위해 다양한 전략이 사용된다.</p>
<p>① 학습률 스케줄링(learning rate scheduling) : 학습이 진행됨에 따라 학습률을 점진적으로 조정하여 안정적 수렴 유도</p>
<p>② 모멘텀(Momentum) : 이전 기울기의 일부를 반영하여 진동을 줄이고 수렴 속도를 향상</p>
<p>③ 적응적 학습률(Adam, RMSProp 등) : 각 파라미터별로 학습률을 자동 조정</p>
<p>④ 배치 크기(batch size) 및 반복 횟수(epochs) : 한 번에 처리하는 데이터 양과 학습 반복 횟수를 조절</p>
<p>이러한 전략들을 적절히 활용하면, 다양한 데이터셋과 모델 구조에서도 손실 함수를 보다 효과적이고 안정적으로 최소화할 수 있다.</p>
<p>Tensorflow — Neural Network Playground</p>
<p>Tinker with a real neural network right here in your browser.</p>
<p>playground.tensorflow.org</p>
<p>3 . 볼록 함수 convex function</p>
<p>아래로 볼록인 손실 함수에서 특히 안정적이고 효율적이다.</p>
<p>아래로 볼록한 함수에서는 국소 최소값(local minimum)이 곧 전역 최소값(global minimum)이므로, 경사하강법이 수렴하면 최적해를 확보할 수 있다.</p>
<p>반면, 비볼록(non-convex) 함수나 위로 볼록한 함수에서는 여러 국소 최소값, 안장점(saddle point)이 존재할 수 있어, 경사하강법이 항상 전역 최적해에 도달한다고 보장할 수 없다.</p>
<p>따라서 최적화를 설계할 때는 가능한 아래로 볼록한 형태를 사용하는 것이 안정적이다.</p>
<p>4 . 경사하강법의 직관적 이해 경사하강법은 손실 함수의 순간 변화율(기울기)을 이용하여 파라미터를 작은 단위로 조정하고, 손실이 낮은 방향으로 이동시킨다.</p>
<p>비유하자면, 물이 자연스럽게 낮은 곳으로 흐르는 과정과 유사하다. 손실이 높은 지역에서 낮은 지역으로 점진적으로 이동하며, 손실 함수가 최소인 지점에 도달하는 원리다.</p>
<p>04 손실 함수 최적화 Loss Function Optimization</p>
<p>기계학습의 대부분의 모델은 대규모 데이터를 효율적으로 처리하기 위해 벡터(vector)와 행렬(matrix) 형태로 데이터를 표현한다.</p>
<p>이러한 수학적 구조화는 계산 효율을 극대화하며, 모델 학습 과정을 선형대수적 관점에서 체계적으로 해석할 수 있게 한다.</p>
<p>1 . 선형 모델의 행렬 표현 단일 입력값 (x)를 사용하는 경우, 가설 함수는 다음과 같이 정의된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D%20=%20w%20x%20+%20b"></p>
<p>(w)는 가중치(weight) (b)는 절편(bias) 그러나 실제 데이터는 다수의 관측치와 다차원 특성(feature)을 포함하므로, 입력 데이터를 행렬 형태로 확장한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BX%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D"></p>
<p>(m:) 데이터 포인트의 개수 (샘플 수) (n:) 각 데이터의 특성(feature) 수 이에 대응하는 가중치 벡터는</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%201%7D"></p>
<p>로 정의되며, 전체 예측값은 다음과 같이 행렬 연산으로 계산된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cmathbf%7By%7D%7D%20=%20%5Cmathbf%7BX%7D%5Cmathbf%7Bw%7D%20+%20%5Cmathbf%7Bb%7D"></p>
<p>이 표현은 모든 데이터 샘플에 대해 한 번의 행렬 연산으로 예측을 수행할 수 있어, 계산 효율성과 모델 학습 속도를 크게 향상시킨다.</p>
<p>2 . 손실 함수의 수학적 정의 손실 함수는 예측값과 실제값 간의 차이를 수치적으로 표현한다. 선형 회귀에서 가장 일반적으로 사용되는 손실 함수는 평균제곱오차(MSE)이며, 다음과 같이 정의된다.</p>
<p><img src="https://latex.codecogs.com/png.latex?L(%5Cmathbf%7Bw%7D,%20b)%20=%20%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20(%5Chat%7By%7D_i%20-%20y_i)%5E2"></p>
<p>혹은 벡터 연산 형태로 나타내면,</p>
<p><img src="https://latex.codecogs.com/png.latex?L(%5Cmathbf%7Bw%7D)%20=%20%5Cfrac%7B1%7D%7Bm%7D%20(%5Cmathbf%7BX%7D%5Cmathbf%7Bw%7D%20-%20%5Cmathbf%7By%7D)%5E%5Ctop%20(%5Cmathbf%7BX%7D%5Cmathbf%7Bw%7D%20-%20%5Cmathbf%7By%7D)"></p>
<p>이 손실 함수를 최소화하는 방향으로 파라미터 와 (b)를 조정하는 것이 모델 학습의 핵심이다.</p>
<p>3 . 행렬 연산 행렬 기반의 모델 학습에서는 다양한 연산이 사용된다. 대표적인 세 가지 연산은 다음과 같다.</p>
<p>① 엘리먼트 와이즈 프로덕트 (Element-wise Product)</p>
<p>각 행렬의 동일 위치 원소끼리 곱하는 연산으로, Hadamard product라 불리며 기호 ()로 나타낸다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20%5Codot%20%5Cmathbf%7BB%7D%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B11%7Db_%7B11%7D%20&amp;%20a_%7B12%7Db_%7B12%7D%20%5C%5C%20a_%7B21%7Db_%7B21%7D%20&amp;%20a_%7B22%7Db_%7B22%7D%20%5Cend%7Bbmatrix%7D"></p>
<p>② 내적 (Dot Product)</p>
<p>두 벡터의 대응 원소를 곱해 합산한 값으로, 스칼라를 생성한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D%20%5Ccdot%20%5Cmathbf%7Bv%7D%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D"></p>
<p>③ 외적 (Cross Product)</p>
<p>3차원 벡터 (, ^3)에 대해 두 벡터에 모두 수직인 벡터를 산출하는 연산이다.</p>
<p>4 . 스케일링과 정규화의 필요성 데이터의 단위나 값의 범위가 서로 다른 경우, 특정 특성이 모델 학습 과정에서 불균형하게 영향을 미칠 수 있다. 이러한 문제를 방지하기 위해 스케일링(scaling) 또는 정규화(normalization)를 적용한다.</p>
<p>① Min–Max 스케일링</p>
<p>각 특성 xjx_jxj​을 0과 1 사이의 값으로 선형 변환한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?x_j%5E%7B(%5Ctext%7Bscaled%7D)%7D%20=%20%5Cfrac%7Bx_j%20-%20%5Cmin(x_j)%7D%7B%5Cmax(x_j)%20-%20%5Cmin(x_j)%7D"></p>
<p>② Z-점수 정규화(Standardization)</p>
<p>평균과 표준편차를 이용하여 데이터를 정규분포 형태로 변환한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?x_j%5E%7B(%5Ctext%7Bnorm%7D)%7D%20=%20%5Cfrac%7Bx_j%20-%20%5Cmu_j%7D%7B%5Csigma_j%7D"></p>
<p>이러한 변환을 수행하면 손실 함수의 등고선(contour)이 타원형에서 원형으로 변화하여, 모든 특성이 최적화 과정에서 동일한 비중으로 반영된다.</p>
<p>그 결과, 경사하강법(Gradient Descent) 등 최적화 알고리즘의 수렴 속도와 안정성이 향상된다.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_09.html</guid>
  <pubDate>Tue, 23 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>머신러닝: R2D3</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_03.html</link>
  <description><![CDATA[ 




<p>모델 학습과 R2D3 를 활용한 실무 적용 방법에 대해 다루고자 한다.</p>
<p>01 신경망 Neural Network, NN</p>
<p>현대 딥러닝 모델의 대부분은 신경망 구조에서 발전하였으며, 데이터의 특성(공간적·순차적 구조)과 문제 유형에 따라 다양한 형태로 변형되어 사용된다.</p>
<p>1 . 인공 신경망 Artificial Neural Network</p>
<p>인공 신경망은 딥러닝의 기본 구조로, 입력층(Input layer), 은닉층(Hidden layer), 출력층(Output layer)으로 구성된다.</p>
<p>각 뉴런은 입력값에 가중치(weight)와 편향(bias)을 적용한 뒤, 활성화 함수(activation function)를 통해 비선형 출력을 생성한다.</p>
<p>딥러닝(DL)은 이러한 인공 신경망을 다층화(심층화)하여 복잡한 패턴과 비선형 관계를 학습할 수 있도록 확장한 구조이다.</p>
<p>2 . 합성곱 신경망 Convolutional Neural Network, CNN</p>
<p>이미지와 같이 격자형 구조를 가진 데이터의 공간적 패턴(spatial pattern)을 학습하는 데 특화되어 있다.</p>
<p>합성곱(convolution) 연산을 통해 국소적인 특징(local feature)을 추출하며, 계층이 깊어질수록 점차 추상적인 특징을 학습한다.</p>
<p>최근에는 Vision Transformer(ViT) 등과 같은 트랜스포머 기반 모델이 이미지 분석에도 적용되며, CNN과 함께 시각 분야의 핵심 구조로 활용되고 있다.</p>
<p>3 . 순환 신경망 Recurrent Neural Network, RNN</p>
<p>시간적 또는 순차적 데이터를 처리하기 위해 설계된 구조로, 이전 단계의 은닉 상태(hidden state)를 현재 입력과 함께 사용하여 시점 간 의존성(temporal dependency)을 학습한다.</p>
<p>다만, 기본 RNN은 긴 시퀀스 처리 시 기울기 소실(vanishing gradient) 문제가 발생할 수 있다.</p>
<p>이를 개선하기 위해 LSTM(Long Short-Term Memory), GRU(Gated Recurrent Unit)와 같은 변형 구조가 널리 사용된다.</p>
<p>4 . 트랜스포머 Transformer</p>
<p>순환 구조 없이 시퀀스 데이터를 병렬적으로 처리할 수 있도록 고안된 모델로, 자기어텐션(Self-Attention) 메커니즘을 통해 입력 간 상관관계를 학습한다.</p>
<p>이 구조는 RNN보다 장거리 의존성(Long-range dependency)을 효과적으로 포착하며, 자연어처리(NLP)를 넘어 이미지, 음성, 멀티모달 학습 등 다양한 분야로 확장되고 있다.</p>
<p>요약하자면,</p>
<p>CNN은 “공간적 패턴 추출”에, RNN은 “순차적 패턴 학습”에, Transformer는 “병렬적·전역적 패턴 학습”에 강점을 지닌다. 이들은 모두 “신경망”이라는 공통 기반 위에서 발전해 온 핵심적인 딥러닝 구조이다.</p>
<p>02 사이킷런 이러한 신경망 기반 접근 외에도, 통계적 학습 이론을 바탕으로 한 전통적 머신러닝 기법이 존재한다.</p>
<p>그 대표적인 라이브러리가 Scikit-learn이며, 파이썬 기반의 대표적인 머신러닝 라이브러리로 회귀, 분류, 클러스터링, 차원 축소 등 다양한 알고리즘을 일관된 인터페이스로 제공한다.</p>
<p>이 라이브러리는 심층 신경망 구조인 CNN, RNN 등을 기본적으로 포함하지 않으며, 이러한 구조는 TensorFlow, Keras, PyTorch 와 같은 딥러닝 프레임워크에서 주로 구현된다.</p>
<p>이 알고리즘은 본질적으로 데이터의 구역을 단순 분할이 아닌, 입력 변수(feature), 목표 변수(target) 간의 관계를 함수적 형태로 모델링하는 방식이다.</p>
<p>일반적으로 데이터는 ” 행(sample) × 열(feature) ” 형태의 구조를 가지며, 각 행은 개별 관측치를, 각 열은 설명 변수를 나타낸다.</p>
<p>모델은 이러한 특징들을 바탕으로 목표 변수를 예측하는 함수를 학습한다.</p>
<p>예: 아파트 가격 예측 문제에서 면적, 교통, 교육 환경 등 다양한 요인을 특징으로 사용 시 데이터는 고차원 공간에 분포하게 된다.</p>
<p>이때 데이터가 3차원에서 도넛 형태와 같이 복잡한 분포를 보일 수 있으며, 단순한 선형 경계로는 구분하기 어려운 경우가 많다.</p>
<p>이러한 상황에서는 PCA, t-SNE, UMAP 과 같은 차원 축소 기법을 활용하여 고차원 데이터를 저차원 공간으로 투영함으로써 데이터의 패턴과 구조를 보다 명확하게 시각화할 수 있다.</p>
<p>03 고도와 주택 가격 R2D3의 시각적 기계학습 입문 글에서는 샌프란시스코와 맨해튼의 주택 가격 데이터를 활용하여, 머신러닝 모델이 입력(feature)과 목표(target) 간 관계를 학습하는 과정을 시각적으로 설명한다.</p>
<p>A visual introduction to machine learning</p>
<p>What is machine learning? See how it works with our animated data visualization.</p>
<p>www.r2d3.us</p>
<p>샌프란시스코는 언덕 지형이 많아 고도(elevation)가 주택 가격에 영향을 미치는 중요한 요인이 된다.</p>
<p>반면 맨해튼은 대체로 평지 구조이므로 고도 요인의 영향이 미미하거나 다르게 나타난다.</p>
<p>이처럼 고도는 미국 부동산 시장에서 elevation 이라는 변수로 다뤄지며, 조망(view), 프라이버시, 도시 스카이라인 등과 함께 가격 형성에 작용할 수 있다.</p>
<p>한국의 경우, 언덕 위 아파트는 접근성 저하, 급경사 도로, 기반 시설 확충 비용 등의 이유로 가격이 낮게 평가되는 경향이 있다.</p>
<p>반대로 바닷가 조망이 있는 주택은 오히려 낮은 가격을 받는 경우도 있다. 이는 고도 자체보다 조망성, 접근성, 지형 조건 등 복합 요인들이 작용한 결과라 볼 수 있다.</p>
<p>이러한 차이는 머신러닝에서 하나의 입력 변수(feature)가 지역적·사회적 맥락에 따라 서로 다른 패턴을 학습하게 되는 과정을 잘 보여준다.</p>
<p>입력 변수(feature)를 2D 평면에 점으로 시각화하고, 이 점들을 기준으로 분류 경계(decision boundary)를 학습하는 과정을 설명한다.</p>
<p>이와 유사하게, 부동산 시장에서 고도(elevation)를 하나의 특징(feature)로 입력하면, 모델은 고도와 가격 패턴 사이의 관계를 학습하여 경계 또는 함수 형태로 변환할 수 있다.</p>
<p>예를 들어, 한국에서는 고도 증가가 가격 하락으로 이어지는 함수적 경향이, 미국 일부 지역에서는 고도 증가가 가격 상승과 연결된 함수적 경향이 학습될 수 있다.</p>
<p>즉, 고도(elevation)는 부동산 가격 모델링에서 하나의 중요한 입력 변수이며, 지역별 맥락과 다른 특징들과의 상호작용을 고려해야 한다.</p>
<p>이러한 지역별 차이를 반영하여, 머신러닝 모델은 학습 데이터 기반으로 최적의 예측 함수를 찾아내게 된다.</p>
<p>전체 데이터를 학습용(train), 검증용(validation), 테스트용(test) 으로 분할한다.</p>
<p>예를 들어, 전체의 70 %를 학습용, 30 %를 테스트용으로 나눈 뒤, 학습용 중 일부(예: 10–20 %)를 검증용으로 재분할한다.</p>
<p>학습 중에 매 epoch마다 학습 정확도와 검증 정확도를 기록하여 학습 상태를 모니터링한다. 검증 정확도가 점진적으로 상승하면 정상적인 학습 경향이다.</p>
<p>하지만 검증 정확도가 자주 들쭉날쭉하거나, 학습 정확도만 계속 상승하고 검증 정확도는 정체되면 과적합 또는 학습 불안정성을 의심해야 한다. 이때 하이퍼파라미터 조정, 정규화(regularization) 적용, 또는 데이터 분할 재설계 등을 고려한다.</p>
<p>R2D3 예제에 따르면,</p>
<p>학습 정확도(training accuracy): 100% 검증 정확도(validation accuracy): 89.7% 구체적으로,</p>
<p>뉴욕 주택: 112개 중 100개 정확 분류 샌프란시스코 주택: 130개 중 117개 정확 분류 이는 모델이 학습 데이터에 과적합되어 있으며, 현실적 적용에는 제한적임을 의미한다. 실무 적용 기준으로는 최소 95% 이상의 검증 정확도가 요구되므로, 현 시점에서의 모델 적용은 신중을 요한다.</p>
<p>04 결정 트리 학습과 과적합 관리</p>
<p>1 . 단일 변수 기반 분류의 한계 의사결정트리는 각 노드에서 조건문(if-then)을 통해 데이터를 두 그룹으로 분할하며, 경계를 설정하여 분류를 수행한다.</p>
<p>그러나 단일 변수(예: elevation)만으로는 고도와 주택 가격 간의 비선형적 관계, 지역별 특성 등을 충분히 반영할 수 없어 데이터 간 명확한 구분이 어렵다.</p>
<p>R2D3 시각화 예시에서도 나타나듯, 고도 하나만으로 주택 가격 범주를 정확히 분류하기 어려우므로, 면적, 교통 접근성, 조망 등 여러 변수(feature)를 고려한 다변량 분할이 필요하다.</p>
<p>2 . 최적 분할과 분할 기준 트리는 각 노드에서 모든 후보 특성(feature)과 임계값(threshold)을 조합하여 가능한 분할(split candidates)을 탐색한다.</p>
<p>각 후보 분할은 엔트로피(entropy), 정보 이득(information gain), 지니 불순도(Gini impurity) 등 불순도 지표를 통해 평가되며, 가장 데이터가 균질하게 나뉘는 최적 분할(best split)이 선택된다.</p>
<p>이 과정을 반복하면, 학습 데이터가 점차 균질한 소그룹으로 세분화되어 목표 변수(target)에 대한 예측 성능이 향상된다.</p>
<p>3 . 과적합의 발생과 영향 트리 깊이가 증가하면 모델이 학습 데이터에 과도하게 적합(overfit)될 수 있다.</p>
<p>학습 데이터에서는 높은 정확도를 나타내지만, 테스트 데이터에서는 일반화 성능이 저하되는 과적합 현상이 발생한다.</p>
<p>R2D3 예시에서는 단일 변수 분할을 반복하여 분류 경계를 지나치게 세분화함으로써 일부 데이터 포인트가 잘못 분류되는 사례가 확인된다.</p>
<p>이러한 과적합은 모델이 학습 데이터의 불필요한 변동과 노이즈까지 학습하게 만들어, 실무에서의 모델 신뢰도를 떨어뜨리는 부작용을 초래한다.</p>
<p>4 . 과적합 방지 전략 과적합을 방지하기 위해서는 여러 전략을 병행할 수 있다.</p>
<p>먼저, 모델 제약을 통해 트리의 최대 깊이(max depth)나 최소 샘플 수(min samples split)와 같은 파라미터를 제한하면, 지나치게 세분화되는 것을 방지할 수 있다.</p>
<p>또한, 가지치기(pruning)를 통해 불필요하게 세분화된 분할을 사후적으로 제거하며 모델 단순화 및 일반화 성능을 향상할 수 있다.</p>
<p>마지막으로, 교차검증(cross-validation)을 활용하여 학습과 검증을 반복하면, 모델이 특정 데이터셋에만 과적합되는 것을 방지하고 안정적인 성능을 확보할 수 있다.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_03.html</guid>
  <pubDate>Tue, 16 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>머신러닝: 실무 사례</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_04.html</link>
  <description><![CDATA[ 




<p>반도체 HBM 공정과 스마트 CCTV를 중심으로 머신러닝의 실제 활용에 대해 다루고자 한다.</p>
<p>01 제조 공정 혁신</p>
<p>1 . 과거 제조업 현장 오랜 기간 아날로그 방식의 공정 관리에 의존해 왔으나 글로벌 경쟁 심화와 공정 복잡성 증가로 인해 단순 수작업이나 경험 중심의 운영만으로는 품질과 효율성을 확보하기 어려워졌다.</p>
<p>이에 따라 디지털 전환(DX) 과 인공지능 전환(AX) 은 제조업 경쟁력 강화를 위한 핵심 과제로 부상하였다.</p>
<p>DX와 AI 트랜스포메이션의 개념을 정리하고, 실제 사례로서 반도체 HBM 적층 공정의 기술적 차이를 분석한다.</p>
<p>2 . Digital Transformation (DX) 기존의 아날로그 및 비체계적 공정을 시스템화된 디지털 관리 체계와 데이터베이스 기반 운영으로 전환하는 과정이다.</p>
<p>공정, 설비, 품질 관리 정보를 실시간으로 수집·저장 운영 데이터의 추적성(traceability) 확보 표준화된 관리 체계 구축을 통해 오류 및 낭비 최소화 제조업에서 DX는 스마트 팩토리로의 진입을 위한 기초 단계라 할 수 있다.</p>
<p>3 . AI Transformation (AX) DX 위에 구축된 데이터 인프라는 AI 분석을 통한 고도화로 확장된다. 이것은 다음 단계들을 포함한다.</p>
<p>센서 및 IoT 장치를 통한 빅데이터 수집 실시간 데이터 시각화 및 공정 모니터링 이상치(anomaly) 탐지 및 자동 알림 데이터 기반 원인 분석 및 해결 방안 제시 공정 최적화 및 예측 유지보수 이러한 체계는 설비 수준이 낮은 공장에서도 점진적 도입이 가능하며, 데이터 기반 의사결정을 통해 전사적 품질 및 생산성 개선 효과를 제공한다.</p>
<p>4 . 사례 분석: HBM 적층 공정 고대역폭 메모리(HBM)는 여러 개의 DRAM 다이를 수직으로 적층하여 초고속 데이터 전송을 가능케 하는 핵심 기술이다. 하지만 적층 단수가 증가할수록 수율(yield) 저하가 주요 문제로 지적된다.</p>
<p>① SK하이닉스</p>
<p>MR-MUF 공정을 활용하여 적층 단수 증가에도 수율 저하를 최소화한 것으로 평가된다.</p>
<p>일부 보고에 따르면 12단 적층에서도 비교적 안정적인 수율 확보가 가능하다.</p>
<p>② 삼성전자</p>
<p>TC-NCF 기반 공정을 채택했으며, 접합 안정성 확보 및 void 제어 문제로 인해 수율 측면에서 난제를 겪고 있는 것으로 알려져 있다. 다만, 최근에는 Cu-to-Cu 본딩 등 새로운 기술을 병행 도입하고 있다.</p>
<p>공개된 산업 보고 및 전문가 분석에 따르면, “삼성은 수율이 70% 미만, SK는 상대적으로 높은 수율 확보”라는 평가가 존재하나, 이는 공식 수치가 아닌 시장 리서치 기반 추정에 가깝다.</p>
<p>‘HBM’ 골든타임 노리는 엇갈린 시선···삼전 ‘포괄적’ vs SK하닉 ‘트렌드’</p>
<p>[이뉴스투데이 김진영 기자] AI 반도체 시장이 급속도로 확대되는 가운데 고대역폭메모리(HBM)의 중요성이 커지고 있다. 삼성전자와 SK하이닉스는 모두 AI 생태계 확장을 목표로 하고 있지만 HBM을</p>
<p>www.enewstoday.co.kr</p>
<p>AI 시대의 새로운 심장: 삼성전자와 SK하이닉스, HBM과 차세대 메모리 기술로 펼치는 반도체 패권</p>
<p>AI 시대의 HBM 기술 혁명! 삼성전자와 SK하이닉스의 패권 경쟁, 차세대 메모리의 미래를 탐구합니다. 한국 반도체의 도약을 확인하세요!</p>
<p>skywork.ai 따라서 기술적 차이와 경향성은 확인되지만, 구체적인 수치는 신뢰도 높은 자료가 부족하므로 주의가 필요하다.</p>
<p>5 . 결론 DX 와 AX 는 제조업 혁신의 핵심 경로로, 단순한 디지털화에서 나아가 AI 기반 예측·최적화 체계로의 전환을 의미한다.</p>
<p>이는 설비 수준과 무관하게 단계적으로 도입이 가능하며, 스마트 팩토리 구현의 기반이 된다.</p>
<p>HBM 사례는 AX 의 필요성을 잘 보여준다. 고난도의 적층 공정에서는 공정 변수와 결함 데이터를 정밀하게 수집·분석해야 수율을 안정적으로 확보할 수 있다. SK와 삼성의 공정 차이는 이러한 데이터 기반 접근의 중요성을 방증한다.</p>
<p>따라서 제조업의 경쟁력 확보를 위해서는 DX → AX → 스마트 팩토리로 이어지는 단계적 전략이 필수적이며, 이는 단순한 시스템 도입을 넘어 데이터와 AI 중심의 운영 철학 전환을 요구한다.</p>
<p>02 서울시 스마트 CCTV 시스템 서울시는 2020년부터 지능형 CCTV를 도입하여 교통 흐름 분석, 범죄 예방, 실시간 교통 신호 제어 등을 시도하였으나, 초기 도입 단계에서 AI 모델이 실제 현장 환경에서 기대 이하의 성능을 보였다.</p>
<p>이는 모델이 주로 실내 환경이나 정형화된 데이터에만 학습되어, 다양한 날씨, 시간대, 사람의 행동 패턴 등 실제 환경의 변수를 충분히 반영하지 못했기 때문이다.</p>
<p>서울시는 이러한 문제를 해결하기 위해 산·학·연과 자치구가 참여하는 ‘지능형 CCTV 활성화 계획’ 을 수립하고, 맞춤형 이벤트 설정, 오탐 데이터 학습, 사물·사람 구분 학습 등을 추진하였다.</p>
<p>지능형CCTV로 만드는 디지털 안전도시 서울</p>
<p>서울시가 시민 안전 강화 및 범죄 등 예방을 위해 올해 AI기반 지능형 CCTV를 대폭 늘리고, 시민들의 정보접근성을 높여줄 공공와이파이를 확대할 계획입니다. 서울시는 또 유동인구가 많은 곳 등</p>
<p>scpm.seoul.go.kr</p>
<p>서울시, ’지능형 CCTV’로 지자체 ICT 우수사례 대통령상 수상</p>
<p>서울시가 ’제30회 지방자치단체 정보통신 우수사례 발표대회’에서 지능형 CCTV 오탐지 문제 해결로 대통령상인 최우수상을 수상했다. 관제 효율과 시민 안전망 강화가 높이 평가됐다. 서울시는</p>
<p>www.etnews.com 그 결과, 지능형 CCTV의 상황 판별 정확도는 36% → 71%로 향상되었고, 관제요원의 이벤트 확인률도 37% → 82%로 높아졌다.</p>
<p>불필요한 탐지 건수는 월 454만 → 53만 건으로 줄어들며 약 8.8배 감소하였다. 이러한 개선은 사건 처리 건수를 이전보다 6배 이상 증가된 성과를 가져왔다.</p>
<p>또한, 서울시는 2026년부터 지능형 CCTV에 생성형 AI를 접목하는 시범사업을 추진하여, 기존 CCTV가 단순히 ‘이상 유무’ 만을 판별하는 수준에서 ‘왜 이상한지, 어떤 맥락인지’ 를 설명할 수 있는 단계로 진화할 계획이다.</p>
<p>이러한 사례는 AI 기반 CCTV 시스템의 효용성을 높이기 위해서는 다양한 상황을 반영한 데이터 수집과 모델 훈련이 필수적임을 보여준다.</p>
<p>정상 상황뿐 아니라 예외적 상황까지 포함하는 데이터 기반의 모델 훈련이 가장 중요한 요소로 고려되어야 한다.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_04.html</guid>
  <pubDate>Tue, 16 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>머신러닝: EnjoySport</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_05.html</link>
  <description><![CDATA[ 




<p>의사결정트리 학습 과정에서 활용되는 개념에 대해 다루고자 한다.</p>
<p>01 함수 근사 Function Approximation</p>
<p>기계학습(supervised learning, 개념학습) 관점에서 가설(hypothesis)과 목표 함수(target function) 관계를 설명하고자 한다.</p>
<p>Introduction to Machine Learning and Design of a Learning System</p>
<p>Let me go to the google trend, and understand the trend of the keywords — Machine Learning, data science, artificial intelligence,Hadoop…</p>
<p>medium.datadriveninvestor.com</p>
<p>일반화된 수학적 구조</p>
<p>1 . 문제 설정 입력 공간 ((X))의 각 인스턴스(instance)는 여러 속성(feature) 벡터로 구성된다. 예: 날씨, 온도, 습도 등</p>
<p>출력 공간 ((Y))은 각 인스턴스에 대응되는 정답(label)이다. 예: EnjoySport = Yes/No</p>
<p>지도 학습의 핵심은 입력(feature)과 출력(label, target)이 있고, 출력값(정답)을 예측하기 위해 모델을 학습하는 것이다.</p>
<p>(이러한 표현은 의사결정트리 학습에서도 나오는 방식이다.)</p>
<p>이는 함수 근사 관점에서, 우리가 직접 알 수 없는 목표 함수 ( f: X Y )를 학습 데이터로부터 추정(hypothesis)하는 과정으로 볼 수 있다.</p>
<p>(목표 함수는 타겟 함수(target function) 혹은 개념 함수(concept)라고도 부른다.)</p>
<p>학습 데이터(training set)는 입력-출력 쌍 ( (x^{(i)}, y^{(i)}) )(x^{(i)}, y^{(i)})들로 구성되어 있으며,</p>
<p>학습자의 목표는 이 제한된 데이터만으로 알려지지 않은 (f)를 가능한 잘 근사하는 가설 함수 (h)를 찾는 것이다. 이 프로세스를 함수 근사라고 부른다. [출처1] [출처2]</p>
<p>SCRIPT https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js</p>
<p>2 . 예제 설명 아래는 “사람이 스포츠를 즐길까(Yes/No)”를 날씨 등의 조건으로 학습하는 문제이다. 기계학습의 기초 강의 자료인 1강 및 2강 PDF를 참고하였다.</p>
<ol type="1">
<li>기계 학습의 기초 2-1~2-5 &gt; Machine Learning in Korean (1) | 카이스트 응용인공지능 연구실</li>
</ol>
<p>aai.kaist.ac.kr</p>
<p>Training data set 여러 인스턴스가 주어지고, 각 인스턴스는 여러 속성(feature)과 최종 레이블(label)을 포함한다. 예: &lt;Sky, Temp, Humid, Wind, Water, Forest&gt; → EnjoySport Perfect World 예제 조건</p>
<p>규칙 기반 학습(Rule-Based Learning) 성립을 위한 이상적인(완벽한) 환경을 가정하였다.</p>
<p>즉, 현실에서는 불가능하지만, 이론적인 학습 개념을 이해하기 위해 아래와 같은 조건을 상정하였다.</p>
<p>학습 데이터는 오류나 잡음이 없음 (noise-free). 목표 함수는 결정적(deterministic). 목표 함수가 가설 공간(hypothesis space) 내부에 존재한다고 가정 (“가설 공간이 충분히 크다”). 가설 (Hypothesis) 과정</p>
<p>처음에는 매우 불완전한 가설: &lt;Sunny, ?, ?, ?, ?, ?&gt; 과 같이 일부 속성만 고정 이후 학습 데이터를 반영하면서 점진적으로 구체화 최종적으로 목표 함수 형태: &lt;Sunny, Warm, ?, Strong, ?, ?&gt; 등 일부 속성은 확정 즉, 학습 알고리즘은 데이터로부터 “이 속성은 고정해도 괜찮다”고 판단된 부분을 점점 좁혀가는 방식이다.</p>
<p>목표 함수 (Target function)</p>
<p>실제 이상적인 함수 (f)은 &lt;Sunny, Warm, ?, Strong, ?, ?&gt; 와 같이 더 구체적인 형태 학습자는 이 목표 함수에 최대한 근접하는 가설 (h)을 찾는 것이 목적 이 과정은 결국 “제한된 데이터로부터 숨겨진 함수(목표 함수)를 근사하는 것”이다.</p>
<p>3 . 수학적 관점 &amp; 한계 학습 알고리즘은 손실 함수 (loss function, 예: 제곱 오차, 0-1 손실 등)를 정의하고, 그 손실을 최소화하는 (h)를 선택하는 방식이다. [출처]</p>
<p>만약 가설 공간이 목표 함수를 포함하지 않거나 너무 제한적이면 표현력 한계(approximation error)가 발생할 수 있다.</p>
<p>또한 데이터가 잡음을 포함하거나 노이즈가 있으면 완전 근사는 불가능할 수 있다.</p>
<p>인공신경망은 함수 근사의 강력한 도구로, 충분한 표현력을 가지면 임의의 연속 함수도 근사할 수 있다는 “보편 근사 정리 (Universal Approximation Theorem)”가 존재한다.</p>
<p>02 노드 불순도 측정 지표 입력-출력 데이터로 학습 트리를 구성할 때, 노드 ((t))에 포함된 데이터의 클래스 분포 ({p(i|t)}_{i=1}^c)을 기준으로 불순도(impurity) 또는 불확실성(uncertainty) 을 측정하는 지표들이 사용된다.</p>
<p>1 . 지니 불순도 Gini Impurity</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BGini%7D(t)%20=%201%20-%20%5Csum_%7Bi=1%7D%5Ec%20p(i%20%5Cmid%20t)%5E2"></p>
<p>또는 (_i p(i t),(1 - p(i t))). 노드 내 임의의 샘플을 랜덤하게 라벨하면 잘못 분류될 확률이다. 값은 0 (노드가 하나의 클래스만 포함할 때) 에서 최대 불순도까지 범위를 가진다.</p>
<p>2 . 엔트로피 Entropy</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BEntropy%7D(t)%20=%20-%20%5Csum_%7Bi=1%7D%5E%7Bc%7D%20p(i%20%5Cmid%20t)%20%5C,%20%5Clog_2%5CBig(%20p(i%20%5Cmid%20t)%20%5CBig)"></p>
<p>정보 이론적 관점에서, 해당 지표는 노드나 시스템 내 데이터의 무질서 정도를 나타내며, 동시에 특정 입력을 기반으로 결과를 예측할 때 발생하는 불확실성을 측정하는 역할을 한다.</p>
<p>최대값은 (_2 c.) 이진 분류에서는 최대 1 이다.</p>
<p>3 . 분류 오류율 Misclassification Error</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BError%7D(t)%20=%201%20-%20%5Cmax_%7Bi%7D%20%5Cbig(%20p(i%20%5Cmid%20t)%20%5Cbig)"></p>
<p>노드 내 다수 클래스로만 예측할 때의 잘못 분류 비율이다.</p>
<p>이들 지표를 이용해 노드를 분할할 때는, 분할 전 불순도에서 분할 후 자식 노드들의 가중 평균 불순도를 빼는 값 (즉, 불순도 감소량, 혹은 정보 이득 개념)을 기준으로 한다. [출처]</p>
<p>4 . 특성과 활용 결정 트리에서 불순도 지표들은 각각 특성이 다르다.</p>
<p>지니 지수와 엔트로피는 노드 내 클래스 확률의 변화에 연속적으로 반응하므로, 작은 데이터 분포 변화도 분할 평가에 반영할 수 있어 세밀한 트리 성장을 가능하게 한다.</p>
<p>반면, 분류 오류율은 확률 변화에 대해 불연속적으로 반응하므로 미세한 분할 개선을 평가하기에는 적합하지 않다.</p>
<p>계산 측면에서는 지니 지수가 제곱 연산 중심이어서 비교적 계산이 간단하며, 엔트로피는 로그 연산을 포함하므로 약간 더 계산 비용이 든다.</p>
<p>실제 트리 성장 기준으로는 일반적으로 지니 지수나 엔트로피를 분할 기준으로 사용하고, 분류 오류율은 리프 노드 결정 등 종착 조건 평가용 보조 지표로 활용된다.</p>
<p>해석적 관점에서는 엔트로피가 정보 이론적 해석, 예를 들어 정보 이득이나 상호 정보와 연결되어 있어 속성 선택 기준에 직관성을 제공한다.</p>
<p>03 정보 이득 Information Gain, IG</p>
<p>의사결정나무(Decision Tree) 같은 지도학습 알고리즘에서, 어떤 속성(feature)을 기준으로 분할(split)을 했을 때</p>
<p>불확실성(uncertainty) 또는 엔트로피(entropy)가 얼마나 감소하는지를 측정한 값이다.</p>
<p>즉 분할 전의 엔트로피에서 분할 후 자식 노드들의 엔트로피를 가중평균한 값을 뺀 것이 정보 이득이다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7BIG%7D(S,%20A)%20=%20H(S)%20-%20%5Csum_%7Bv%20%5Cin%20%5Cmathrm%7BValues%7D(A)%7D%20%5Cfrac%7B%7CS_v%7C%7D%7B%7CS%7C%7D%20%5C,%20H(S_v)"></p>
<p>(S): 전체 데이터 집합 (부모 노드) (A): 분할 기준으로 삼는 속성(feature) (S_v)​: 속성 (A)가 값 (v)을 갖는 샘플들의 부분 집합(자식 노드) (H()): 엔트로피 함수 분할 특성(feature)을 선택할 때, “가장 많이 불확실성을 줄이는” 속성을 선택하게 함으로써 트리의 분기가 효과적으로 이루어진다.</p>
<p>트리의 뿌리(root) 쪽에는 정보 이득이 큰 특성이 온다.</p>
<p>이는 여러 속성들 중 어느 속성이 타겟 레이블(label)에 대해 더 “정보를 많이 제공하는지” 또는 “불확실성 감소에 기여하는지” 비교할 수 있음.</p>
<p>정보 이득은 속성(feature)이 갖는 값의 수(value count 또는 카테고리 수) 에 대해 편향(bias)이 있을 수 있음. 값의 종류가 많은 속성이 자칫 더 높은 정보 이득을 갖게 되는 경우 있다.</p>
<p>이를 보완한 방법으로 정보 이득 비율(IG Ratio) 를 쓰는 경우가 많다.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_05.html</guid>
  <pubDate>Tue, 16 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Credit Approval</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_06.html</link>
  <description><![CDATA[ 




<p>의사결정트리 기반 신용평가 분석에 대해 다루고자 한다</p>
<p>01 Credit Approval UCI의 Credit Approval 데이터셋의 일부 속성(attribute)들을 보고, 어떤 속성을 학습 가설(feature set)에 포함하는 것이 더 좋은지를 판단하고자 한다.</p>
<p>참고자료</p>
<ol type="1">
<li>기계 학습의 기초 2-1~2-5 &gt; Machine Learning in Korean (1) | 카이스트 응용인공지능 연구실</li>
</ol>
<p>aai.kaist.ac.kr 본 장에서는 KAIST 인공지능연구원(AAI)에서 제공한 강의 자료 기계 학습의 기초 3강, 4강을 참고하였다.</p>
<p>UCI Machine Learning Repository</p>
<p>A1: b, a. A2: continuous. A3: continuous. A4: u, y, l, t. A5: g, p, gg. A6: c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.&nbsp;A7: v, h, bb, j, n, z, dd, ff, o. A8: continuous. A9: t, f.&nbsp;A10: t, f.&nbsp;A11: continuous. A12: t, f.&nbsp;A13: g, p, s. A14: continuous. A15:</p>
<p>archive.ics.uci.edu # pip install ucimlrepo # ucimlrepo 파이썬 패키지를 통해 간편히 불러올 수도 있다.</p>
<p>from ucimlrepo import fetch_ucirepo import pandas as pd</p>
<section id="데이터-불러오기-credit-approval-id-27" class="level1">
<h1>1. 데이터 불러오기 (Credit Approval, ID = 27)</h1>
<p>credit = fetch_ucirepo(id=27)</p>
</section>
<section id="피처와-타깃-결합" class="level1">
<h1>2. 피처와 타깃 결합</h1>
<p>df = pd.concat([credit.data.features, credit.data.targets], axis=1) df</p>
<p>데이터셋 개요</p>
<p>전체 인스턴스 수: 690개 샘플(instances): 690개 피처(features): 15개 타깃(target, 승인 여부): 1개 일부 피처들이 연속형(continuous), 일부 명목형(categorical).</p>
<p>결측값(missing values)이 존재함 (UCI 리포지토리에 “Has Missing Values? Yes” 라고 명시됨). [출처]</p>
<p>결측이 표기된 방식이 ‘?’ 문자열 (특히 categorical 또는 일부 continuous 피처)임. [출처]</p>
<p>여기서 A1, A9 두 속성이 각각 긍정/부정 클래스를 얼마나 잘 분리할 수 있는지를 비교하고 있고, 어떤 속성이 더 좋은 속성인지 판별하고자 한다.</p>
</section>
<section id="각-컬럼의-고유값이-시리즈-형태로-반환" class="level1">
<h1>각 컬럼의 고유값이 시리즈 형태로 반환</h1>
<p>unique_values = df[[‘A1’, ‘A9’, ‘A16’]].apply(lambda x: x.unique()) unique_values</p>
<p>A1에 결측치 확인</p>
<p>A1, A9 속성 기준 승인/거절 빈도 및 퍼센트 요약표 생성</p>
<p>import pandas as pd</p>
</section>
<section id="a1-컬럼의-nan-값을-문자열-로-변환-결측치-표시" class="level1">
<h1>A1 컬럼의 NaN 값을 문자열 ’?’로 변환 (결측치 표시)</h1>
<p>df[‘A1_filled’] = df[‘A1’].fillna(‘?’)</p>
</section>
<section id="전체-클래스-분포" class="level1">
<h1>전체 클래스 분포</h1>
<p>class_dist = df[‘A16’].value_counts().rename_axis(‘A16’).reset_index(name=‘count’) total_positive = class_dist.loc[class_dist[‘A16’]==‘+’,‘count’].values[0] total_negative = class_dist.loc[class_dist[‘A16’]==‘-’,‘count’].values[0]</p>
</section>
<section id="a1-교차표-결측치-포함" class="level1">
<h1>A1 교차표 (결측치 포함)</h1>
<p>cross_A1 = pd.crosstab(df[‘A1_filled’], df[‘A16’]).reset_index() cross_A1.insert(0, ‘속성’, ‘A1’) cross_A1 = cross_A1.rename(columns={‘A1_filled’: ‘값’, ‘+’: ‘승인(+)’, ‘-’: ‘거절(-)’})</p>
</section>
<section id="퍼센트-컬럼-추가" class="level1">
<h1>퍼센트 컬럼 추가</h1>
<p>cross_A1[‘승인(%)’] = (cross_A1[‘승인(+)’] / total_positive * 100).round(1) cross_A1[‘거절(%)’] = (cross_A1[‘거절(-)’] / total_negative * 100).round(1)</p>
</section>
<section id="a9-교차표-결측치-없음" class="level1">
<h1>A9 교차표 (결측치 없음)</h1>
<p>cross_A9 = pd.crosstab(df[‘A9’], df[‘A16’]).reset_index() cross_A9.insert(0, ‘속성’, ‘A9’) cross_A9 = cross_A9.rename(columns={‘A9’: ‘값’, ‘+’: ‘승인(+)’, ‘-’: ‘거절(-)’}) cross_A9[‘승인(%)’] = (cross_A9[‘승인(+)’] / total_positive * 100).round(1) cross_A9[‘거절(%)’] = (cross_A9[‘거절(-)’] / total_negative * 100).round(1)</p>
</section>
<section id="전체-클래스-분포를-표-형태로-변환" class="level1">
<h1>전체 클래스 분포를 표 형태로 변환</h1>
<p>overall = pd.DataFrame({ ‘속성’: [‘전체’], ‘값’: [‘-’], ‘승인(+)’: [total_positive], ‘거절(-)’: [total_negative], ‘승인(%)’: [100.0], ‘거절(%)’: [100.0] })</p>
</section>
<section id="데이터-병합" class="level1">
<h1>데이터 병합</h1>
<p>combined_df = pd.concat([overall, cross_A1, cross_A9], ignore_index=True) combined_df</p>
<p>1 . 속성 선택 기준 머신러닝 / 개념 학습 이론에서 좋은 속성(feature)을 선택하는 기준은 다음과 같다:</p>
<p>정보 이득(IG) 혹은 엔트로피 감소 지니 계수 (Gini impurity) 감소 분류 순도 (Purity) 잡음 민감성 — 속성이 얼마나 레이블 노이즈에 영향을 덜 받는가 이 속성 선택 기준들은 결정 트리 알고리즘(C4.5, CART 등)에서 흔히 쓰인다.</p>
<p>즉, 어떤 속성이 클래스 라벨(+)과 (–)를 더 잘 구분할 수 있을지, 엔트로피(불확실성)를 많이 줄일 수 있을지를 보는 것이다.</p>
<p>2 . A1 vs A9 비교</p>
<p>기계 학습의 기초 3강 pdf 자료 A9 속성의 Positive/Negative 비율을 보면, t일 경우 약 79%가 Positive, f일 경우 약 93%가 Negative로 나타나, 클래스 구분력이 매우 높음을 알 수 있다.</p>
<p>반면 A1 속성은 a와 b 사이의 Positive 비율 차이가 약 3~4% 수준으로 미미하여, 클래스 구분 신호가 약하다.</p>
<p>따라서 (A9)를 포함하는 학습 가설 모델은 더 높은 성능을 기대할 수 있다.</p>
<p>SCRIPT https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js</p>
<p>3 . 주의할 점 / 한계 제시된 것은 빈도수 기반 단순 비교일 뿐이고, 실제 속성의 복합 상관관계나 다른 속성과의 상호작용은 고려하지 않는다.</p>
<p>결측치(?) 처리가 중요하다. 제시된 A1의 경우 “?” 값이 일부 존재하므로, 이를 어떻게 처리하는가가 결과에 영향을 준다.</p>
<p>노이즈(잘못된 레이블, 입력 오류 등)가 존재할 수 있고, 속성 선택이 그 노이즈에 민감할 수 있다.</p>
<p>속성 하나만으로 모든 분류가 가능하지 않으므로 여러 속성을 조합하는 가설이 필요하다.</p>
<p>02 암맹처리 UCI의 Credit Approval 데이터셋에서 결측치(missing values, 암맹처리 또는 ‘?’ 표기됨) 처리를 하는 이유에 대해 설명하고자 한다.</p>
<p>1 . 분류 모델/알고리즘의 단점 대부분의 ML 라이브러리(예: scikit-learn)의 분류/회귀 알고리즘은 입력 피처(feature)의 값이 모두 수치(numeric), 범주형(categorical) 변환이 완료된 상태여야 한다.</p>
<p>‘?’ 같은 문자열은 수치 연산, 비교, 통계계산, 분기(split) 등이 불가능하거나 오류를 발생시키기 쉬우며, 평균(mean), 엔트로피 계산, 불순도 계산 시 오류가 발생한다.</p>
<p>따라서 ’?’를 NaN 또는 동일한 결측치 포맷으로 바꾸고, 이를 채우거나 해당 샘플/속성을 제거해야 한다.</p>
<p>2 . 모델의 성능 및 일반화 결측치를 처리하는 핵심 목적 중 하나가 편향(bias) 제거이다.</p>
<p>결측치 미처리 시 모델이 학습 중 일부 피처를 무시하거나, 잘못된 피처 분할(split)로 과적합(overfitting) 또는 편향(bias)가 커질 수 있기 때문이다.</p>
<p>또한 학습 데이터와 테스트 데이터 간의 일관성이 깨질 수 있다.</p>
<p>학습에는 특정 방식으로 결측치 처리를 했는데, 실제 예측 시에는 결측치 형태가 다르면 예측이 잘 안 되는 경우</p>
<p>3 . 통계적 분석의 정확성 확보 결측이 있는 상태로 단순히 평균/분포/상관관계(correlation) 계산 등을 하면, 해당 피처가 가진 정보가 왜곡될 수 있다.</p>
<p>예: 연속형 피처에 결측치가 많으면 그 피처의 평균/표준편차 등의 계산이 왜곡됨 → 전체 엔트로피나 지니, 정보 이득(IG) 계산 등에 영향을 끼침.</p>
<p>4 . 데이터의 규모와 손실 최소화 전체 데이터 중 결측이 있는 샘플이 많지 않다면(dropna), 이들을 제거하는 것이 하나의 방법임.</p>
<p>이 데이터셋에서는 약 37개의 행(samples) — 전체의 약 5% 정도가 결측값을 포함함. [출처]</p>
<p>하지만 결측치가 많은 피처가 있다면 단순 제거는 정보 손실이 큼. 이런 경우 imputation(대체값 채우기) 방법(평균, 최빈값, 예측 모델 등)이 사용된다.</p>
<p>5 . 실제 적용 예시 여러 프로젝트/분석에서, 이 데이터셋의 결측치는 ’?’로 표시되어 있어 먼저 이를 NaN으로 변환함. [출처]</p>
<p>연속형 피처에 대해서는 평균(mean) 또는 중앙값(median)으로 채움(imputation). 명목형(categorical) 피처의 경우 최빈값(mode)으로 채우는 사례가 많음. [출처]</p>
<p>또는 결측이 있는 샘플을 통째로 제거(drop)하는 방법이 사용됨. 예: 37개의 결측 샘플을 제거한 후 분석 진행한 연구 있음. [출처]</p>
<p>결과적으로, 암맹처리는 단순히 오류를 피하기 위한 것뿐만 아니라 모델의 공정성(fairness)과 일반화 성능을 높이는 중요한 단계이다.</p>
<p>03 ID3 의사결정나무 분할 전략 ID3(Iterative Dichotomiser 3) 알고리즘은 의사결정나무 모델에서 데이터를 분할할 특성을 선택할 때 정보 이득(IG)을 기준으로 삼는다.</p>
<p>정보 이득은 특정 속성으로 데이터를 분할했을 때 엔트로피가 얼마나 감소하는지를 측정하는 지표로, 엔트로피는 데이터의 불순도 또는 무질서를 나타낸다.</p>
<p>즉, 엔트로피 감소가 클수록 해당 속성은 데이터를 더 잘 분리한다고 판단되어 우선적으로 선택된다. [출처].</p>
<p>엔트로피 계산 예제</p>
<p>1 . 전체 엔트로피 H(Y) (P(+) = 307/690 ,P(-) = 383/690 ) (H(Y) = - (0.445 _2 0.445 + 0.555 _2 0.555) )</p>
<p>2 . A1로 분할 후 엔트로피 H(Y|A1) 각 그룹 엔트로피 계산 후 가중 평균:</p>
<p><img src="https://latex.codecogs.com/png.latex?H(Y%7CA1)%20=%20%5Cfrac%7B210%7D%7B690%7D%20H(a)%20+%20%5Cfrac%7B468%7D%7B690%7D%20H(b)%20+%20%5Cfrac%7B12%7D%7B690%7D%20H(?)"></p>
<p>각 그룹 엔트로피:</p>
<p>(a: (H(a) = - (98/210 _2 (98/210) + 112/210 _2 (112/210)) ) ) (b: (H(b) = - (206/468 _2 (206/468) + 262/468 _2 (262/468)) ) ) (?: (H(?) = - (3/12 _2 (3/12) + 9/12 _2 (9/12)) ) ) 가중 평균:</p>
<p><img src="https://latex.codecogs.com/png.latex?H(Y%7CA1)%20%5Capprox%20%5Cfrac%7B210%7D%7B690%7D%5Ccdot0.998%20+%20%5Cfrac%7B468%7D%7B690%7D%5Ccdot0.993%20+%20%5Cfrac%7B12%7D%7B690%7D%5Ccdot0.811%20%5Capprox%200.994"></p>
<p>3 . A9로 분할 후 엔트로피 H(Y|A9) ( t: (H(t) = - (284/361 _2(284/361) + 77/361 _2(77/361)) )) ( f: (H(f) = - (23/329 _2(23/329) + 306/329 _2(306/329)) ) ) 가중 평균:</p>
<p><img src="https://latex.codecogs.com/png.latex?H(Y%7CA9)%20%5Capprox%20%5Cfrac%7B361%7D%7B690%7D%5Ccdot0.722%20+%20%5Cfrac%7B329%7D%7B690%7D%5Ccdot0.164%20%5Capprox%200.455"></p>
<p>4 . 정보이득 계산 <img src="https://latex.codecogs.com/png.latex?IG(Y,%20A1)%20=%20H(Y)%20-%20H(Y%7CA1)%20%5Capprox%200.99%20-%200.994%20=%20-0.004%20%5Cquad%20(%5Ctext%7B%EC%82%AC%EC%8B%A4%EC%83%81%200%7D)"></p>
<p><img src="https://latex.codecogs.com/png.latex?IG(Y,%20A9)%20=%20H(Y)%20-%20H(Y%7CA9)%20%5Capprox%200.99%20-%200.455%20=%200.535"></p>
<p>A9가 정보이득이 훨씬 크므로, ID3에서는 A9를 루트 노드(최초 분할 기준)로 선택한다. A1은 거의 정보이득이 없어 의미 있는 분할이 되지 않는다.</p>
<p>따라서, A9가 먼저 선택되어 분할 기준으로 사용되며, 이는 모델의 성능 향상에 기여할 수 있다.</p>
<p>04 의사결정 트리의 한계 의사결정 트리(Decision Tree)는 구조가 직관적이고 해석이 용이하다는 장점이 있으나, 현실의 데이터가 갖는 노이즈와 불일치성에 매우 민감하다는 단점이 있다.</p>
<p>데이터에 포함된 잡음이나 이상치가 많을 경우, 트리는 그 불완전한 패턴까지 학습하여 과적합(overfitting) 이 발생하거나 작은 데이터 변화에도 트리 구조가 크게 달라지는 불안정성(variance) 을 보인다.</p>
<p>이러한 이유로, 단일 트리 모델은 실제 업무 환경에서의 예측 신뢰성이 낮을 수 있다.</p>
<p>이러한 문제를 보완하기 위해 도입된 방법이 앙상블 기법이다.</p>
<p>1 . 앙상블 기법 Ensemble</p>
<p>여러 개의 학습기(base learners)를 조합하여, 단일 모델보다 더 안정적이고 일반화 성능이 높은 예측 결과를 도출하는 방법.</p>
<p>이는 음악의 ’오케스트라’처럼 개별 모델의 예측을 조화롭게 결합하여 전체적인 조화(화음)를 이루는 방식으로 비유할 수 있다.</p>
<p>앙상블 기법은 일반적으로 두 가지로 구분된다.</p>
<p>2 . Bagging Bootstrap Aggregating</p>
<p>데이터로부터 복원추출(bootstrap sampling)된 여러 하위 표본을 생성하여, 각 표본마다 독립된 트리를 학습시킨 후 결과를 평균(또는 투표)하는 방식이다.</p>
<p>대표적인 알고리즘은 랜덤 포레스트(Random Forest) 로, 각 트리 학습 시 특성(feature)의 일부만 무작위로 선택하여 트리 간의 상관성 및 분산을 효과적으로 감소한다.</p>
<p>이러한 무작위성과 집계(aggregation) 과정을 통해 단일 트리에 비해 일반화 능력과 예측 안정성이 향상된다.</p>
<p>3 . Boosting 약한 학습기(weak learner)를 순차적으로 학습시키는 방식으로, 이전 모델이 잘못 예측한 데이터에 더 큰 가중치를 부여하여 점진적으로 오차를 보정한다.</p>
<p>이 방식은 편향(bias) 을 줄이는 데 효과적이며, 대표적인 알고리즘으로 AdaBoost, Gradient Boosting, XGBoost 등이 있다.</p>
<p>다만, 데이터에 노이즈가 많을 경우 과적합 위험이 존재하므로, 적절한 규제(regularization)와 학습률 조절이 필요하다.</p>
<p>4 . 효과와 한계 일반적으로 단일 트리 모델보다 2 ~ 5% 내외의 성능 향상을 보이는 것으로 보고되지만, 향상 폭은 데이터의 특성과 모델 설계에 따라 달라질 수 있다.</p>
<p>또한, 앙상블은 여러 모델을 결합하므로 해석력이 낮아지고 계산 비용이 증가하는 단점도 존재한다.</p>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_06.html</guid>
  <pubDate>Tue, 16 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>AI 산업 전망</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_01.html</link>
  <description><![CDATA[ 




<p>AI 산업 전망에 대해 다루고자 한다.</p>
<p>01 팬데믹</p>
<p>1 . 온라인 전환 및 IT 수요 급증 팬데믹으로 인해 오프라인 중심이던 기업들이 온라인으로 빠르게 전환되었다.</p>
<p>MS의 CEO인 Satya Nadella는 2020년 4월 30일에 발표된 분기 실적 보고서에서 다음과 같이 언급하였다:</p>
<p>” 우리는 두 달 만에 2년 분량의 디지털 전환을 경험했다. ” [출처] 재택근무와 원격교육이 보편화됨에 따라 화상회의, 실시간 번역, 맞춤형 배경 등 다양한 비대면 기술이 빠르게 발전했으며, 이로 인해 협업 솔루션 시장은 급격히 확대되었다.</p>
<p>연도 시장 규모 추정치 출처/비고 2019 약 9.878 십억 달러 Allied Market Research 2020 약 15.25 십억 달러 Fortune Business Insights 2021 추정치 계산 불가 COVID-19 효과가 강해, 일관된 비교가 어렵다는 한계 있음. 2022 약 27.4081 십억 달러 Grand View Research 2023 약 21.79 십억 달러 Fortune Business Insights 2024 약 36.1142 십억 달러 Grand View Research 미국의 온라인 쇼핑 매출은 2019년 5,712억 달러에서 2020년 8,154억 달러로 전년 대비 43% 증가했다. [출처]</p>
<p>유럽에서도 2020년 4월, 전체 소매 판매는 큰 폭으로 감소했지만, 온라인 구매 비중은 2019년 4월 19.1%에서 30.7%로 급증했다. [출처]</p>
<p>각국의 락다운이 시행되면서 화상회의, 원격근무, 온라인 교육 등의 증가로 인터넷 트래픽이 1주일 이내에 15 ~ 20% 증가했다. [출처]</p>
<p>2 . 팬데믹 종료 이후 이전 수준으로 회귀 여부 소비 회복의 불균형 가능성이 언급되었다.</p>
<p>팬데믹으로 대면 서비스 수요는 급감했지만, 팬데믹 이후 일부 행태는 유지될 가능성이 컸다. [출처]</p>
<p>또한, 많은 오프라인 매장의 폐업, 상업용 부동산 공실 증가 등은 온라인 전환이 영구적인 변화였음을 시사한다.</p>
<p>1 . 오프라인 회복, 여전히 주요 비중 유지 2019년 디지털 판매 성장률이 53.5%였던 반면, 2022년 오프라인 매출은 전체 성장의 78.1%를 차지하며 오프라인 매장이 여전히 매출 성장의 주요 원천임을 보여준다. [출처]</p>
<p>실제 매장 개방 시 디지털 매출이 평균 6.9% 증가하지만, 매장을 닫으면 온라인 매출은 11.5% 줄어든다는 연구도 있다. 이는 오프라인 매장의 존재가 디지털 매출에도 긍정적 영향을 준다는 점을 시사한다. [출처]</p>
<p>2 . 오프라인이 다시 강세를 보이는 추세 팬데믹 중 급성장한 전자상거래는 이후 이전 예상 수준으로 회귀하는 경향이 있는 반면, 오프라인 소매업은 예상보다 더 높은 회복세를 보였다. 오프라인 소매 비중이 온라인보다 더욱 빠르게 반등했다는 분석도 있다. [출처]</p>
<p>3 . 장기적인 변화는 지속 중 “다시는 이전으로 돌아가지 않을 것”이라는 표현이 있을 만큼, 디지털화된 경제 구조는 팬데믹 이후에도 지속될 가능성이 크다는 분석도 존재한다. 변화된 생산 및 소비 방식이 장기적으로 유지될 것이라는 견해이다.</p>
<p>02 GPT</p>
<p>1 . GPT 탄생, 챗봇 혁명 OpenAI는 2022년 11월 30일, GPT-3.5 기반의 ChatGPT를 공개적인 “연구 미리보기(research preview)” 형태로 출범시켰다.</p>
<p>이 발표 직후 비약적인 성장세를 보였으며, 출시 두 달 만에 1억 명 이상의 사용자를 확보하는 등 빠른 이용자 확산을 기록했다.</p>
<p>이 모델은 텍스트 기반 응답뿐만 아니라, 코드 생성 및 코드 완성이 가능한 능력을 갖추고 있어 많은 개발자가 실제로 활용 중이다.</p>
<p>2 . 저렴한 수준의 AI 코딩 서비스 OpenAI가 제공하는 최상위 구독 요금제인 ChatGPT Pro는 월 $200에 무제한 GPT-4o Pro 접근권, 고급 음성 기능 등을 포함하며, 이는 약 50만 원 수준에 해당한다. [출처]</p>
<p>구글도 마찬가지로 AI Ultra 요금제를 발표했으며, 가격은 $249.99/월로, Deep Think reasoning 모드 등 고급 기능을 탑재한 모델 및 AI 툴 세트를 제공한다. [출처]</p>
<p>위 요금제는 고급 모델을 사용하려는 개인 혹은 연구자에게 적합하며, 초급 개발자를 비용 대비 대체하는 수준의 AI 기능을 충분히 포함하고 있다.</p>
<p>3 . 월 10 ~ 20만 원대의 AI 코딩 도구 보다 현실적인 예시로, 다음과 같은 AI 코딩 어시스턴트도 존재한다: [출처]</p>
<p>구분 비용 및 특징 GitHub Copilot 약 $10/월 , GPT-4 기반 코드 완성 기능 제공 Cursor Pro 약 $20/월, 다양한 모델 액세스 및 IDE 통합 Tabnine Pro 및 유사 도구들 $12–20/월 이들 도구는 초급 개발자 수준의 코딩 지원에 필요한 기능을 충분히 제공하며, 월 약 10 ~ 20만 원의 비용으로 사용 가능하다.</p>
<p>03 경제 둔화</p>
<p>1 . 물가 상승 → 금리 인상 중앙은행은 높은 인플레이션을 억제하기 위해 기준금리를 인상한다. 이는 통화정책의 기본 방향이며, 비교적 일반적인 경제 수단이다.</p>
<p>테일러 룰(Taylor Rule)에 따르면, 인플레이션이 1% 상승할 때마다 명목금리는 그 이상을 인상해야 실제 금리가 상승하여 경제를 안정시키는 효과가 생긴다.</p>
<p>2 . 금리 인상 → 고용 감소 물가 상승을 막기 위한 금리 인상은 기업의 비용 부담을 높여 고용 축소로 이어질 수 있으며 일부 계층(예: 여성, 소수민족 등)에 더 큰 영향을 줄 수 있다. [출처] 실제로 금리 인상 후 경기 침체(리세션) 즉 고용 시장이 위축되는 경향이 있다.</p>
<p>3 . 고용 감소 → 소비 위축 고용이 줄면 소득 및 소비 여력이 감소되어, 결과적으로 경제활동 전반에 부정적 영향을 미친다. 이는 중앙은행이 다시 경기 부양을 위한 금리 인하를 고려하게 만드는 요인 중 하나이다. [출처]</p>
<p>4 . 소득 감소 및 불확실성 → 투자 여력 축소 고용 불안정과 소비 위축은 기업의 투자 여력도 감소시킨다. 이는 재정의 불안정과 기업 활동 위축으로 이어질 수 있다는 일반적 경제 논리와 맞닿아 있다.</p>
<p>04 고령화</p>
<p>1 . 기술직 내 세대별 노동력 변화 대형 테크 기업에서 직원 평균 연령이 약 3년 이상 상승했다. 이는 밀레니얼 세대 이상이 IT 업계 내에서 지배적인 위치를 차지하게 되었음을 보여준다. 동시에, 디지털에 익숙한 젊은 세대(Gen Z)의 비중이 감소하고 있는 것으로 해석된다. [출처]</p>
<p>이러한 경향은 “신입보다 시니어 인력이 주류가 되는 현상”과 연관시켜 볼 수 있다.</p>
<p>2 . 고령화된 노동층의 도전 및 기회 AI 도입 과정에서 고령 노동자를 배제하지 않고 포함할 수 있도록 하는 전략 즉 ’age-proofing AI’의 필요성을 강조한다.</p>
<p>이는 인력 다양성과 포용성을 위한 조치이며, 고령자 중심 구조가 불가피한 사회 변화로 다가올 수 있음을 시사한다. [출처]</p>
<p>55–64세 연령층의 고용률은 학력 수준에 따라 크게 차이가 있으며, 고학력자 중심으로 고령 노동 시장에서의 참여가 증가하고 있다. [출처]</p>
<p>3 . 시니어 중심 노동 시장에 대한 사회적 우려 45세 이상의 IT 종사자 중 70%가 연령 차별을 경험하거나 목격한 적이 있다고 응답했다.</p>
<p>이 사실은 고령 인력이 노동 시장에서 고립될 수 있다는 구조적 위험도 내포한다. [출처]</p>
<p>중국의 “curse of 35” (35세 저주) 사례도 주목할 만한다. 일부 IT 기업들은 30대 중반 이상 직원을 비용 부담과 에너지 부족을 이유로 선호하지 않는 경향이 있으며, 이는 고령 인력의 지위가 위태로울 수 있음을 나타낸다. [출처]</p>
<p>4 . 기업 내 핵심 지식과 경험의 상실 U.S. 기업들의 경우, 베이비붐 세대가 은퇴하면서 조직의 핵심 지식이 사라지고 경험이 축적되지 않는 상황에 직면하고 있다. 이는 기업의 효율성과 혁신 역량 저하로 이어질 수 있다. [출처]</p>
<p>고령 직원의 은퇴는 생산성 및 리더십 공백을 초래할 수 있어, 이를 대비한 체계적인 승계 계획과 멘토링 프로그램 수립이 필수적이라고 강조한다. [출처]</p>
<p>NASA의 아폴로 사업 경험처럼, 핵심 인력 퇴직 후 해당 지식을 대체하지 못한 사례들도 있다. [출처] 2005년 Accenture 조사에서는 많은 기업들이 은퇴자 지식 이전을 위한 계획조차 없었음을 보고했다. [출처]</p>
<p>5 . 고령 노동 비중 증가 추세 2022년 대비 2032년까지, 65세 이상 노동자의 노동 참여율이 6.6%에서 8.6%로 상승하며, 전체 노동 인구 증가분 중 57%가 고령층에 해당할 것으로 전망된다. 이는 고령층 노동자 비중이 높아지는 구조적 변화를 가리킨다. [출처]</p>
<p>ベイビーブーマー 세대의 대규모 은퇴로, Gen X, 밀레니얼, Z세대가 노동 시장의 주요 역량으로 부상하며, ’Silver Tsunami’로도 불리는 전환기가 도래하고 있다. [출처]</p>
<p>05 산업 변곡점 1998년, NIPA(한국 IT산업진흥원)이 설립되어 대한민국의 IT 산업 육성을 위한 중추적 역할을 해 왔다.</p>
<p>1 . 한국 정부의 AI 전략 집중 2025년 8월, 한국 정부는 AI 및 혁신 프로젝트 30개 추진을 골자로 한 AI 중심 경제 전략을 발표했다. 로봇, 자동차, 반도체, 드론 등 산업 전반을 포함하며, 국가 성장 펀드 규모는 100조 원 규모이다. [출처]</p>
<p>또한 국가 AI 전략위원회를 설립하여 AI 정책 및 전략을 대통령 직속으로 관리하고 있다.</p>
<p>“한국 정부는 AI를 국가 전략 산업으로 설정했고, 이제 본격적인 출발점에 서 있다.” 결과적으로, 기존 IT는 계속 존재하지만 정책·투자·혁신 관점에서는 AI가 1순위, 전통 IT는 2순위라는 구조적 변화라고 볼 수 있다.</p>
<p>AI 산업에서의 경쟁 우위 확보는 주요 국정 과제로 꼽힌다. 이를 위해서는 데이터 확보 및 AI 인프라가 중요한 전략으로 강조된다. [출처]</p>
<p>2 . 플랫폼을 통한 데이터 확보 한국에서는 네이버가 검색 엔진 시장의 절반 이상을 차지하고 있으며, 외국 Big Tech의 점유율은 상대적으로 낮게 유지되고 있다는 보고가 있다. [출처]</p>
<p>특히, 한국은 지리정보 데이터와 같은 특정 데이터에 대해 엄격한 규제를 두고 있으며, 이로 인해 Google Maps 같은 서비스 기능이 완전히 작동하지 못하는 경우가 있다.</p>
<p>또, Google은 한국의 앱스토어 수수료 및 자사 앱 우선 노출 등 관련하여 공정거래위원회 또는 규제 대상이 된 사례가 있으며, 이는 국내 플랫폼 보호와 경쟁 환경의 복합적 모습을 보여준다. [출처]</p>
<p>한국 내 검색·광고 시장 분석에서는 네이버가 국내 사용자 특성, 언어, 콘텐츠 생태계와의 적합성 덕분에 강한 지위를 유지하고 있다는 언급이 있다. [출처]</p>
<p>네이버와 카카오가 AI·콘텐츠 강화 전략을 내세우며 “자체 생태계 확장”을 추진 중이라는 보도도 있다. [출처]</p>
<p>3 . 일본의 플랫폼 부재 일본은 전통적으로 내수 중심 플랫폼 기업이 한국·중국 등에 비해 적다는 평가가 있다.</p>
<p>언어 및 문화, 법률·규제 측면에서 외국 기술 및 플랫폼 기업에 의존하는 경향이 있었고, 이에 따라 일본 정부나 대기업이 데이터 주권, 플랫폼 통합성 확보에 더 민감할 가능성 있다.</p>
<p>일본과 유럽 간 데이터 공간(data space) 구현 방식을 비교한 연구에서는, 일본이 거버넌스 체계나 인증 프레임워크, 기술 표준 면에서 유럽보다 상호 운용성 확보에 어려움을 겪고 있다는 분석이 나온다. [출처]</p>
<p>저작권 및 개인정보 보호 규제 측면에서, 일본은 AI 학습용 데이터 활용에 있어 일부 유연한 접근을 허용한 사례도 있으나, 여전히 데이터 접근과 보안 규제의 균형이 과제로 남아 있다. [출처]</p>
<p>특허 기반 연구에서도 일본 기업들이 기술 복잡성 측면에서는 대응 가능하지만, 신생 플랫폼 기업의 민첩성과 확장성에서는 경쟁국에 비해 약점이 있다는 해석이 나온다. [출처]</p>
<p>① 생성형 AI는 대규모 데이터와 학습용 데이터의 접근성이 핵심이다.</p>
<p>일본이 거버넌스 체계, 인증 프레임워크, 기술 표준 면에서 유럽보다 상호 운용성 확보가 어렵다면, 다양한 출처의 데이터를 통합·활용하는 데 제약이 생긴다.</p>
<p>결과적으로 AI 모델 학습 속도와 성능 향상에 제한이 발생할 수 있으며, 저작권·개인정보 보호 규제의 균형 문제도 데이터 확보와 활용에 직접적 영향을 준다.</p>
<p>② AI 시스템 개발에는 소프트웨어 설계, 최적화, 확장성이 필수적이다.</p>
<p>일본의 소프트웨어 산업이 플랫폼 경쟁력 확보에서 취약하다면, 혁신적 AI 서비스 개발이나 글로벌 경쟁에서 불리할 수 있다.</p>
<p>특허 기반 연구에서는 기술 복잡성 대응은 가능하지만, 신생 플랫폼 기업의 민첩성 및 확장성 부족은 시장 적응과 혁신 속도에 제한을 줄 수 있다.</p>
<p>따라서 한국도 국내 플랫폼이 강력한 우위를 가진다고 방심할 수 없다. 데이터 확보, 기술 표준화, 소프트웨어 역량 강화, 규제 환경의 유연화 등 다각적인 대비가 필요하며, 지속적인 혁신과 인프라 확충을 통해 경쟁 우위를 유지해야 한다.</p>
<p>06 AI의 전망</p>
<p>1 . AI 산업의 급성장 MS는 AI 인프라 공급업체인 Nebius와 최대 200억 달러 규모의 5년 계약을 체결하였다. 이는 AI 모델 학습과 추론을 위한 GPU 리소스 확보를 위한 전략의 일환이다. [출처]</p>
<p>NVIDIA는 차세대 AI 칩인 ’Rubin CPX’를 2026년 말 출시할 예정이며, 이는 고해상도 비디오 생성 및 AI 기반 SW 개발에 최적화되어 있다. [출처]</p>
<p>데이터 센터의 전력 수요가 2027년까지 50%, 2030년까지 165% 증가할 것으로 전망하고 있다. [출처]</p>
<p>2 . 데이터와 GPU의 중요성 IDTechEx는 2025년 GPU 배치량이 기하급수적으로 증가할 것으로 예상하며, 이는 AI 모델 훈련과 추론에 필수적인 요소로 작용하고 있다. [출처]</p>
<p>데이터 센터 GPU 시장이 2025년 1,199억 7,000만 달러에서 2030년까지 2,280억 4,000만 달러에 이를 것으로 예상하고 있다. [출처]</p>
<p>3 . AI 관련 인력 수요 Databricks는 AI 제품에 대한 수요 증가로 연간 수익이 40억 달러에 이를 것으로 예상하며, 이는 AI 관련 인력의 수요 증가를 시사한다. [출처]</p>
<p>4 . AI 산업의 지속 가능성 NVIDIA는 AI 시장이 연평균 성장률(CAGR) 26.6%로 성장할 것으로 전망하며, 이는 AI 산업의 지속 가능성을 뒷받침한다. [출처]</p>
<p>현재 엔비디아(NVDA)의 주가는 170.76달러로, 전일 대비 2.58달러(1.53%) 상승하였다. 이는 AI 산업의 성장과 엔비디아의 시장 지배력을 반영하는 지표로 볼 수 있다.</p>



 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_01.html</guid>
  <pubDate>Tue, 09 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>머신러닝 개론</title>
  <link>https://shinjihan.github.io/studylog/ai/ml/ml_02.html</link>
  <description><![CDATA[ 




<p>머신러닝의 전반적인 개론에 대해 다루고자 한다.</p>
<section id="머신러닝" class="level1">
<h1>01 머신러닝</h1>
<p><code>Machine Learning</code></p>
<p>데이터로부터 패턴을 학습하여 예측이나 의사결정을 수행하는 인공지능의 한 분야이다.</p>
<p>머신러닝은 데이터의 라벨(Label) 존재 여부에 따라 지도학습(Supervised Learning)과 비지도학습(Unsupervised Learning)으로 구분된다. 이를 이해하기 위해 대표적인 예시인 분류와 군집화를 비교하도록 한다.</p>
<p>1 . 분류(Classification) 지도학습의 대표적인 기법으로, 라벨이 주어진 데이터를 학습하여 새로운 데이터의 정답을 예측한다.</p>
<p>결과값은 이산형 범주(예: 스팸/일반메일)이며, 대표 알고리즘으로 로지스틱 회귀, 의사결정나무, SVM 등이 있다.</p>
<p>2 . 군집화(Clustering) 비지도학습에 속하며, 라벨이 없는 데이터를 유사도에 따라 그룹화하여 내재된 구조를 발견한다.</p>
<p>실제 라벨이 없으므로 손실함수 대신 클러스터 내의 응집도(cohesion)와 클러스터 간 분리도(separation)와 같은 목적함수를 사용하여 데이터의 구조를 평가한다. [출처]</p>
<p>대표 알고리즘으로는 K-Means, DBSCAN, 계층적 군집화가 있으며, 고객 세분화나 이미지 분석 등에 활용된다. [출처1], [출처2]</p>
<p>반지도학습(Semi-supervised Learning)</p>
<p>일부 데이터에만 라벨이 존재하는 경우, 라벨이 없는 데이터를 함께 활용해 학습 성능을 향상시키는 방법이다. 이는 라벨링 비용이 높은 실제 환경에서 자주 사용된다.</p>
<p>02 손실함수 Loss function</p>
<p>앞서 살펴본 지도학습은 라벨이 존재하는 데이터를 기반으로 예측 모델을 학습한다. 이러한 학습의 핵심은 예측값과 실제값의 차이를 최소화하는 것으로, 이를 위해 손실함수를 정의한다.</p>
<p>예측과 정답의 오차(error)를 수치화하며, 학습의 목표는 이 손실을 최소화하는 것이다. [출처]</p>
<p>이 과정에서 사용되는 가중치(weight) 는 입력 변수의 중요도를 나타내는 모델의 매개변수이며, 학습은 손실함수를 최소화하는 방향으로 가중치를 조정하는 절차이다.</p>
<p>기울기(gradient)는 손실함수에 대한 가중치의 변화율을 의미하며, 이를 이용해 가중치를 반복적으로 업데이트한다.</p>
<p>최종적으로 학습이 완료되면 성능 지표(evaluation metric)를 통해 모델의 예측력이 평가된다. [출처]</p>
<p>강화학습, Reinforcement Learning</p>
<p>앞서 지도학습이 정답 데이터를 통해 모델을 학습했다면, 강화학습은 보상을 통해 스스로 최적의 행동을 학습한다.</p>
<p>예를 들어, 로봇이 공의 궤적을 예측하고 어떤 타격 동작을 해야 가장 좋은 보상을 얻는지를 학습하는 방식이다.</p>
<p>계층적 구조를 적용해, 상위 수준에서는 언제 어떤 자세로 칠지 등의 전략을 결정하고, 하위 수준에서는 실제 관절 제어와 동작 실행을 담당한다.</p>
<p>결과적으로 로봇이 사람처럼 스핀·속도에 대응하며 탁구를 치는 것이 가능해진다.</p>
<p>03 차원축소 Dimensionality reduction</p>
<p>고차원 데이터에서 중요한 정보를 보존한 채 저차원으로 표현하는 기법이다.</p>
<p>숨겨진 구조나 패턴을 더 명확히 드러내고 데이터의 시각화 및 분석 효율을 높이는 데 활용된다. [출처]</p>
<p>이들은 차원을 줄이면서도 정보 손실을 최소화하는 것을 목표로 한다.</p>
<p>이러한 차원 축소 알고리즘들은 학습 방식에 따라 선형과 비선형으로 구분된다.</p>
<p>1 . 선형 기법 데이터의 분산이나 경계선을 직선(또는 평면) 형태로 설명하는 방식이다.</p>
<p>공분산 행렬의 고유벡터나 선형 결합 계수를 구하며, 경우에 따라 가중치나 파라미터를 학습하지만 반드시 절편(intercept)이 포함되지는 않는다.</p>
<p>대표적인 기법으로는 PCA(주성분분석), LDA(선형판별분석)이 있다.</p>
<p>2 . 비선형 기법 복잡하게 휘어진 데이터 구조를 그대로 보존하려는 방식이다.</p>
<p>고차원 공간에서의 유사성 확률을 저차원에서도 유지하도록 하며, 전통적인 가중치나 절편 개념을 사용하지 않는다.</p>
<p>대표적인 기법으로는 t-SNE가 있다.</p>
<p>3 . 특징의 의미 머신러닝에서 특징(feature)은 관측된 입력 변수로서, 목표값 y를 예측하는 데 사용되는 정보이다. [출처]</p>
<p>이러한 변수들은 모두 같은 역할을 하지는 않으며, 모델은 학습을 통해 변수의 기여도나 중요도를 반영한다. [출처]</p>
<p>선형 모델에서는 가중치(coefficient)가 크면 특정 변수의 영향이 크다는 의미가 될 수 있지만, 변수 간 상관관계나 스케일 차이로 단순 비교는 주의가 필요하다. [출처]</p>
<p>그러나 모든 모델이 가중치를 명확히 제공하는 것은 아니다.</p>
<p>특히 비선형 구조나 트리 기반 모델에서는 변수의 영향력을 직접 해석하기 어려우므로,</p>
<p>feature importance, SHAP, LIME 등의 기법을 이용해 각 변수의 기여도를 시각화한다.</p>
<p>04 최적화 알고리즘 파라미터 공간(parameter space)을 탐색하여 더 나은 해를 찾는 절차라는 점에서 탐색(search)의 성격을 가진다.</p>
<p>하지만 전통적인 그래프, 경로 탐색 알고리즘과는 달리, 연속적인 공간에서 목적 함수를 기준으로 한 최적 해를 찾아가는 과정이다.</p>
<p>비선형(non-convex) 문제나 딥러닝 모델의 경우, 전역 최적해(global optimum)에 도달할 수 있는지,</p>
<p>아니면 지역 최적해(local optimum)나 안장점(saddle point)에 머무를지에 대한 이론적 증명은 매우 복잡하다.</p>
<p>특히 Adam, AMSGrad 같은 최적화 기법의 수렴(convergence)을 보장하는 연구에서도, 하이퍼파라미터 설정이나 학습률 조건 등이 중요한 변수가 되며, 수렴 증명 자체가 쉽지 않다는 점이 강조된다.</p>
<p>또한 최적화 과정은 많은 반복(iteration)과 대규모 데이터, 복잡한 모델 구조가 결합될 경우 계산 비용(computation cost)과 시간적 비용이 매우 크다.</p>
<p>이러한 이유로 실무에서는 학습 과정이 고비용·고시간 소모적이라는 점이 자주 지적된다.</p>
<p>05 실무 사용처</p>
<p>1 . 지자체 분야 지자체는 교통 흐름 예측, 범죄 예측, 환경 모니터링 등 다양한 분야에서 머신러닝 알고리즘을 활용한다.</p>
<p>예: 교통 혼잡도 예측, 재난 발생 가능성 예측</p>
<p>2 . 제조 분야 제조업체는 센서 데이터를 분석하여 장비 고장을 예측하고, 이를 통해 유지보수 비용을 절감하는 예지 보수(Predictive Maintenance)를 한다.</p>
<p>생산 라인에서 발생하는 결함을 실시간으로 감지 및 품질 향상을 위해 머신러닝 알고리즘이 사용된다.</p>
<p>KAMP, 인공지능제조플랫폼</p>
<p>스마트 대한민국 구현의 허브!제조 AI 강국으로의 도약 KAMP가 함께합니다.</p>
<p>www.kamp-ai.kr</p>
<p>3 . 금융 분야 금융 기관은 고객의 신용도 평가 및 대출 리스크 관리를 위해 머신러닝 모델을 활용한다.</p>
<p>거래 패턴을 분석하여 이상 거래를 실시간으로 감지 및 사기 예방에 사용된다.</p>
<p>06 데이터 분석 파이프라인</p>
<p>1 . 수집, Collection DB 연계(Repository), 웹 크롤링, 에이전트 설치, 서버 로그, IoT 센서 등 다양한 채널을 통해 데이터를 확보한다.</p>
<p>이때 수집된 데이터에는 정상치(normal data), 비정상치(outlier 또는 anomaly), 그리고 노이즈(noise) 가 함께 포함될 수 있으며, 이 세 요소의 비율과 품질은 분석 성능에 직접적인 영향을 미친다.</p>
<p>다만 이러한 비율은 고정된 규칙이 있는 것은 아니며, 데이터의 특성과 도메인(예: 제조, 금융, 의료 등)에 따라 경험적으로 조정·판단되어야 한다.</p>
<p>핵심은 각 요소를 정확히 구분하고 적절히 처리하는 것이다.</p>
<p>2 . 정제, Cleaning 수집된 데이터의 품질을 향상시켜 학습 알고리즘이 효율적으로 동작하도록 한다.</p>
<p>이 단계에서는 먼저 추가·삭제·대체 등의 과정을 통해 누락값(missing values)을 처리하거나 불필요한 데이터를 제거한다.</p>
<p>또한, 로그 변환이나 스케일 조정 등 변환(Transformation) 작업을 수행하고, 범주형 데이터를 수치형으로 바꾸는 인코딩(Encoding) 과정을 거친다.</p>
<p>변수 간의 범위를 맞추기 위해 스케일링(Scaling) 또는 정규화(Normalization) 를 적용하며, 이상치(outlier)는 탐지 후 제거하거나 조정하여 데이터의 왜곡을 방지한다.</p>
<p>한편, 이상치 또는 희소 클래스(sparse class)에 대한 증강(augmentation) 은 전통적 전처리(cleaning) 절차에는 포함되지 않지만,</p>
<p>불균형(class imbalance) 문제를 완화하거나 특정 도메인(예: 이미지, 텍스트)에서 모델의 일반화 능력 향상을 위해 합성(over-sampling), 생성모델 기반 증강, 혼합 확장(mixup) 등 증강 기법으로 활용된다.</p>
<p>이러한 방식은 소수 클래스의 표현을 늘려 분포의 대표성을 높이는 전략으로 연구되고 있다.</p>
<p>예를 들어, SMOTE(Synthetic Minority Over-sampling Technique)는 소수 클래스 데이터 간 보간(interpolation) 방식을 통해 합성 샘플을 생성함으로써 클래스 불균형을 완화하는 대표적인 증강 기법이다.</p>
<p>또한, GAN(Generative Adversarial Network) 기반 증강 기법(BAGAN 등)은 소수 클래스를 생성하여 불균형 문제를 해결하려는 연구도 있다.</p>
<p>3 . 저장, Storage 수집 및 정제된 데이터를 효율적으로 보관하고, 분석과 학습에 활용할 수 있도록 관리한다.</p>
<p>데이터는 세 가지 유형으로 나뉘며, 각 유형에 따라 저장 기술이 다르다.</p>
<p>① 정형 데이터, Structured Data</p>
<p>고정된 스키마를 가진 테이블 형식 데이터로, 관계형 DB(RDBMS)에 저장된다.</p>
<p>예: MES(Manufacturing Execution System)에서 생성되는 생산 이력, IoT 센서 데이터 등</p>
<p>대표 기술: MySQL, MariaDB, PostgreSQL, SAP HANA(인메모리 DB), 데이터 웨어하우스(Amazon Redshift, Google BigQuery)</p>
<p>② 비정형 데이터, Unstructured Data</p>
<p>사전 정의된 스키마가 없으며, 텍스트, 이미지, 영상, 오디오 등 다양한 형식을 포함한다.</p>
<p>예: CCTV 영상, 소셜 미디어 게시물, 고객 피드백</p>
<p>대표 기술: MongoDB, Cassandra, HBase(NoSQL DB), Hadoop HDFS, 데이터 레이크(Amazon S3, Azure Data Lake)</p>
<p>③ 반정형 데이터, Semi-structured Data</p>
<p>일부 구조적 요소를 포함하지만 완전한 스키마는 없는 데이터</p>
<p>예: JSON, XML, 로그 파일, IoT 센서 데이터</p>
<p>대표 기술: MongoDB, Couchbase, 데이터 레이크(Amazon S3, Azure Data Lake)</p>
<p>참고 사항 Schema-on-write: 데이터를 저장할 때 스키마를 정의하는 방식 (RDBMS)</p>
<p>Schema-on-read: 데이터를 읽을 때 스키마를 적용하는 방식 (NoSQL, 데이터 레이크)</p>
<p>4 . 시각화, Visualization 분석 결과를 직관적으로 이해 및 전달하기 위한 단계이다. 특히 대시보드(Dashboard)는 여러 시각화 요소를 통합하여 웹이나 애플리케이션 상에서 상호작용 가능하게 제공한다.</p>
<p>① 주요 시각화 도구</p>
<p>Plotly: 웹 기반 인터랙티브 시각화 라이브러리로, 2D·3D 플롯과 대시보드 제작에 적합하다. Dash: Plotly를 기반으로 한 Python 웹 프레임워크로, 코드만으로 대시보드를 구현 가능하다. Matplotlib: 기본 2D 시각화에 강점을 가지며, 세밀한 커스터마이징이 가능하다. Seaborn: Matplotlib 기반으로 통계적 시각화에 특화되어 있으며, 간결한 문법과 미려한 디자인을 제공한다. ② 주요 시각화 유형</p>
<p>2D/3D 플롯: 데이터 분포 및 변수 간 관계를 표현 바 차트, 파이 차트: 범주형 데이터의 분포를 시각화 히트맵(Heatmap): 데이터 간 상관관계 또는 밀도를 색상으로 표현 맵(Map): 지리적 데이터를 시각화하여 공간적 패턴 분석</p>
<p>5 . 분석, Analysis 수집·정제·저장된 데이터를 기반으로 의미 있는 인사이트를 도출한다. 빅데이터와 AI 환경에서 머신러닝은 핵심적인 역할을 하며, 네 가지의 주요 기법이 있다.</p>
<p>① 분류, Classification</p>
<p>지도학습(Supervised Learning)에 속하며, 입력 데이터에 대해 미리 정의된 레이블을 예측한다.</p>
<p>활용 예: 스팸 이메일 필터링, 질병 진단 등</p>
<p>② 군집화, Clustering</p>
<p>비지도학습(Unsupervised Learning)에 속하며, 라벨 없이 데이터 내 유사한 특성을 가진 그룹을 식별한다.</p>
<p>활용 예: 고객 세분화, 시장 분석</p>
<p>③ 예측, Prediction/Regression</p>
<p>연속형 목표값을 예측하며, 과거 데이터 기반으로 미래 값을 추정한다.</p>
<p>④ 추천, Recommendation</p>
<p>사용자 행동이나 선호도를 분석하여 개인화된 추천을 제공한다.</p>
<p>활용 예: 전자상거래, 콘텐츠 플랫폼</p>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/ml/ml_02.html</guid>
  <pubDate>Tue, 09 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>트리 알고리즘</title>
  <dc:creator>혼자 공부하는 머신러닝+딥러닝</dc:creator>
  <link>https://shinjihan.github.io/studylog/ai/hg_05.html</link>
  <description><![CDATA[ 




<p>트리 알고리즘, 하이퍼파라미터 튜닝 실습, 그리고 앙상블 모델에 대해 다루고자 한다.</p>
<p>05 - 1 . 결정 트리</p>
<p>5-1 결정 트리.ipynb</p>
<p>https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-1.ipynb</p>
<p>와인 샘플 데이터 불러오기.</p>
<p>import pandas as pd wine = pd.read_csv(‘https://bit.ly/wine_csv_data’)</p>
<p>처음 5개의 샘플 확인.</p>
<p>전체 와인 데이터에서 화이트 와인을 골라내는 문제.</p>
<p>각 열 데이터 확인 및 누락된 데이터 확인.</p>
<p>wine.info()</p>
<p>열에 대한 간략한 통계량 출력.</p>
<p>wine.describe()</p>
<p>훈련 세트와 데스트 세트로 나누기.</p>
<p>data = wine[[‘alcohol’, ‘sugar’, ‘pH’]].to_numpy() target = wine[‘class’].to_numpy()</p>
<p>from sklearn.model_selection import train_test_split train_input, test_input, train_target, test_target = train_test_split( data, target, test_size = 0.2, random_state = 42)</p>
<p>print(train_input.shape, test_input.shape)</p>
<p>훈련 세트 전처리.</p>
<p>from sklearn.preprocessing import StandardScaler</p>
<p>ss = StandardScaler() ss.fit(train_input)</p>
<p>train_scaled = ss.transform(train_input) test_scaled = ss.transform(test_input)</p>
<p>from sklearn.linear_model import LogisticRegression</p>
<p>lr = LogisticRegression() lr.fit(train_scaled, train_target)</p>
<p>print(lr.score(train_scaled, train_target)) print(lr.score(test_scaled, test_target))</p>
<p>점수가 높지 않음을 확인.</p>
<p>학습한 계수와 절편 출력.</p>
<p>print(lr.coef_, lr.intercept_)</p>
<p>결정 트리 정확도 평가하기.</p>
<p>from sklearn.tree import DecisionTreeClassifier dt = DecisionTreeClassifier(random_state = 42) dt.fit(train_scaled, train_target)</p>
<p>print(dt.score(train_scaled, train_target)) print(dt.score(test_scaled, test_target))</p>
<p>노트가 어떤 특성으로 이뤄졌는지 확인하기.</p>
<p>import matplotlib.pyplot as plt from sklearn.tree import plot_tree</p>
<p>plt.figure(figsize = (10,7)) plot_tree(dt)</p>
<p>plt.figure(figsize = (10,7)) plot_tree(dt, max_depth = 1, filled = True, feature_names = [‘alcohol’, ‘sugar’, ‘pH’])</p>
<p>불순도</p>
<p>정보이득</p>
<p>가지치기</p>
<p>최대 3개의 노드까지 성장히기.</p>
<p>dt = DecisionTreeClassifier(max_depth = 3, random_state = 42) dt.fit(train_scaled, train_target)</p>
<p>print(dt.score(train_scaled, train_target)) print(dt.score(test_scaled, test_target))</p>
<p>함수로 그리기.</p>
<p>plt.figure(figsize = (20,15)) plot_tree(dt, filled = True, feature_names = [‘alcohol’, ‘sugar’, ‘pH’])</p>
<p>다시 훈련하기.</p>
<p>dt = DecisionTreeClassifier(max_depth = 3, random_state = 42) dt.fit(train_input, train_target)</p>
<p>print(dt.score(train_input, train_target)) print(dt.score(test_input, test_target))</p>
<p>특성값을 표준점수로 바꾸지 않기.</p>
<p>plt.figure(figsize = (20,15)) plot_tree(dt, filled = True, feature_names = [‘alcohol’, ‘sugar’, ‘pH’])</p>
<p>특성 중요도 출력하기.</p>
<p>print(dt.feature_importances_)</p>
<p>dt = DecisionTreeClassifier(min_impurity_decrease = 0.0005, random_state = 42) dt.fit(train_input, train_target)</p>
<p>print(dt.score(train_input, train_target)) print(dt.score(test_input, test_target))</p>
<p>plt.figure(figsize = (20,15)) plot_tree(dt, filled = True, feature_names = [‘alcohol’, ‘sugar’, ‘pH’])</p>
<p>05 - 2 . 교차 검증 &amp; 그리드 서치</p>
<p>5-2 교차 검증과 그리드 서치.ipynb</p>
<p>Run, share, and edit Python notebooks</p>
<p>colab.research.google.com import pandas as pd wine = pd.read_csv(‘https://bit.ly/wine_csv_data’)</p>
<p>data = wine[[‘alcohol’, ‘sugar’, ‘pH’]].to_numpy() target = wine[‘class’].to_numpy()</p>
<p>from sklearn.model_selection import train_test_split</p>
<p>train_input, test_input, train_target, test_target = train_test_split( data, target, test_size=0.2, random_state=42)</p>
<p>sub_input, val_input, sub_target, val_target = train_test_split( train_input, train_target, test_size=0.2, random_state=42)</p>
<p>print(sub_input.shape, val_input.shape)</p>
<p>모델 평가하기.</p>
<p>from sklearn.tree import DecisionTreeClassifier</p>
<p>dt = DecisionTreeClassifier(random_state=42) dt.fit(sub_input, sub_target)</p>
<p>print(dt.score(sub_input, sub_target)) print(dt.score(val_input, val_target))</p>
<p>교차 검증</p>
<p>from sklearn.model_selection import cross_validate import pandas as pd</p>
<p>scores = cross_validate(dt, train_input, train_target) scores_df = pd.DataFrame(scores) scores_df</p>
<p>최상의 검증 점수.</p>
<p>import numpy as np print(np.mean(scores[‘test_score’]))</p>
<p>교차 검증.</p>
<p>from sklearn.model_selection import StratifiedKFold scores = cross_validate(dt, train_input, train_target, cv = StratifiedKFold()) print(np.mean(scores[‘test_score’]))</p>
<p>교차 검증.</p>
<p>splitter = StratifiedKFold(n_splits = 10, shuffle=True, random_state=42) scores = cross_validate(dt, train_input, train_target, cv=splitter) print(np.mean(scores[‘test_score’]))</p>
<p>하이퍼파라미터 튜닝 딕셔너리 만들기.</p>
<p>from sklearn.model_selection import GridSearchCV params = {‘min_impurity_decrease’: [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]} gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1) gs.fit(train_input, train_target)</p>
<p>dt = gs.best_estimator_ print(dt.score(train_input, train_target))</p>
<p>print(gs.best_params_)</p>
<p>0.0001이 가장 좋은 값으로 선택.</p>
<p>5번의 교차 검증.</p>
<p>print(gs.cv_results_[‘mean_test_score’])</p>
<p>최상의 매개변수로 만 검증 점수의 조합.</p>
<p>best_index = np.argmax(gs.cv_results_[‘mean_test_score’]) print(gs.cv_results_[‘params’][best_index])</p>
<p>지정하기.</p>
<p>params = {‘min_impurity_decrease’: np.arange(0.0001, 0.001, 0.0001), ‘max_depth’: range(5, 20, 1), ‘min_samples_split’: range(2, 100, 10) }</p>
<p>gs = GridSearchCV(</p>
<pre><code>DecisionTreeClassifier(random_state = 42), 
params, n_jobs = -1)</code></pre>
<p>gs.fit(train_input, train_target)</p>
<p>최상의 매개변수 조합확인.</p>
<p>print(gs.best_params_)</p>
<p>최상의 교차 검증 점수 확인.</p>
<p>print(np.max(gs.cv_results_[‘mean_test_score’]))</p>
<p>랜덤서치</p>
<p>from scipy.stats import uniform, randint rgen = randint(0, 10) rgen.rvs(10)</p>
<p>샘플링 숫자 늘리기.</p>
<p>np.unique(rgen.rvs(1000), return_counts=True)</p>
<p>10개의 실수 추출.</p>
<p>ugen = uniform(0, 1) ugen.rvs(10)</p>
<p>탐색.</p>
<p>params = {‘min_impurity_decrease’: uniform(0.0001, 0.001), ‘max_depth’: randint(20, 50), ‘min_samples_split’: randint(2, 25), ‘min_samples_leaf’: randint(1, 25), }</p>
<p>from sklearn.model_selection import RandomizedSearchCV</p>
<p>gs = RandomizedSearchCV( DecisionTreeClassifier(random_state = 42), params,n_iter = 100, n_jobs = -1, random_state = 42) gs.fit(train_input, train_target)</p>
<p>매개변수에 지정.</p>
<p>gs.best_params_</p>
<p>최고의 교차 검증 점수 확인.</p>
<p>print(np.max(gs.cv_results_[‘mean_test_score’]))</p>
<p>테스트 세트의 성능 확인.</p>
<p>dt = gs.best_estimator_ print(dt.score(test_input, test_target))</p>
<p>gs = RandomizedSearchCV( DecisionTreeClassifier(splitter = ‘random’, random_state = 42), params, n_iter = 100, n_jobs = -1, random_state = 42 ) gs.fit(train_input, train_target)</p>
<p>gs.best_params_</p>
<p>print(np.max(gs.cv_results_[‘mean_test_score’]))</p>
<p>dt = gs.best_estimator_ print(dt.score(test_input, test_target))</p>
<p>05 - 3 . 트리의 앙상블</p>
<p>5-3 트리의 앙상블.ipynb</p>
<p>Run, share, and edit Python notebooks</p>
<p>colab.research.google.com import numpy as np import pandas as pd from sklearn.model_selection import train_test_split</p>
<p>wine = pd.read_csv(‘https://bit.ly/wine_csv_data’)</p>
<p>data = wine[[‘alcohol’, ‘sugar’, ‘pH’]].to_numpy() target = wine[‘class’].to_numpy()</p>
<p>train_input, test_input, train_target, test_target = train_test_split( data, target, test_size=0.2, random_state=42)</p>
<p>from sklearn.model_selection import cross_validate from sklearn.ensemble import RandomForestClassifier</p>
<p>rf = RandomForestClassifier(n_jobs=-1, random_state=42) scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)</p>
<p>print(np.mean(scores[‘train_score’]), np.mean(scores[‘test_score’]))</p>
<p>rf.fit(train_input, train_target) print(rf.feature_importances_)</p>
<p>rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)</p>
<p>rf.fit(train_input, train_target) print(rf.oob_score_)</p>
<p>from sklearn.ensemble import ExtraTreesClassifier et = ExtraTreesClassifier(n_jobs=-1, random_state=42) scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)</p>
<p>print(np.mean(scores[‘train_score’]), np.mean(scores[‘test_score’]))</p>
<p>et.fit(train_input, train_target) print(et.feature_importances_)</p>
<p>from sklearn.ensemble import GradientBoostingClassifier</p>
<p>gb = GradientBoostingClassifier(random_state=42) scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)</p>
<p>print(np.mean(scores[‘train_score’]), np.mean(scores[‘test_score’]))</p>
<p>gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42) scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)</p>
<p>print(np.mean(scores[‘train_score’]), np.mean(scores[‘test_score’]))</p>
<p>gb.fit(train_input, train_target) print(gb.feature_importances_)</p>
<section id="사이킷런-1.0-버전-아래에서는-다음-라인의-주석을-해제하고-실행하세요." class="level1">
<h1>사이킷런 1.0 버전 아래에서는 다음 라인의 주석을 해제하고 실행하세요.</h1>
</section>
<section id="from-sklearn.experimental-import-enable_hist_gradient_boosting" class="level1">
<h1>from sklearn.experimental import enable_hist_gradient_boosting</h1>
<p>from sklearn.ensemble import HistGradientBoostingClassifier</p>
<p>hgb = HistGradientBoostingClassifier(random_state=42) scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)</p>
<p>print(np.mean(scores[‘train_score’]), np.mean(scores[‘test_score’]))</p>
<p>from sklearn.inspection import permutation_importance</p>
<p>hgb.fit(train_input, train_target) result = permutation_importance(hgb, train_input, train_target, n_repeats=10, random_state=42, n_jobs=-1) print(result.importances_mean)</p>
<p>result = permutation_importance(hgb, test_input, test_target, n_repeats=10, random_state=42, n_jobs=-1) print(result.importances_mean)</p>
<p>hgb.score(test_input, test_target)</p>
<p>from xgboost import XGBClassifier</p>
<p>xgb = XGBClassifier(tree_method=‘hist’, random_state=42) scores = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)</p>
<p>print(np.mean(scores[‘train_score’]), np.mean(scores[‘test_score’]))</p>
</section>
<section id="pip-install-lightgbm" class="level1">
<h1>!pip install lightgbm</h1>
<p>from lightgbm import LGBMClassifier lgb = LGBMClassifier(random_state = 42) scores = cross_validate(lgb, train_input, train_target, return_train_score = True, n_jobs = -1) print(np.mean(scores[‘train_score’]), np.mean(scores[‘test_score’]))</p>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/hg_05.html</guid>
  <pubDate>Fri, 04 Oct 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>다양한 분류 알고리즘</title>
  <dc:creator>혼자 공부하는 머신러닝+딥러닝</dc:creator>
  <link>https://shinjihan.github.io/studylog/ai/hg_04.html</link>
  <description><![CDATA[ 




<p>로지스틱 회귀와 확률적 경사 하강법과 같은 분류 알고리즘을 배우고, 이진 분류와 다중 분류의 차이를 이해하며, 각 클래스에 대한 확률 예측에 대해 다루고자 한다.</p>
<p>04 - 1 . 로지스틱 회귀</p>
<p>4-1 로지스틱 회귀.ipynb</p>
<p>Run, share, and edit Python notebooks</p>
<p>colab.research.google.com import pandas as pd # 데이터 준비하기 fish = pd.read_csv(‘https://bit.ly/fish_csv_data’) fish.head()</p>
<p>Species를 타겟으로 하고 나머지를 입력 데이터로 사용한다.</p>
<p>어떤 종류의 생선이 있는지 확인한다.</p>
<p>print(pd.unique(fish[‘Species’]))</p>
<p>7가지의 생선 종이 있음을 확인.</p>
<p>Species를 제외한 새로운 데이터프레임 만들기.</p>
<p>fish_input = fish[[‘Weight’,‘Length’,‘Diagonal’,‘Height’,‘Width’]].to_numpy() print(fish_input[:5])</p>
<p>새로운 데이터 프레임이 만들어 졌음을 확인.</p>
<p>모델 만들기.</p>
<section id="species-열의-데이터를-타겟-변수로-설정" class="level1">
<h1>‘Species’ 열의 데이터를 타겟 변수로 설정</h1>
<p>fish_target = fish[‘Species’].to_numpy()</p>
<p>from sklearn.model_selection import train_test_split # 데이터를 훈련 세트와 테스트 세트로 나누기 train_input, test_input, train_target, test_target = train_test_split( fish_input, fish_target, random_state = 42) # 결과 재현을 위한 설정</p>
<p>from sklearn.preprocessing import StandardScaler ss = StandardScaler() # StandardScaler 객체 생성 ss.fit(train_input) # 표준화 전처리 작업 train_scaled = ss.transform(train_input) # 훈련 데이터 변환 test_scaled = ss.transform(test_input) # 테스트 데이터 변환</p>
<p>from sklearn.neighbors import KNeighborsClassifier # k-NN 분류기 객체 생성 (k=3) kn = KNeighborsClassifier(n_neighbors=3) # 훈련된 데이터를 사용하여 모델 학습 kn.fit(train_scaled, train_target)</p>
</section>
<section id="훈련-데이터-정확도-출력" class="level1">
<h1>훈련 데이터 정확도 출력</h1>
<p>print(kn.score(train_scaled, train_target)) # 테스트 데이터 정확도 출력 print(kn.score(test_scaled, test_target))</p>
<p>fish[‘Species’]는 여러 종류의 물고기 종(species)을 대상으로 하므로, 각 샘플이 둘 이상의 클래스 중 하나로 분류된다.</p>
<p>이처럼 클래스가 3개 이상일 때, 이를 다중 분류라고 한다.</p>
<p>k-NN 분류기는 다중 분류 문제에서도 잘 동작하며,</p>
<p>각 데이터 포인트에 대해 가장 가까운 이웃들 중 다수의 클래스를 선택하는 방식으로 클래스를 예측한다.</p>
<p>scikit-learn의 장점</p>
<p>분류 알고리즘에서 문자열로 된 타겟값도 자동으로 처리할 수 있도록 설계되어 있다. 내부적으로는 문자열을 고유한 정수 값으로 인코딩하여 사용되며 이때, 사용자는 별도의 인코딩을 하지 않아도 된다.</p>
<p>문자열 타겟값을 내부적으로 처리할 때에는 알파벳 순서대로 고유한 정수로 인코딩한다.</p>
<p>예를 들어, 타겟값이 [ ‘Tuna’, ‘Salmon’, ‘Bass’ ] 일 때 다음과 같이 인코딩된다.</p>
<ul>
<li>Bass ⇨ 0</li>
<li>Salmon ⇨ 1</li>
<li>Tuna ⇨ 2</li>
</ul>
<p>그러므로, 분류 모델에서 예측된 클래스가 어떤 값인지 해석할 때 이를 염두 해야 한다.</p>
<p>특히 모델의 성능 평가나 결과 해석 시, 클래스 레이블이 자동으로 정렬된다는 점에 주의해야 한다.</p>
<p>인코딩 순서를 직접 지정하고 싶다면,</p>
<p><code>LabelEncoder</code> 또는 <code>pandas.Categorical</code>을 사용해 명시적으로 타겟값을 숫자로 변환할 수 있다.</p>
<p>정렬된 순서 확인하기.</p>
<p>print(kn.classes_)</p>
<p>알파벳 순서로 정렬된 것을 확인.</p>
<p>테스트 세트에 있는 처음 5개의 샘플을 예측해본다.</p>
<p>print(kn.predict(test_scaled[:5]))</p>
<p>5개의 샘플에 대한 예측이 어떤 확률을 갖는지 확인하기.</p>
<p>import numpy as np</p>
<p>proba = kn.predict_proba(test_scaled[:5]) print(np.round(proba, decimals = 4)) # 소수점 네 번째 자리 표시</p>
<p>위 숫자는 각각 [ Bream ~ Whitefish ] 순서에 해당된다.</p>
<p>네 번째 샘플의 최근접 이웃의 클래스 확인하기.</p>
<p>distances, indexes = kn.kneighbors(test_scaled[3:4]) print(train_target[indexes])</p>
<p>1개의 Roach = 0.3333 + 2개의 Perch = 0.6667 클래스 확률을 정확히 예측하였다.</p>
<p>그러나, k = 3일 경우 이웃이 포함될 확률이 0/3, 1/3, 2/3, 3/3과 같은 제한된 확률만을 가진다.</p>
<p>이는 확률적으로 다소 불안정한 결과를 초래할 수 있으며, 분류를 좀 더 세밀하게 조정하는 데 한계가 있다.</p>
<p>그러므로, 더 나은 성능을 얻기 위해 다른 방법이 필요할 수 있다.</p>
<p>로지스틱 회귀 (Logistic Regression)</p>
<p>이진, 다중 분류 문제에서 자주 사용되는 통계적 기법.</p>
<p>선형 회귀와는 달리 예측값이 0 ~ 1 사이의 확률값으로 제한되어 분류 문제에 적합하다.</p>
<p>이 모델은 본질적으로 선형 모델지만,</p>
<p>예측값이 (– ∞ ~ + ∞) 범위를 가지므로, 그 값을 그대로 사용하지 않는다.</p>
<p>이는 분류 문제로 만들기 위한 과정으로 시그모이드 함수를 이용하여 예측값을 0 ~ 1 사이의 확률로 변환할 수 있다.</p>
<p>피(Φ, φ: 그리스어 알파벳의 21번째 글자)</p>
<p>–5 ~ +5 사이에 0.1 간격으로 배열 z를 만든 뒤, z 위치마다 시그모이드 함수를 계산한다.</p>
<p>import numpy as np import matplotlib.pyplot as plt</p>
<p>z = np.arange(-5, 5, 0.1) phi = 1 / (1 + np.exp(-z))</p>
<p>plt.plot(z, phi) plt.xlabel(‘z’) plt.ylabel(‘phi’)</p>
<p>0 ~ 1의 범위를 갖는 것을 확인.</p>
<ol type="1">
<li>로지스틱 회귀로 이진 분류 수행하기.</li>
</ol>
</section>
<section id="도미와-빙어의-행만-골라내기." class="level1">
<h1>도미와 빙어의 행만 골라내기.</h1>
</section>
<section id="도미빙어-true-그-외-false" class="level1">
<h1>도미&amp;빙어 = True, 그 외 = False</h1>
<p>bream_smelt_indexes = (train_target == ‘Bream’) | (train_target == ‘Smelt’) train_bream_smelt = train_scaled[bream_smelt_indexes] target_bream_smelt = train_target[bream_smelt_indexes]</p>
<p>from sklearn.linear_model import LogisticRegression lr = LogisticRegression() lr.fit(train_bream_smelt, target_bream_smelt)</p>
<p>처음 5개의 샘플 예측하기.</p>
<p>print(lr.predict(train_bream_smelt[:5]))</p>
<p>두 번째 샘플을 제외한 나머지를 도미로 예측.</p>
<p>처음 5개의 샘플에 대해 예측 확률 확인하기.</p>
<p>print(lr.predict_proba(train_bream_smelt[:5]))</p>
<p>[ 왼쪽: 음성 클래스(0) / 오른쪽: 양성 클래스(1) ] 샘플마다 2개의 확률이 출력되었다.</p>
<p>어떤 것이 양성 클래스인지 알기 위해, 알파벳으로 정렬하기.</p>
<p>print(lr.classes_)</p>
<p>오른쪽에 있는 빙어(Smelt)가 양성 클래스인 것을 확인. 따라서, 로지스틱 회귀를 통해 성공적으로 이진 분류를 수행하였다.</p>
<p>로지스틱 회귀가 학습한 계수 확인하기.</p>
<p>print(lr.coef_, lr.intercept_)</p>
<p>처음 5개의 샘플의 z값을 출력.</p>
<p>decisions = lr.decision_function(train_bream_smelt[:5]) print(decisions)</p>
<p>이 값은 시그모이드 함수를 적용하여 해당 클래스에 속할 확률로 변환하기.</p>
<p>from scipy.special import expit print(expit(decisions))</p>
<p>두 번째 열의 값이 양성 클래스임을 확인.</p>
<ol start="2" type="1">
<li>로지스틱 회귀로 다중 분류 수행하기.</li>
</ol>
<p>lr = LogisticRegression(C = 20, max_iter = 1000) lr.fit(train_scaled, train_target)</p>
<p>print(lr.score(train_scaled, train_target)) print(lr.score(test_scaled, test_target))</p>
<p>훈련 세트와 테스트 세트 모두에서 높은 점수를 기록했으며, 과대적합이나 과소적합의 문제가 나타나지 않았다.</p>
<p>테스트 세트의 처음 5개의 샘플 예측하기.</p>
<p>print(lr.predict(test_scaled[:5]))</p>
<p>테스트 세트의 처음 5개의 샘플에 대한 예측 확률 출력하기.</p>
<p>proba = lr.predict_proba(test_scaled[:5]) print(np.round(proba, decimals=3))</p>
<p>5개의 행과 7개의 열을 통해, 다중 분류임을 확인.</p>
<p>클래스 정보 확인하기.</p>
<p>print(lr.classes_)</p>
<p>위 예측 확률 중 가장 큰 값이 예측된 클래스가 된다.</p>
<p>다중 분류의 선형 방정식 알아보기.</p>
<p>print(lr.coef_.shape, lr.intercept_.shape)</p>
<p>이 로지스틱 회귀 모델은 7개의 클래스(다중 분류)를 예측하며, 각 클래스에 대해 5개의 특성을 고려한 선형 결정을 내리고 있음을 알 수 있다.</p>
<p>소프트맥스 함수 (Softmax)</p>
<p>다중 클래스 분류 문제에서 각 클래스에 대한 확률을 계산하기 위해 사용되는 함수.</p>
<p>주어진 입력 값(로지스틱 회귀에서의 결정값)을 확률로 변환하여, 각 클래스에 속할 확률을 반환한다.</p>
<p>결과적으로, 출력된 확률들의 총합이 1이 되도록 정규화한다.</p>
<p>소프트맥스 함수 사용하여, 확률 변환하기.</p>
<p>decision = lr.decision_function(test_scaled[:5]) print(np.round(decision, decimals = 2))</p>
<p>샘플에 대한 예측 확률 출력하기.</p>
<p>from scipy.special import softmax proba = softmax(decision, axis = 1) print(np.round(proba, # 소수점 세 번째자리 decimals = 3))</p>
<p>이전에 구한 배열과 결과가 일치한다.</p>
<p>결과적으로, 7개의 생선 종류에 대한 확률을 예측하는 모델을 성공적으로 훈련하였다.</p>
<p>04 - 2 . 확률적 경사 하강법</p>
<p>4-2 확률적 경사 하강법.ipynb</p>
<p>Run, share, and edit Python notebooks</p>
<p>colab.research.google.com</p>
<p>확률적 경사 하강법 (Stochastic Gradient Descent, SGD)</p>
<p>기계 학습에서 최적화를 위해 널리 사용되는 알고리즘 중 하나. 경사 하강법의 변형 중 하나로, 특히 큰 데이터셋을 처리할 때 효과적이다.</p>
<p>이 알고리즘은 매 반복마다 손실 함수의 기울기를 계산한 뒤, 그 방향으로 파라미터를 업데이트한다.</p>
<p>이를 통해 손실을 줄이도록 학습하는 과정이다.</p>
<p>에포크 (Epoch)</p>
<p>전체 훈련 데이터셋을 모델이 한 번 완전히 통과한 주기.</p>
<p>한 번의 에포크는, 모델이 전체 데이터셋을 사용하여 파라미터를 업데이트하는 과정을 한 번 수행한 것이다.</p>
<p>미니 배치 경사 하강법 (Mini-Batch Gradient Descent)</p>
<p>전체 데이터셋을 작은 배치(mini-batch)로 나누어 각각의 배치에 대해 파라미터를 업데이트하는 방법.</p>
<p>한 번의 업데이트에 하나의 데이터 포인트인 단일 샘플만 사용하는 SGD와 달리</p>
<p>여러 샘플(미니 배치)로 구성된 소규모 데이터 세트를 사용한다.</p>
<p>배치 경사 하강법 (Batch Gradient Descent)</p>
<p>전체 데이터셋을 사용하여 파라미터를 업데이트하는 방법. 모든 샘플을 사용해 손실 함수의 기울기를 계산한다.</p>
<p>손실 함수 (loss function)</p>
<p>기계 학습 및 통계에서 모델의 예측 성능 평가용 함수.</p>
<p>모델이 예측한 값과 실제 값 간의 차이를 수치적으로 나타내며, 이 값을 최소화하는 것이 학습의 목표이다.</p>
<p>이진 교차 엔트로피 손실 (Binary Cross-Entropy Loss)</p>
<p>로지스틱 회귀에서의 손실 함수.</p>
<p>모델의 예측 확률과 실제 클래스 레이블 간의 차이를 측정하여, 모델을 최적화하는 데 사용된다.</p>
<p>이 손실 함수는 모델의 예측이 실제 클래스와 얼마나 일치하는지를 측정한다.</p>
<p>예측이 정확할수록 손실 값이 0에 가까워지고, 예측이 틀릴 경우 손실 값은 크게 증가하며, 이론적으로 무한대까지 커질 수 있다.</p>
<p>특성값의 스케일을 맞춘 두 Numpy 배열 준비하기.</p>
</section>
<section id="이전과-동잉한-코드" class="level1">
<h1>이전과 동잉한 코드</h1>
<p>import pandas as pd fish = pd.read_csv(‘https://bit.ly/fish_csv_data’)</p>
</section>
<section id="species-타겟-데이터-나머지-입력-데이터" class="level1">
<h1>Species ⇨ 타겟 데이터, 나머지 ⇨ 입력 데이터</h1>
<p>fish_input = fish[[‘Weight’,‘Length’,‘Diagonal’,‘Height’,‘Width’]].to_numpy() fish_target = fish[‘Species’].to_numpy()</p>
</section>
<section id="훈련-세트와-데이터-세트로-나누기" class="level1">
<h1>훈련 세트와 데이터 세트로 나누기</h1>
<p>from sklearn.model_selection import train_test_split train_input, test_input, train_target, test_target = train_test_split( fish_input, fish_target, random_state = 42)</p>
</section>
<section id="각각의-특성-표준화-전처리하기" class="level1">
<h1>각각의 특성 표준화 전처리하기</h1>
<p>from sklearn.preprocessing import StandardScaler ss = StandardScaler() ss.fit(train_input) train_scaled = ss.transform(train_input) test_scaled = ss.transform(test_input)</p>
<p>SGD를 사용하여 로지스틱 회귀 모델을 학습하기.</p>
<p>from sklearn.linear_model import SGDClassifier sc = SGDClassifier(loss = ‘log_loss’, max_iter = 10, random_state = 42) sc.fit(train_scaled, train_target)</p>
<p>print(sc.score(train_scaled, train_target)) print(sc.score(test_scaled, test_target))</p>
<p>두 데이터 세트 모두 점수가 낮아서 개선이 필요하다.</p>
<p>매 호출 시 1 에포크씩 이어서 진행하는 점진적 학습법을 시도한다.</p>
<p>sc.partial_fit(train_scaled, train_target) print(sc.score(train_scaled, train_target)) print(sc.score(test_scaled, test_target))</p>
<p>정확도가 향상된 것을 확인. 이로 인해 에포크를 늘리면 정확도가 향상된다는 것을 알았지만, 계속해서 에포크를 늘리기만 하면 과대적합의 위험이 있다.</p>
<p>따라서, 과대적합되지 않으면서도 높은 정확도를 유지할 수 있는 최적의 에포크 횟수를 찾아야 한다.</p>
<p>과대적합되기 전, 조기 종료를 통해 최적의 에포크 횟수를 알아내기.</p>
<p>import numpy as np sc = SGDClassifier(loss=‘log_loss’, random_state = 42)</p>
<p>train_score = [] test_score = []</p>
<p>classes = np.unique(train_target) for _ in range(0, 300): # 300번의 에포크 동안 훈련을 반복진행 sc.partial_fit(train_scaled, train_target, classes=classes)</p>
<pre><code>train_score.append(sc.score(train_scaled, train_target))
test_score.append(sc.score(test_scaled, test_target))</code></pre>
<p>import matplotlib.pyplot as plt plt.plot(train_score) plt.plot(test_score) plt.xlabel(‘epoch’) plt.ylabel(‘accuracy’)</p>
<p>약 100번째 에포크부터 두 데이터 세트의 점수 차이가 증가하기 시작한다.</p>
<p>위 그래프를 참고하여 반복 횟수를 100으로 맞추어 훈련을 진행한다.</p>
<p>sc = SGDClassifier(loss = ‘log_loss’, max_iter = 100, tol = None, random_state = 42) sc.fit(train_scaled, train_target)</p>
<p>print(sc.score(train_scaled, train_target)) print(sc.score(test_scaled, test_target))</p>
<p>정확도 점수가 매우 높게 나온 것을 확인.</p>
<p>확률적 경사 하강법을 사용하여 생선 분류 문제를 성공적으로 수행하였다.</p>
<p>힌지 손실 (Hinge Loss)</p>
<p>loss의 매개변수의 기본값이다.</p>
<p>주로 SVM(Support Vector Machine)과 같은 분류 모델에서 사용되는 손실 함수이다.</p>
<p>힌지 손실을 기반으로 한 추가적인 분류 모델을 학습한다.</p>
<p>sc = SGDClassifier(loss = ‘hinge’, max_iter = 100, tol = None, random_state = 42) sc.fit(train_scaled, train_target)</p>
<p>print(sc.score(train_scaled, train_target)) print(sc.score(test_scaled, test_target))</p>
<p>결과적으로 loss를 log_loss로 설정했을 때, 가장 우수한 성능을 보인다.</p>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/hg_04.html</guid>
  <pubDate>Tue, 01 Oct 2024 15:00:00 GMT</pubDate>
</item>
<item>
  <title>회귀 알고리즘 &amp; 모델 규제</title>
  <dc:creator>혼자 공부하는 머신러닝+딥러닝</dc:creator>
  <link>https://shinjihan.github.io/studylog/ai/hg_03.html</link>
  <description><![CDATA[ 




<p>지도 학습의 한 종류인 회귀 문제를 이해하고 다양한 선형 회귀 알고리즘의 장단점에 대해 다루고자 한다.</p>
<p>https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/3-1.ipynb</p>
<p>03 - 1 . 최근접 이웃 회귀</p>
<p>3-1 최근접 이웃 회귀.ipynb</p>
<p>회귀 (regression) 지도 학습에서 중요한 개념 중 하나로, 주어진 데이터를 바탕으로 연속적인 값을 예측하는 문제를 해결한다.</p>
<p>k–최근접 이웃(KNN) 회귀는 회귀 알고리즘 중 하나이다.</p>
<p>이 알고리즘은 예측하려는 값이 주어졌을 때, 가까운 이웃들의 값을 평균 내어 결과를 추정하는 방식으로 작동한다.</p>
<p>KNN은 단순하면서도 직관적인 알고리즘이기 때문에, 데이터의 패턴을 찾는 데 유용한 경우가 많다.</p>
<p>예를 들어, 농어의 무게를 예측할 때, 특정 농어와 가까운 다른 농어들의 무게를 이용해 평균값을 예측하는 것이 KNN 회귀 방식이다.</p>
<p>이 방법은 복잡한 계산을 요구하지 않지만, 데이터의 분포나 k 값 설정에 민감할 수 있다.</p>
<p>회귀 문제에서는 예측하고자 하는 값이 숫자로 표현되며, 이는 여러 산업 분야에서 다양하게 활용될 수 있다.</p>
<p>농어의 길이와 무게 데이터</p>
<p>import numpy as np perch_length = np.array( [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5, 44.0] )</p>
<p>perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] )</p>
<p>이 데이터의 형태를 보기 위해, 산점도를 그리기</p>
<p>import matplotlib.pyplot as plt plt.scatter(perch_length, perch_weight) plt.xlabel(‘length’) plt.ylabel(‘weight’) 더보기 더보기</p>
<p>농어의 길이와 무게는 비례한다.</p>
<p>데이터를 훈련 세트와 테스트 세트로 나누기</p>
<p>from sklearn.model_selection import train_test_split train_input, test_input, train_target, test_target = train_test_split( perch_length, perch_weight, random_state = 42)</p>
<p>train_input.shape, test_input.shape</p>
<p>두 개의 배열을 2차원 배열로 변환</p>
<p>train_input = train_input.reshape(-1, 1) test_input = test_input.reshape(-1, 1) train_input.shape, test_input.shape</p>
<section id="배열의-크기를-자동으로-맞추기" class="level1">
<h1>-1: 배열의 크기를 자동으로 맞추기</h1>
</section>
<section id="배열의-두-번째-차원을-1열로-설정" class="level1">
<h1>1: 배열의 두 번째 차원을 1열로 설정</h1>
<p>KNeighborsRegressor 모델을 생성하고 두 개의 데이터를 사용하여 학습시키는 과정</p>
<p>from sklearn.neighbors import KNeighborsRegressor knr = KNeighborsRegressor() knr.fit(train_input, train_target)</p>
<p>결정계수 (R², R-squared)</p>
<p>SSres: 잔차 제곱합, SStot: 총 제곱합</p>
<p>회귀 분석에서 모델의 예측 성능을 평가하는 지표 중 하나로, 모델이 주어진 데이터를 얼마나 잘 설명하는지를 나타낸다.</p>
<p>결정계수는 0 ~ 1 사이의 값을 가지며, 1 에 가까울수록 모델이 데이터를 잘 설명하고, 0 에 가까울수록 설명력이 떨어진다는 의미이다.</p>
<p>테스트 세트의 점수 확인</p>
<p>knr.score(test_input, test_target)</p>
<p>이 모델은 99%의 변동성을 설명할 수 있다.</p>
<p>다만, 결정계수(R²)는 정확도처럼 직관적으로 해석하기는 조금 어려울 수 있다.</p>
<p>단순히 맞고 틀린 것을 계산하는 지표가 아니기 때문에, “예측이 얼마나 정확한가”를 직관적으로 파악하기는 힘들다.</p>
<p>즉, 99%의 값이 실제로 좋은 성능인지 여부는 문제의 특성에 따라 다를 수 있다.</p>
<p>또한, 모든 데이터에서 완벽한 예측을 했는지 여부는 알 수 없고, 오차나 과적합 문제에 대한 구체적인 설명을 해주지 않는다.</p>
<p>따라서, 모델의 성능을 더 명확히 평가하기 위해서는 추가적인 평가 지표가 필요하다.</p>
<p>예측이 벗어난 정도를 알아보기 위해, 타겟과 예측한 값 사이의 차이를 계산 및 출력한다</p>
<p>from sklearn.metrics import mean_absolute_error</p>
</section>
<section id="테스트-세트에-대한-예측을-만든다" class="level1">
<h1>테스트 세트에 대한 예측을 만든다</h1>
<p>test_prediction = knr.predict(test_input)</p>
</section>
<section id="테스트-세트에-대한-평균-절댓값-오차를-계산한다" class="level1">
<h1>테스트 세트에 대한 평균 절댓값 오차를 계산한다</h1>
<p>mae = mean_absolute_error(test_target, test_prediction) mae</p>
<p>평균적으로 약 19g 정도 타겟값과 다르다는 것을 확인</p>
<p>훈련 세트를 사용해 평가해보기 위해, score() 메서드에 훈련 세트를 전달하여 점수 출력하기</p>
<p>knr.score(train_input, train_target)</p>
<p>훈련 세트(96%)가 테스트 세트(99%)보다 낮은 점수임을 확인</p>
<p>보통 훈련 세트에서의 성능이 (테스트 세트, 검증 세트에서의 성능보다) 더 높게 나오는 경우가 많다.</p>
<p>그 이유는 모델이 훈련 세트에 직접 노출되어 그 데이터를 바탕으로 학습하기 때문이다. 훈련 세트에 최적화된 상태일 경우, 그 데이터에서의 성능은 당연히 높아질 수밖에 없다.</p>
<p>위 경우, 훈련 세트의 점수가 낮게 나왔으므로 과소적합된 것이다.</p>
<p>과대적합(overfitting) &amp; 과소적합(underfitting) 머신러닝에서 모델의 성능을 저하시키는 두 가지 주요 문제.</p>
<ol type="1">
<li>과대적합 (Overfitting) 과대적합은 모델이 훈련 데이터에 너무 과도하게 적응하여, 새로운 데이터(테스트 데이터)에는 잘 일반화되지 못하는 현상.</li>
</ol>
<p>즉, 모델이 훈련 데이터의 노이즈나 불필요한 패턴까지 학습하는 경우이다.</p>
<ol type="1">
<li><p>훈련 데이터에 대한 정확도는 매우 높지만, 테스트 데이터나 새로운 데이터에 대한 성능이 떨어진다.</p></li>
<li><p>훈련 데이터의 세부 사항까지 모두 학습하므로, 복잡한 모델이나 파라미터 수가 많은 모델에서 자주 발생한다.</p></li>
<li><p>모델이 데이터의 본질적인 패턴보다는 훈련 데이터에 특화된 규칙을 학습하는 문제를 일으킨다.</p></li>
<li><p>과소적합 (Underfitting) 모델이 훈련 데이터를 충분히 학습하지 못해, 훈련 데이터와 테스트 데이터 모두에서 성능이 좋지 않은 상태.</p></li>
</ol>
<p>즉, 모델이 너무 단순해서 데이터의 패턴을 제대로 잡지 못하는 경우이다.</p>
<ol type="1">
<li><p>훈련 데이터에서조차 예측 성능이 낮다.</p></li>
<li><p>모델이 데이터를 적절히 설명할 수 없을 정도로 너무 단순하거나 제한적인 구조를 가지고 있을 때 발생한다.</p></li>
<li><p>훈련 데이터와 테스트 데이터에서 모두 성능이 낮게 나온다.</p></li>
</ol>
<p>모델이 너무 단순하므로, 복잡성을 높이기 위해 이웃의 개수 k를 줄여보기로 한다</p>
</section>
<section id="이웃의-갯수를-3으로-설정" class="level1">
<h1>이웃의 갯수를 3으로 설정</h1>
<p>knr.n_neighbors = 3</p>
</section>
<section id="모델을-다시-훈련" class="level1">
<h1>모델을 다시 훈련</h1>
<p>knr.fit(train_input, train_target) knr.score(train_input, train_target)</p>
<p>훈련 세트의 점수가 높아진 것을 확인</p>
<p>knr.score(test_input, test_target)</p>
<p>테스트 세트의 점수가 낮아진 것을 확인</p>
<p>위 과정을 통해, 과소적합 문제를 해결했고 두 세트 간에 점수 차이도 크지 않으므로 과대적합 문제도 없다.</p>
<p>따라서, 성공적으로 회귀 모델을 훈련하였다.</p>
<p>03 - 2 . 선형 회귀</p>
<p>3-2 선형 회귀.ipynb</p>
<p>Run, share, and edit Python notebooks</p>
<p>colab.research.google.com # 이전과 동일한 데이터 import numpy as np perch_length = np.array( [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5, 44.0] ) perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] )</p>
</section>
<section id="훈련-세트와-데이터-세트로-나누고-2차원-배열로-변환하기" class="level1">
<h1>훈련 세트와 데이터 세트로 나누고 2차원 배열로 변환하기</h1>
<p>from sklearn.model_selection import train_test_split</p>
<p>train_input, test_input, train_target, test_target = train_test_split( perch_length, perch_weight, random_state = 42)</p>
<p>train_input = train_input.reshape(-1, 1) test_input = test_input.reshape(-1, 1)</p>
</section>
<section id="최근접-이웃-개수를-3으로-하는-모델-훈련" class="level1">
<h1>최근접 이웃 개수를 3으로 하는 모델 훈련</h1>
<p>from sklearn.neighbors import KNeighborsRegressor</p>
<p>knr = KNeighborsRegressor(n_neighbors = 3) knr.fit(train_input, train_target)</p>
<p>위 모델을 사용하여 길이 50cm 농어의 무게를 예측한다</p>
<p>knr.predict([[50]])</p>
<p>1,033g = 1.033kg으로 예측</p>
<p>그러나 이 농어의 실제 무게는 더 많으므로, 이 농어를 산점도에 표시하고 최근접 이웃도 함께 시각화하기로 한다.</p>
</section>
<section id="cm-농어의-이웃을-구한다" class="level1">
<h1>50cm 농어의 이웃을 구한다</h1>
<p>distances, indexes = knr.kneighbors([[50]])</p>
<p>plt.scatter(train_input, train_target) plt.scatter(train_input[indexes], train_target[indexes], marker = ‘D’) plt.scatter(50, 1033, marker = ‘^’) plt.xlabel(‘length’) plt.ylabel(‘weight’) 더보기 더보기</p>
<p>50cm 농어에서 가장 가까운 것은 45cm 근방임을 확인</p>
<p>위 샘플들의 무게를 평균한다.</p>
<p>np.mean(train_target[indexes])</p>
<p>모델이 예측한 값과 정확히 일치한다.</p>
<p>따라서, 새로운 샘플이 훈련 세트의 범위를 벗어나면 엉뚱한 값을 예측할 수 있다.</p>
<p>knr.predict([[100]])</p>
<p>100cm인 농어도 1,033g으로 예측</p>
<p>위 농어도 산점도에 표시하고 최근접 이웃도 함께 시각화하기로 한다.</p>
</section>
<section id="cm-농어의-이웃을-구한다-1" class="level1">
<h1>100cm 농어의 이웃을 구한다</h1>
<p>distances, indexes = knr.kneighbors([[100]])</p>
<p>plt.scatter(train_input, train_target) plt.scatter(train_input[indexes], train_target[indexes], marker = ‘D’) plt.scatter(100, 1033, marker = ‘^’) plt.xlabel(‘length’) plt.ylabel(‘weight’) 더보기 더보기</p>
<p>농어가 아무리 커도 무게는 고정됨을 확인</p>
<p>이를 해결하려면 가장 큰 농어가 포함되도록 훈련 세트를 다시 구성해야 한다. 그러나 이러한 작업을 매번 반복하는 것은 번거로울 수 있다.</p>
<p>따라서, 새로운 알고리즘을 적용해 보기로 한다.</p>
<p>선형 회귀 (Linear Regression)</p>
<p>직선의 방정식: y = ax + b 기울기는 계수(coefficient) &amp; 가중치(weight)라고도 부른다.</p>
<p>독립 변수와 종속 변수 간의 선형 관계를 모델링하는 가장 기본적인 회귀 분석 방법이다.</p>
<p>목표는 주어진 데이터를 기반으로 직선 을 그려서 종속 변수(예측하고자 하는 값)를 예측하는 것이다.</p>
<p>선형 회귀 모델 훈련</p>
<p>from sklearn.linear_model import LinearRegression</p>
<p>lr = LinearRegression() lr.fit(train_input, train_target)</p>
<p>50cm 농어에 대한 예측</p>
<p>lr.predict([[50]])</p>
<p>1,241g = 1.241kg으로 예측</p>
<p>LinearRegression 클래스가 찾은 a, b를 출력</p>
<p>lr.coef_, lr.intercept_</p>
<p>농어의 길이가 15 ~ 50인 범위에 대해 직선을 그려본다</p>
<p>plt.scatter(train_input, train_target) plt.plot([15, 50], [15<em>lr.coef_+lr.intercept_, 50</em>lr.coef_+lr.intercept_]) plt.scatter(50, 1241.8, marker=‘^’) plt.xlabel(‘length’) plt.ylabel(‘weight’) 더보기 더보기</p>
<p>선형 회귀 알고리즘이 이 데이터셋에서 찾은 최적의 직선</p>
<p>훈련 세트와 테스트 세트에 대한 R² 출력</p>
<p>print(lr.score(train_input, train_target)) print(lr.score(test_input, test_target))</p>
<p>전체적으로 과소적합되었음을 확인</p>
<p>위 직선의 좌측 하단을 보면, 선이 0 이하로 내려가 있다. 하지만 0g 이하의 농어는 존재하지 않으므로, 이를 보완할 필요가 있다.</p>
<p>다항 회귀 (Polynomial Regression)</p>
<p>2차 다항 회귀 공식: y = ax² + bx + c</p>
<p>선형 회귀의 확장으로, 데이터가 비선형적일 때 더 적합한 모델을 만들기 위해 사용된다.</p>
<p>선형 회귀가 직선을 그리는 것과 달리, 다항 회귀는 곡선 을 그려 비선형 관계를 설명한다.</p>
<p>새롭게 만든 데이터셋의 크기 확인</p>
<p>train_poly = np.column_stack((train_input ** 2, train_input)) test_poly = np.column_stack((test_input ** 2, test_input)) train_poly.shape, test_poly.shape</p>
<p>원래 특성인 길이를 제곱하여 왼쪽 열에 추가하였고, 그 결과 각각의 데이터 세트에 2개의 특성이 생겼다</p>
<p>train_poly를 사용하여, 선형 회귀 모델을 다시 훈련</p>
<p>lr = LinearRegression() lr.fit(train_poly, train_target) lr.predict([[50**2, 50]])</p>
<p>이전에 훈련된 모델보다 더 높은 값을 예측</p>
<p>이 모델이 훈련한 계수와 절편을 출력</p>
<p>lr.coef_, lr.intercept_</p>
<p>농어의 무게 = 1.01 × 농어의 길이² – 21.6 × 농어의 길이 + 116.05</p>
<p>이전과 동일하게 훈련 세트의 산점도에 그래프로 그려보기</p>
<p>point = np.arange(15, 50) plt.scatter(train_input, train_target) plt.plot(point, 1.01*point**2 - 21.6*point + 116.05) plt.scatter([50], [1574], marker=‘^’) plt.xlabel(‘length’) plt.ylabel(‘weight’) 더보기 더보기</p>
<p>앞선 단순 선형 회귀 모델보다 훨씬 더 나은 예측 곡선이 그려졌다.</p>
<p>훈련 세트와 테스트 세트에 대한 R² 출력</p>
<p>print(lr.score(train_poly, train_target)) print(lr.score(test_poly, test_target))</p>
<p>두 데이터 세트에 대한 점수가 높아졌다.</p>
<p>다만, 훈련 세트의 점수가 더 낮아 여전히 과소적합 문제가 남아 있다. 또한, 전체 데이터 세트의 점수가 낮기 때문에 이를 개선할 필요가 있다.</p>
<p>03 - 3 . 특성 공학과 규제</p>
<p>3-3 특성 공학과 규제.ipynb</p>
<p>Run, share, and edit Python notebooks</p>
<p>colab.research.google.com</p>
<p>다중 회귀 (Multiple Regression) 두 개 이상의 독립 변수를 사용하여 종속 변수를 예측하는 회귀 분석 기법.</p>
<p>이 방법은 데이터에서 복잡한 관계를 모델링할 수 있는 유연성을 제공한다.</p>
<p>그러나 다중 회귀는 다중 공선성(multi-collinearity) 문제가 발생할 수 있어, 독립 변수 간의 상관관계가 높으면 모델의 해석이 어려워질 수 있다.</p>
<p>즉, 과대적합의 위험이 있으며, 모델이 너무 복잡해질 수 있다.</p>
<p>또한, 독립 변수가 3개 이상이 되면, 시각적으로 표현하기 어려워진다.</p>
<p>예를 들어, 4차원 이상의 데이터를 시각화하는 것은 사람의 직관으로는 불가능하다.</p>
<p>특성 공학 (Feature Engineering) 데이터 전처리 과정에서 기존 데이터를 변형하거나 새로운 특성을 생성하여 모델의 성능을 향상시키는 기법.</p>
<p>이는 머신러닝 모델이 데이터를 더 잘 이해하도록 돕는 중요한 과정이다.</p>
<p>농어의 특성이 3개로 늘어나 데이터가 커졌기 때문에, 이를 복사해서 붙여넣는 것은 번거롭다.</p>
<p>이 경우, 판다스를 사용하여 인터넷에서 농어 데이터를 내려받으면 된다.</p>
<p>import pandas as pd df = pd.read_csv(‘https://bit.ly/perch_csv_data’) perch_full = df.to_numpy() perch_full</p>
<p>이하 생략</p>
</section>
<section id="이전과-동일한-데이터" class="level1">
<h1>이전과 동일한 데이터</h1>
<p>import numpy as np perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] )</p>
</section>
<section id="훈련-세트와-테스트-세트-나누기" class="level1">
<h1>훈련 세트와 테스트 세트 나누기</h1>
<p>from sklearn.model_selection import train_test_split train_input, test_input, train_target, test_target = train_test_split( perch_full, perch_weight, random_state = 42)</p>
<p>사이킷런의 PolynomialFeatures 클래스를 사용하여 입력 데이터를 다항식 특성으로 변환하는 과정이다.</p>
<p>PolynomialFeatures 클래스 위와 같은, 데이터 변환 클래스를 변환기(transformer)라고 한다. 이러한 변환 과정은 타겟 데이터의 유무와 관계없이 진행되며</p>
<p>이를 통해, 모델에 더 적합한 형태로 만들거나, 성능을 향상시킨다.</p>
<p>from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures() poly.fit([[2, 3]]) poly.transform([[2, 3]])</p>
<p>2개의 특성: [2, 3] ⇨ 6(=4+2)개의 특성: [1, 2, 3, 4, 6, 9]</p>
<p>위 모델에 대한 선형 방정식 더보기 더보기</p>
<p>추가된 4가지 특성: 길이, 높이, 두께, 1</p>
<p>절편(1)을 위한 항 제거</p>
<p>poly = PolynomialFeatures(include_bias = False) poly.fit([[2, 3]]) poly.transform([[2, 3]])</p>
<p>절편(1)이 제거된 것을 확인</p>
<p>배열의 크기 확인</p>
<p>poly.fit(train_input) train_poly = poly.transform(train_input) train_poly.shape</p>
<p>데이터의 샘플 수 42개(훈련 샘플의 개수) / 각 샘플이 9개의 다항식 특성으로 확장</p>
<p>9개의 특성이 어떤 과정으로 만들어졌는지 확인</p>
<p>poly.get_feature_names_out()</p>
<p>변환된 특성을 이용하여 다중 회귀 모델 훈련</p>
<p>test_poly = poly.transform(test_input) # 데이터 세트 변환 from sklearn.linear_model import LinearRegression</p>
<p>lr = LinearRegression() lr.fit(train_poly, train_target) lr.score(train_poly, train_target)</p>
<p>모델이 훈련 데이터의 변동성을 약 99.03% 설명함을 의미</p>
<p>테스트 세트의 점수 확인</p>
<p>lr.score(test_poly, test_target)</p>
<p>이전과 비교해 점수 상승은 없으나, 농어의 길이만 사용했을 때의 과소적합 문제는 해결되었다</p>
<p>5제곱까지 특성을 만들어 다시 출력</p>
<p>poly = PolynomialFeatures(degree = 5, include_bias = False) poly.fit(train_input) train_poly = poly.transform(train_input) test_poly = poly.transform(test_input) train_poly.shape</p>
<p>특성이 무려 55개나 증가함을 확인</p>
<p>선형 회귀 모델 다시 훈련</p>
<p>lr.fit(train_poly, train_target) lr.score(train_poly, train_target)</p>
<p>거의 완벽한 점수임을 확인</p>
<p>테스트 세트의 점수 재확인</p>
<p>lr.score(test_poly, test_target)</p>
<p>매우 큰 음수값이 나온 것을 확인</p>
<p>더 많은 특성을 통해 데이터의 복잡한 패턴과 비선형 관계를 더 잘 모델링할 수 있다는 장점이 있지만</p>
<p>특성이 너무 많아지면, 모델이 훈련 데이터에 과적합될 위험이 커지며 이는 새로운 데이터에 대한 일반화 성능을 떨어뜨릴 수 있다.</p>
<p>규제 (Regularization) 머신러닝 모델의 과적합(overfitting)을 방지하기 위해 사용되는 기술. 모델의 복잡성을 줄여 일반화 성능을 향상시키는 데 도움을 준다.</p>
<p>이를 통해 모델이 훈련 데이터에 지나치게 맞춰지는 것을 방지하고, 새로운 데이터에 대한 예측 성능을 높일 수 있다.</p>
<p>일반적으로 선형 회귀 모델에 규제를 적용할 때는, 계수 값의 크기가 서로 크게 다르지 않아야 한다.</p>
<p>그러므로, 규제를 진행하기 전 정규화를 해야만 한다.</p>
<p>훈련 데이터에 대해 평균과 표준편차를 계산</p>
<p>from sklearn.preprocessing import StandardScaler ss = StandardScaler() ss.fit(train_poly)</p>
</section>
<section id="훈련-데이터를-표준화-평균-0-표준편차-1" class="level1">
<h1>훈련 데이터를 표준화 (평균 0, 표준편차 1)</h1>
<p>train_scaled = ss.transform(train_poly)</p>
</section>
<section id="테스트-데이터를-훈련-데이터의-통계에-맞춰-표준화" class="level1">
<h1>테스트 데이터를 훈련 데이터의 통계에 맞춰 표준화</h1>
<p>test_scaled = ss.transform(test_poly)</p>
<p>릿지 회귀 &amp; 라쏘 회귀 둘 다 선형 회귀 모델에 규제를 적용하여 과적합을 방지하는 기법.</p>
<p>릿지 회귀 (Ridge Regression)</p>
<p>L2 정규화를 적용, 이는 모든 계수의 제곱합에 비례하는 패널티 추가</p>
<p>모든 특성을 유지하지만, 계수의 크기를 작게 만들어 모델의 복잡성을 줄인다. 특성 간의 상관관계가 높은 경우, 규제를 통해 더 안정적인 모델을 만든다.</p>
<p>주로 다중 공선성이 있는 데이터에서 효과적</p>
<p>라쏘 회귀 (Lasso Regression) L1 정규화를 적용, 이는 모든 계수의 절댓값 합에 비례하는 패널티 추가</p>
<p>일부 계수를 0으로 만들어 불필요한 특성을 선택적으로 제거하며, 이로 인한 모델의 해석성 향상</p>
<p>자동으로 특성 선택을 수행하므로, 더 간결한 모델을 생성 가능 특히 고차원 데이터에서 유용하게 사용</p>
<p>릿지 회귀 모델 훈련</p>
<p>from sklearn.linear_model import Ridge</p>
<p>ridge = Ridge() ridge.fit(train_scaled, train_target) print(ridge.score(train_scaled, train_target))</p>
<p>이전 모델에 비해 점수가 낮아짐을 확인</p>
<p>테스트 세트에 대한 점수 확인</p>
<p>ridge.score(test_scaled, test_target)</p>
<p>이전 음수값의 점수가 정상으로 돌아왔음을 확인</p>
<p>위 모델들의 규제의 양은 하이퍼파라미터(alpha)를 통해 임의로 조절할 수 있다.</p>
<p>alpha를 사용하여 L1 및 L2 정규화의 강도를 조절하며, 이 값이 클수록 규제의 강도가 강해지는 비례 관계가 나타난다.</p>
<p>반대로 계수의 값은 작아지는 반비례 관계를 가지며, 결과적으로 과소적합이 발생할 수 있다.</p>
<p>적절한 alpha값을 찾기 위해, R² 값을 그리기</p>
<p>import matplotlib.pyplot as plt</p>
<p>train_score = [] test_score = []</p>
</section>
<section id="배씩-늘려가며-훈련하기0.01-100" class="level1">
<h1>10배씩 늘려가며 훈련하기(0.01 ~ 100)</h1>
<p>alpha_list = [0.001, 0.01, 0.1, 1, 10, 100] for alpha in alpha_list: ridge = Ridge(alpha = alpha) ridge.fit(train_scaled, train_target) train_score.append(ridge.score(train_scaled, train_target)) test_score.append(ridge.score(test_scaled, test_target))</p>
</section>
<section id="동일한-간격으로-나타내기-위해-로그-함수로-바꾸어-지수로-표현" class="level1">
<h1>동일한 간격으로 나타내기 위해 로그 함수로 바꾸어 지수로 표현</h1>
<p>plt.plot(np.log10(alpha_list), train_score) plt.plot(np.log10(alpha_list), test_score) plt.xlabel(‘alpha’) plt.ylabel(‘R^2’) 더보기 더보기</p>
<p>적절한 alpha값으로 최종 모델 훈련</p>
<p>ridge = Ridge(alpha = 0.1) ridge.fit(train_scaled, train_target)</p>
<p>print(ridge.score(train_scaled, train_target)) print(ridge.score(test_scaled, test_target))</p>
<p>이 모델은 두 데이터 세트의 점수가 모두 높고, 과대적합과 과소적합 사이의 균형을 맞추고 있다</p>
<p>라쏘 모델 훈련</p>
<p>from sklearn.linear_model import Lasso # 클래스 라쏘로 바꾸기 ↴ lasso = Lasso() # Ridge ⇨ Lasso lasso.fit(train_scaled, train_target) print(lasso.score(train_scaled, train_target)) print(lasso.score(test_scaled, test_target))</p>
<p>라쏘 모델 또한 과대적합과 과소적합을 잘 억제하였다</p>
<p>적절한 alpha값을 찾기 위해, R² 값을 그리기</p>
<p>train_score = [] test_score = []</p>
<p>alpha_list = [0.001, 0.01, 0.1, 1, 10, 100] for alpha in alpha_list: lasso = Lasso(alpha = alpha, max_iter = 10000) lasso.fit(train_scaled, train_target) train_score.append(lasso.score(train_scaled, train_target)) test_score.append(lasso.score(test_scaled, test_target))</p>
<p>plt.plot(np.log10(alpha_list), train_score) plt.plot(np.log10(alpha_list), test_score) plt.xlabel(‘alpha’) plt.ylabel(‘R^2’) 더보기 더보기</p>
<p>적절한 alpha값으로 최종 모델 훈련</p>
<p>lasso = Lasso(alpha = 10) lasso.fit(train_scaled, train_target)</p>
<p>print(lasso.score(train_scaled, train_target)) print(lasso.score(test_scaled, test_target))</p>
<p>이 모델은 두 데이터 세트의 점수가 모두 높고, 과대적합을 잘 억제하였다.</p>
<p>영향력이 적은 특성의 계수값을 0으로 만든다</p>
<p>np.sum(lasso.coef_ == 0)</p>
<p>라쏘 회귀가 40개의 특성의 계수를 0으로 만들고, 해당 특성들을 모델에서 제거</p>


</section>

 ]]></description>
  <category>1</category>
  <guid>https://shinjihan.github.io/studylog/ai/hg_03.html</guid>
  <pubDate>Mon, 23 Sep 2024 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
